---
tags:
  - 5semester
  - CompInt
  - informatik
fach: "[[Computational Intelligence]]"
Thema:
Benötigte Zeit:
date created: Wednesday, 23. October 2024, 20:00
date modified: Thursday, 24. October 2024, 11:30
---

# Computational Intelligence Vorlesung

## Einführung

- **Beginn der Vorlesung**:
  - **Rückkehr zum regulären Vorlesungstrack**: Nach einer Pause oder einem anderen Fokus kehrt die Vorlesung wieder zum Hauptthema zurück.
  - **Fokus auf Basisbegriffe und Definitionen**: Einführung grundlegender Konzepte, die das Fundament für das weitere Verständnis bilden.
  - **Erste Einblicke in die mathematische Arbeit**: Anwendung von Mathematik zur präzisen Beschreibung und Analyse der Konzepte.

## Organisatorisches

- **Aufzeichnungen**:
  - **Vorlesungen werden aufgezeichnet**: Für Studierende, die nicht anwesend sein können oder die Inhalte wiederholen möchten.
  - **Verfügbarkeit der Aufzeichnungen**: Sie werden demnächst hochgeladen, sodass noch kein dringender Zeitdruck besteht.
- **Klausurtermin**:
  - **Geplanter Wunschtermin**: In der letzten Semesterwoche, um ausreichend Vorbereitungszeit zu gewährleisten.
  - **Beantragung und Bestätigung**: Der Dozent wird den Termin offiziell beantragen und die Studierenden informieren, sobald er bestätigt ist.
  - **Weitere Informationen folgen**: Aktualisierungen werden zeitnah mitgeteilt, um Planungssicherheit zu bieten.
- **Umfrage zu Prolog**:
  - **Frage an die Studierenden**: Wer hat Erfahrung mit Prolog?
    - Ziel ist es, den Kenntnisstand der Studierenden zu ermitteln.
  - **Hintergrund**: Überlegung, Prolog in zukünftigen Kursen oder Übungen zu integrieren.
  - **Ergebnisse der Umfrage**:
    - Wenige Studierende haben Prolog-Code gesehen.
    - Noch weniger haben komplexe Programme in Prolog geschrieben.
  - **Schlussfolgerung**:
    - Eventuell Einführung von Prolog in optionalen Kursen oder Lesekreisen.
    - Anpassung des Unterrichts, um Über- oder Unterforderung zu vermeiden.

## Einführung in Agenten

### Das Agentenmodell

- **Grundidee**:
  - Modellierung von **intelligenten Systemen** als **Agenten**, die in einer **Umgebung (Environment)** agieren.
  - **Agenten** sind autonome Einheiten, die Entscheidungen treffen und handeln können.
- **Bestandteile**:
  - **Agent**:
    - Nimmt Informationen aus der Umwelt auf und reagiert darauf.
    - Hat **Sensoren**, um die Umwelt wahrzunehmen, und **Aktuatoren**, um Aktionen auszuführen.
    - Verfügt über ein internes **Verhalten (Behavior)**, das die Entscheidungslogik enthält.
  - **Environment (Umgebung)**:
    - Die Welt, in der der Agent agiert.
    - Kann dynamisch und komplex sein, mit eigenen Regeln und Zuständen.
- **Interaktion zwischen Agent und Environment**:
  - **Aktionen**:
    - Der Agent beeinflusst die Umwelt durch gezielte Aktionen.
    - Beispiele: Bewegung, Manipulation von Objekten, Kommunikation.
  - **Observationen**:
    - Der Agent erhält Feedback oder neue Informationen aus der Umwelt.
    - Sensoren liefern Daten über den aktuellen Zustand oder Veränderungen.
- **Interne Struktur des Agenten**:
  - **Sensoren**:
    - Erfassen spezifische Arten von Daten, z.B. visuelle Informationen, Temperaturen, Positionen.
    - Übersetzen physikalische Größen in verarbeitbare Daten.
  - **Aktuatoren**:
    - Ermöglichen dem Agenten, auf die Umwelt einzuwirken.
    - Beispiele: Motoren zur Bewegung, Greifarme zur Manipulation.
  - **Verhalten (Behavior)**:
    - Definiert die **Regeln** oder **Algorithmen**, nach denen der Agent Entscheidungen trifft.
    - Kann einfach (z.B. feste Regeln) oder komplex (z.B. maschinelles Lernen) sein.

### Anwendbarkeit des Modells

- **Universelle Anwendbarkeit**:
  - Das Agentenmodell ist flexibel und kann in vielen Bereichen eingesetzt werden.
  - **Roboter**: Physische Agenten, die in der realen Welt interagieren.
  - **Software-Agenten**: Programme, die in digitalen Umgebungen agieren, z.B. Suchalgorithmen, virtuelle Assistenten.
  - **Biologische Systeme**: Modellierung von Tieren oder sogar menschlichem Verhalten.
- **Vorteile des Modells**:
  - **Klare Schnittstellen**:
    - Durch die Definition von Observationen und Aktionen ist die Interaktion zwischen Agent und Umwelt strukturiert.
    - Erleichtert das Design komplexer Systeme durch Modularität.
  - **Analytische Möglichkeiten**:
    - Das Modell erlaubt es, das Verhalten von Agenten formal zu analysieren und zu optimieren.
    - Grundlage für theoretische Untersuchungen und praktische Implementierungen.
  - **Flexibilität und Erweiterbarkeit**:
    - Neue Sensoren, Aktuatoren oder Verhaltensweisen können leicht hinzugefügt werden.
    - Anpassbar an spezifische Anforderungen oder Forschungsfragen.

## Beispiele zur Veranschaulichung

### Beispiel 1: Vacuum World

- **Beschreibung**:
  - Eine einfache Welt bestehend aus zwei Räumen.
  - Ein **Staubsauger-Agent** soll die Räume sauber halten.
  - Jeder Raum kann entweder **sauber** oder **schmutzig** sein.
- **Aktionen (A)**:
  - `move_to_left_room`: Der Agent bewegt sich in den linken Raum.
  - `move_to_right_room`: Der Agent bewegt sich in den rechten Raum.
  - `clean`: Der Agent reinigt den aktuellen Raum.
- **Observationen (O)**:
  - **Position**:
    - Gibt an, in welchem Raum sich der Agent befindet.
    - Typischerweise numerisch codiert (z.B. `1` für links, `2` für rechts).
  - **is_dirty**:
    - Boolean-Wert (`true` oder `false`), der angibt, ob der aktuelle Raum schmutzig ist.
- **Anwendung des Modells**:
  - Der Agent nimmt seine **aktuelle Position** und den **Zustand des Raums** wahr.
  - Basierend darauf entscheidet er, ob er reinigen oder den Raum wechseln soll.
  - Ziel ist es, beide Räume dauerhaft sauber zu halten.
- **Herausforderungen**:
  - Obwohl einfach, illustriert dieses Beispiel grundlegende Konzepte wie Entscheidungsfindung und Zustandswahrnehmung.

### Beispiel 2: GridWorld

- **Beschreibung**:
  - Eine **zweidimensionale Gitterwelt**, in der sich der Agent bewegen kann.
  - Es gibt **Hindernisse**, **Ziele** und möglicherweise gefährliche Felder wie **Lava**.
- **Aktionen (A)**:
  - `go_north`, `go_east`, `go_south`, `go_west`:
    - Der Agent bewegt sich um ein Feld in die jeweilige Richtung.
  - Optional: `do_nothing`:
    - Der Agent bleibt stehen, was in bestimmten Situationen sinnvoll sein kann.
- **Observationen (O)**:
  - **Umgebungsfelder**:
    - Informationen über die Felder in den vier Himmelsrichtungen.
    - Mögliche Zustände: `empty`, `wall`, `lava`, `goal`.
  - **Position**:
    - **position_x**, **position_y**: Aktuelle Koordinaten des Agenten im Gitter.
  - **Ausrichtung**:
    - **direction**: Blickrichtung des Agenten, relevant für bestimmte Aktionen oder Sensoren.
- **Anwendung des Modells**:
  - Der Agent muss sicher navigieren, Hindernisse umgehen und das Ziel erreichen.
  - Er nutzt seine Sensorinformationen, um Entscheidungen zu treffen.
- **Herausforderungen**:
  - **Planung**: Finden des optimalen Pfades zum Ziel.
  - **Unbekannte Umgebungen**: Möglicherweise muss der Agent die Welt zuerst erkunden.

### Beispiel 3: Cutting Marble

- **Beschreibung**:
  - Ein **Steinmetz-Agent** arbeitet an einem Marmorblock.
  - Ziel ist es, eine bestimmte Skulptur oder Form zu erstellen.
- **Aktionen (A)**:
  - `chisel(stone_x, stone_y, angle)`:
    - **stone_x**, **stone_y**: Position auf dem Stein, an der gearbeitet wird.
    - **angle**: Winkel, unter dem der Meißel angesetzt wird.
- **Observationen (O)**:
  - **Image**:
    - Visuelle Darstellung des aktuellen Zustands des Marmorblocks.
    - Kann als hochauflösendes Bild mit Farbinformationen repräsentiert werden.
  - **Viewing Angle**:
    - Betrachtungswinkel, unter dem der Agent den Stein sieht.
    - Wichtig für die räumliche Orientierung.
  - **Position**:
    - Aktuelle Position des Werkzeugs oder des Agenten relativ zum Stein.
- **Anwendung des Modells**:
  - Der Agent analysiert das Bild, um zu entscheiden, wo Material entfernt werden muss.
  - Entscheidungen basieren auf der gewünschten Endform und dem aktuellen Zustand.
- **Herausforderungen**:
  - **Komplexität der Wahrnehmung**: Verarbeitung großer Datenmengen (Bilddaten).
  - **Fehleranfälligkeit**: Ein falscher Meißelschlag kann irreversible Schäden verursachen.
  - **Planung und Präzision**: Exakte Berechnungen sind notwendig, um das gewünschte Ergebnis zu erzielen.

### Beispiel 4: Autonomes Fahren

- **Beschreibung**:
  - Ein **autonomes Fahrzeug** navigiert durch eine reale Umgebung.
  - Muss **Verkehrsregeln** einhalten, **Hindernisse** vermeiden und **Ziele** erreichen.
- **Aktionen (A)**:
  - `accelerate`: Erhöht die Geschwindigkeit des Fahrzeugs.
  - `brake`: Reduziert die Geschwindigkeit oder stoppt das Fahrzeug.
  - `steer(angle)`: Lenkt das Fahrzeug in eine bestimmte Richtung.
- **Observationen (O)**:
  - **Car Position**:
    - GPS-Daten geben die genaue Position auf der Karte an.
  - **Lidar Distances**:
    - Sensoren messen Abstände zu Objekten in der Umgebung.
    - Wichtig für die Erkennung von Hindernissen und anderen Verkehrsteilnehmern.
  - **Current Speed**:
    - Momentane Geschwindigkeit, wichtig für Bremsberechnungen und Tempokontrollen.
  - **Video Feed**:
    - Kamerabilder liefern visuelle Informationen über die Umgebung.
    - Verwendung für Objekterkennung, Spurhaltung und Verkehrszeichenerkennung.
- **Anwendung des Modells**:
  - Der Agent muss große Mengen an Daten in Echtzeit verarbeiten.
  - Entscheidungen müssen schnell und sicher getroffen werden.
- **Herausforderungen**:
  - **Echtzeitverarbeitung**: Schnelle Reaktionen sind essenziell für die Sicherheit.
  - **Komplexe Umgebungen**: Unvorhersehbare Ereignisse wie Fußgänger oder Wetterbedingungen.
  - **Regulatorische Anforderungen**: Einhaltung von Gesetzen und Sicherheitsstandards.

## Definition eines Agenten

- **Formale Definition**:
  - Ein **Agent** ist definiert durch eine **Policy-Funktion** `π: O → A`.
  - **O**: Menge der möglichen Observationen.
  - **A**: Menge der möglichen Aktionen.
- **Policy-Funktion (`π`)**:
  - **Input**: Eine Observation `O_t` zum Zeitpunkt `t`.
  - **Output**: Eine Aktion `A_t`, die aufgrund der Observation gewählt wird.
  - **Interpretation**:
    - Die Policy legt fest, wie der Agent auf jede mögliche Observation reagiert.
    - Kann als Regelwerk oder als komplexer Algorithmus implementiert sein.
- **Zeitreihen**:
  - **Observationen**: Folge von Observationen über die Zeit, z.B. `O_1, O_2, …, O_t`.
  - **Aktionen**: Entsprechende Folge von Aktionen, z.B. `A_1, A_2, …, A_t`.
  - **Zusammenhang**:
    - Zu jedem Zeitpunkt entscheidet der Agent basierend auf der aktuellen Observation.
    - Die Aktion kann die Umwelt verändern, was zu neuen Observationen führt.
- **Anmerkungen**:
  - **Deterministische vs. stochastische Policies**:
    - Deterministisch: Gleiche Observation führt immer zur gleichen Aktion.
    - Stochastisch: Aktionen können mit bestimmten Wahrscheinlichkeiten gewählt werden.
  - **Interner Zustand**:
    - Der Agent kann zusätzlich einen internen Zustand haben, der seine Entscheidungen beeinflusst.
    - Ermöglicht **Gedächtnis** oder **Lernfähigkeit**.
  - **Seiteneffekte und Zustandsänderungen**:
    - In der Praxis haben Aktionen Auswirkungen auf die Umwelt, was zu neuen Observationen führt.
    - Diese Wechselwirkung ist zentral für die Dynamik zwischen Agent und Umwelt.

## Ziele von Agenten

### Warum sind Ziele wichtig?

- **Notwendigkeit von Zielen**:
  - Ohne Ziele fehlt dem Agenten die **Richtung** oder **Motivation** für sein Handeln.
  - Ziele definieren, **was erreicht werden soll**, und ermöglichen zielgerichtetes Verhalten.
- **Funktion von Zielen**:
  - **Orientierung**: Helfen dem Agenten, Entscheidungen zu treffen, die auf ein gewünschtes Ergebnis hinarbeiten.
  - **Bewertung**: Ermöglichen die Beurteilung, ob ein Verhalten erfolgreich oder optimal ist.
- **Beispiel**:
  - Ein Agent in der Vacuum World ohne das Ziel, die Räume sauber zu halten, könnte zufällig handeln.
  - Mit dem Ziel der **Reinigung** wird sein Verhalten darauf ausgerichtet, Schmutz zu beseitigen.

### Verschiedene Arten von Zielen

#### Klasse 0: Keine Ziele (No Goals)

- **Beschreibung**:
  - Agenten agieren ohne explizit vorgegebene Ziele.
  - Verhalten kann **zufällig** oder **starr programmiert** sein.
- **Anwendungsfälle**:
  - **Full Autonomy**:
    - Erforschung von Agenten, die ohne externe Vorgaben agieren.
    - Untersuchung, ob Agenten **eigene Ziele** oder **Motivationen** entwickeln können.
  - **Self-Organization**:
    - Systeme, die von selbst **Strukturen** oder **Muster** bilden.
    - Beispiele aus der Natur: Bildung von Kristallen, Wachstum von Pflanzen.
  - **Open-Endedness**:
    - Agenten agieren in einer Umgebung ohne definiertes Endziel.
    - Ziel ist es, **komplexes Verhalten** und **ständige Anpassung** zu beobachten.
- **Diskussion**:
  - **Philosophische Aspekte**:
    - Kann ein System wirklich intelligent sein ohne Ziele?
    - Unterscheidung zwischen **intrinsischer Motivation** und externen Zielen.
  - **Praktische Relevanz**:
    - Nützlich für die Grundlagenforschung, aber weniger für zielgerichtete Anwendungen.

#### Klasse 1: Goal Predicates

- **Beschreibung**:
  - Ziele werden durch ein **Prädikat** definiert, das **wahr** wird, wenn das Ziel erreicht ist.
  - Der Agent erhält **keine Informationen** darüber, wie er das Ziel erreichen kann.
- **Definition**:
  - **Goal Predicate (`γ`)**:
    - Funktion `γ: Π → {true, false}`, wobei `Π` die Menge aller möglichen Policies `π` ist.
    - `γ(π) = true`, wenn die Policy das Ziel erfüllt.
- **Beispiel**:
  - **Labyrinth**:
    - Ziel ist es, den Ausgang zu finden.
    - Das Prädikat `γ` wird `true`, wenn der Agent eine Policy hat, die zum Ausgang führt.
  - **Puzzle lösen**:
    - Ziel ist es, ein Puzzle korrekt zu lösen.
    - Das Prädikat überprüft, ob die Endkonfiguration korrekt ist.
- **Anwendung**:
  - **Suchprobleme**:
    - Der Agent muss den **Raum der möglichen Aktionen** durchsuchen, um eine erfolgreiche Policy zu finden.
  - **Heuristiken**:
    - Ohne Hinweise muss der Agent möglicherweise **Heuristiken** verwenden, um effizient zu suchen.
- **Herausforderungen**:
  - **Keine graduellen Feedbacks**:
    - Der Agent erhält nur am Ende eine Erfolgsmeldung, keine Zwischenbewertungen.
  - **Komplexität**:
    - In großen Räumen kann die Suche nach einer erfolgreichen Policy sehr aufwändig sein.
  - **Effizienz**:
    - Ohne Hinweise kann viel Rechenzeit auf unwichtige Pfade verschwendet werden.

## Zusammenfassung

- **Agentenmodell**:
  - Bietet ein **universelles Framework** zur Modellierung intelligenter Systeme.
  - Ermöglicht die **Analyse** und **Gestaltung** von Agenten in verschiedenen Umgebungen.
- **Wichtigkeit von Zielen**:
  - **Ziele** sind entscheidend, um Agenten zu **zielgerichtetem Verhalten** zu bewegen.
  - Unterschiedliche **Zieltypen** beeinflussen die Art und Weise, wie Agenten lernen und handeln.
- **Weiterführende Themen**:
  - **Optimierung von Policies**:
    - Finden von Strategien, die nicht nur erfolgreich, sondern auch effizient sind.
  - **Lernalgorithmen**:
    - Einsatz von Methoden wie **Reinforcement Learning**, um aus Erfahrungen zu lernen.
  - **Belohnungsfunktionen**:
    - Einführung von **graduellen Feedbacks**, um den Lernprozess zu steuern.
  - **Komplexere Zielsetzungen**:
    - Kombination mehrerer Ziele, Priorisierung oder dynamische Anpassung von Zielen.
  - **Ethik und Sicherheit**:
    - Berücksichtigung von **ethischen Aspekten** und **Sicherheitsfragen** bei der Gestaltung von Agenten.

---

Diese erweiterte stichpunktartige Zusammenfassung bietet zusätzliche Erklärungen und Beispiele zu den wichtigsten Punkten der Vorlesung. Sie ist speziell für Informatikstudenten zum Lernen gedacht und soll ein tieferes Verständnis der behandelten Themen fördern, ohne dabei erschöpfend zu sein.

---

<!-- DISQUS SCRIPT COMMENT START -->

<!-- DISQUS RECOMMENDATION START -->

<div id="disqus_recommendations"></div>

<script> 
(function() { // REQUIRED CONFIGURATION VARIABLE: EDIT THE SHORTNAME BELOW
var d = document, s = d.createElement('script'); // IMPORTANT: Replace EXAMPLE with your forum shortname!
s.src = 'https://myuninotes.disqus.com/recommendations.js'; s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>
Please enable JavaScript to view the 
<a href="https://disqus.com/?ref_noscript" rel="nofollow">
comments powered by Disqus.
</a>
</noscript>

<!-- DISQUS RECOMMENDATION END -->

<hr style="border: none; height: 2px; background: linear-gradient(to right, #f0f0f0, #ccc, #f0f0f0); margin-top: 4rem; margin-bottom: 5rem;">
<div id="disqus_thread"></div>
<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://myuninotes.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

<!-- DISQUS SCRIPT COMMENT END -->
