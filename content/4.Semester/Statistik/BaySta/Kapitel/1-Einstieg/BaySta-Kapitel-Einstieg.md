---
tags:
  - 4semester
  - BaySta
  - statistik
fach: "[[BaySta]]"
Thema:
  - "[[Priori und Posteriori Wahrscheinlichkeit]]"
date created: Wednesday, 24. April 2024, 21:17
date modified: Sunday, 14. July 2024, 13:29
---

# Kurze Wiederholung der Theorie der Wahrscheinlichkeit

## Wahrscheinlichkeiten

Dieses Kapitel gibt eine kurze Einf√ºhrung bzw. Wiederholung in die Theorie der Wahrscheinlichkeit.

Wir interessieren uns (vorerst) f√ºr _zuf√§llige Ergebnisse_ in einem Ergebnisraum $Œ©$. Jedem _Ereignis_ $A‚äÜŒ©$ kann eine _Wahrscheinlichkeit_ $ùëÉ(ùê¥)$ zugeordnet werden, f√ºr die die Axiome von Kolmogorov gelten:

- $0 ‚â§ P(A) ‚â§ 1$ (Wahrscheinlichkeiten liegen zwischen 0 und 1)
- F√ºr das sichere Ereignis $Œ©$ gilt: $P(Œ©) = 1$ (irgendein Ergebnis aus $Œ©$ tritt sicher ein)
- F√ºr beliebige disjunkte (nicht √ºberschneidende) Ereignisse $A$ und $B$ gilt $P(A ‚à™ B) = P(A) + P(B)$ (die Wahrscheinlichkeit, dass $A$ _oder_ $B$ eintritt ist Summe der einzelnen Wahrscheinlichkeiten, wenn beide nicht gleichzeitig eintreten k√∂nnen)

Beispiel: Wir interessieren uns f√ºr das zuf√§llige Ereignis _Niederschlag am morgigen Tag_. Unser Ergebnisraum sei: $Œ© = \{"Es regnet", "Es schneit", "Es regnet und schneit nicht"\}$

Ein Ergebnis war dann zum Beispiel $A = \{"Es regnet", "Es schneit"\} = "Es gibt Niederschlag"$. Aus den Axiomen von Kolmogorov folgt:

$$
P(A) = P(\text{"Es regnet"}) + P(\text{"Es schneit"})
$$

### Folgerungen

Daraus folgt direkt:

- Die Wahrscheinlichkeit f√ºr das unm√∂gliche Ereignis $‚àÖ$ (leere Menge) ist: $P(‚àÖ) = 0$
- Die Wahrscheinlichkeit des Gegenereignisses $A$ zu $A$ (d.¬†h. $A$ tritt nicht ein) ist: $P(A') = 1 - P(A)$

### Beispiel: W√ºrfel

Wir werfen einen fairen sechsseitigen W√ºrfel.

Die Annahme ‚Äûfairer W√ºrfel‚Äú entspricht dabei der Annahme, dass jede Seite dieselbe Wahrscheinlichkeit hat. Zum Beispiel gilt f√ºr die Wahrscheinlichkeit des Ereignisses $A$: ‚ÄûEs f√§llt eine 6‚Äú

$$
P(A) = \frac{1}{6}
$$

Oder allgemein:

$$
P(A) = \frac{|A|}{|\Omega|}
$$

Wobei $|A|$ die ‚ÄûM√§chtigkeit‚Äú von $A$, also die Anzahl der Elemente in $A$ ist. Man nennt diese Definition einer Wahrscheinlichkeit auch _Laplace-Wahrscheinlichkeit._

## OddsAlternativ lassen sich Wahrscheinlichkeiten auch als _Odds_ oder _Chance_ darstellen:

### Definition

Die Odds eines Ereignisses $A$ sind definiert als:

$$
\text{Odds}(A) = \frac{P(A)}{P(\bar{A})}
$$

wobei $\bar{A}$ das Gegenereignis zu $A$ ist. Es gilt $P(\bar{A}) = 1 - P(A)$.

Ein Odds von 1 entspricht also einer Wahrscheinlichkeit von 50%.

### Fortsetzung Beispiel: W√ºrfel

Der Odds f√ºr $A$: "Der W√ºrfel zeigt die Zahl 6" ist:

$$
\text{Odds}(A) = \frac{1/6}{5/6} = 1 : 5
$$

Man kennt den Odds auch als Wettquote. Bei einer Wahrscheinlichkeit $P(A) = 1/6$ ist die Wettquote f√ºr das Eintreten von $A$ dementsprechend $5 : 1$. Wettet man auf $A$, erh√§lt man - neben dem Einsatz - das F√ºnffache des Einsatzes zur√ºck, zusammen also das Sechsfache des Einsatzes.

## Interpretation

Der mathematische Begriff _Wahrscheinlichkeit_ kann dabei unterschiedlich interpretiert werden:

- klassisch: Alle Elementarereignisse haben dieselbe Wahrscheinlichkeit (_Laplace-Wahrscheinlichkeit_)
- als relative H√§ufigkeit bei unendlicher Wiederholung (_Frequentistischer Wahrscheinlichkeitsbegriff_)
- subjektiv als Ma√ü f√ºr den Glauben an das Eintreten (_Bayesscher Wahrscheinlichkeitsbegriff_)
- als Eigenschaft eines physikalischen Systems (z.¬†B. _Propensit√§t_ nach Karl Popper)

### Frequentistischer Wahrscheinlichkeitsbegriff

Die Frequentistische Interpretation basiert auf dem _Gesetz der gro√üen Zahlen_:

Wiederholt man ein Experiment, bei dem das Ereignis $A$ mit Wahrscheinlichkeit $P(A)$ eintritt, $n$-mal, dann n√§hert sich die relative H√§ufigkeit

$$
P = \frac{h_n}{n}
$$

mit steigendem $n$ immer mehr dem Wert $P(A)$. Dabei bezeichnet $h_n$ die Anzahl der Experimente, in denen $A$ eingetreten ist.

_Relative H√§ufigkeit einer 6 beim fairen W√ºrfel bei simulierten $n$ Wiederholungen_

(Graphische Darstellung der relativen H√§ufigkeit √ºber die Anzahl der Wiederholungen)

### Bayesscher Wahrscheinlichkeitsbegriff

Der Bayessche Wahrscheinlichkeitsbegriff ist subjektiv. Er versteht Wahrscheinlichkeit als _Grad pers√∂nlicher √úberzeugung_, dass ein Ereignis eintritt.

Dieser Grad l√§sst sich z.B. dadurch messen, wieviel man darauf wetten w√ºrde, dass ein Ereignis eintritt (welchen _Odds_ man geben w√ºrde). Bei einem fairen W√ºrfel w√ºrde man f√ºr das W√ºrfeln der 6 z.B. einen Odds von 5:1 geben.

Die pers√∂nliche √úberzeugung wird dabei durch Informationen gebildet. Das kann z.B. das Wissen sein, dass ein industriell gefertigter W√ºrfel in der Regel fair ist (_Vorwissen_). Alternativ kann das Wissen auch durch Beobachtung (_Daten_) entstehen, z.B. in dem man die relative H√§ufigkeit bei n Wiederholungen betrachtet.

Der Bayessche Wahrscheinlichkeitsbegriff ist nicht notwendig f√ºr die Benutzung Bayesischer Statistik. Aber er verdeutlicht schon einen ersten Aspekt der Bayesischen Statistik:

_Wahrscheinlichkeit_ entspricht _Wissen_ gleich _Information_.

## Verteilung und Zufallsvariablen

### Verteilung

Wenn wir f√ºr jedes m√∂gliche Ereignis $A \subseteq \Omega$ die Wahrscheinlichkeit $P(A)$ definieren, sprechen wir insgesamt von einer _Verteilung_.

Im Beispiel des fairen W√ºrfels haben wir eine _Gleich-Verteilung_ angenommen; jedes gleichgro√üe Ereignis $A$ hat die selbe Wahrscheinlichkeit.

### Zufallsvariablen

Unter einer Zufallsvariablen verstehen wir die Zuordnung von Zahlen, zu jedem m√∂glichen Ereignis zuordnen. Tritt ein Ereignis ein, dann sprechen wir von der _Realisation_ der Zufallsvariable.

### Beispiel W√ºrfel

- Ereignis $A_1$: "Die Seite mit einem Auge liegt oben"
- Ereignis $A_2$: "Die Seite mit zwei Augen liegt oben"
- Ereignis $A_3$: "Die Seite mit drei Augen liegt oben"
- Ereignis $A_4$: "Die Seite mit vier Augen liegt oben"
- Ereignis $A_5$: "Die Seite mit f√ºnf Augen liegt oben"
- Ereignis $A_6$: "Die Seite mit sechs Augen liegt oben"

Sei die Zufallsvariable $X$ "Anzahl der Augen", dann gilt f√ºr alle $i = 1, \ldots, 6$:

- tritt $A_i$ ein, dann ist $X = i$

Damit lassen sich auch f√ºr Zufallsvariablen Wahrscheinlichkeiten und damit Verteilungen definieren:

- $P(X = 1) = P(A_1) = \frac{1}{6}$
- $P(X > 5) = P(A_5) + P(A_6) = \frac{1}{3}$

### Verteilung einer Zufallsvariablen

Die Verteilung einer Zufallsvariablen wird dadurch spezifiziert, dass alle Wahrscheinlichkeiten f√ºr alle m√∂glichen Realisationen angegeben werden.

### Binomialverteilung

Sei $Y$ die Zufallsvariable "Bei $n$-maligen W√ºrfeln wir $y$-mal die 6 gew√ºrfelt. Dann ist $Y$ _Binomialverteilt_, wir schreiben $Y \sim B(n,p)$, und es gilt f√ºr $0 \leq y \leq n$

$$
P(Y = y) = \binom{n}{y}p^y(1 - p)^{n-y}
$$

wobei hier $p = \frac{1}{6}$.

# Bedingten Wahrscheinlichkeiten

## Unabh√§ngigkeit

Ein wichtiges Grundkonzept von zuf√§lligen Ereignissen ist die Unabh√§ngigkeit, dass also das Eintreten eines Ereignisses $A$ nicht das Eintreten eines anderen Ereignisses $B$ beeinflusst.

Interessanter ist in der Regel die Abh√§ngigkeit von Ereignissen. In diesem Fall √§ndert sich die Wahrscheinlichkeit f√ºr das Eintreten von $B$ durch das Eintreten von $A$. Bayesisch betrachtet gewinnen wir durch das Eintreten von $A$ Information √ºber das Eintreten von $B$.

### Stochastische Unabh√§ngigkeit

Zwei Ereignisse hei√üen _stochastisch unabh√§ngig_, wenn gilt:

$$
P(A \cap B) = P(A) \cdot P(B)
$$

Dabei meint $A \cap B$, dass beide Ereignisse eintreten.

Zwei Zufallsvariablen hei√üen _stochastisch unabh√§ngig_, wenn gilt:

$$
P(X = x, Y = y) = P(X = x) \cdot P(Y = y)
$$

f√ºr alle m√∂glichen Werte von $x$ und $y$. Dabei meint $X = x, Y = y$, dass beide Ereignisse eintreten, also dass $X$ den Wert $x$ annimmt und $Y$ den Wert $y$.

#### Beispiel: Fairer W√ºrfel

Sei $A$: "Es f√§llt eine 5 oder 6", $B$: "Es f√§llt eine gerade Zahl". Dann ist $A \cap B$: "Es f√§llt eine 6". Es gilt:

$$
P(A) \cdot P(B) = \frac{1}{3} \cdot \frac{1}{2} = \frac{1}{6} = P(A \cap B)
$$

Die beiden Ereignisse sind also voneinander unabh√§ngig!

Wir nennen

- $P(A \cap B)$ gemeinsame Wahrscheinlichkeit
- $P(A)$ bzw. $P(B)$ Rand- oder marginale Wahrscheinlichkeit

## Satz von Bayes

Aus der Definition der bedingten Wahrscheinlichkeit $P(A|B)$ ergeben sich folgende Zusammenh√§nge:

$$
P(A \cap B) = P(A|B) \cdot P(B)
$$

$$
P(A \cap B) = P(B|A) \cdot P(A)
$$

Daraus folgt, dass

$$
P(A|B) \cdot P(B) = P(B|A) \cdot P(A)
$$

und somit der _Satz von Bayes_:

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
$$

### Satz von der totalen Wahrscheinlichkeit

$P(B)$ k√∂nnen wir dabei mit dem _Satz von der totalen Wahrscheinlichkeit_ berechnen:

$$
P(B) = P(B \cap A) + P(B \cap \bar{A}) = P(B|A) \cdot P(A) + P(B|\bar{A}) \cdot P(\bar{A})
$$

Wir erhalten eine weitere Version des Satzes von Bayes:

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B|A) \cdot P(A) + P(B|\bar{A}) \cdot P(\bar{A})}
$$

### Beispiel: unfairer W√ºrfel?

Als erstes Beispiel √ºberlegen wir uns folgende Situation. Ein Bekannter von Ihnen besitzt zwei identische aussehende W√ºrfel. Einer davon ist fair, einer W√ºrfel immer die 6. Der Bekannte w√ºrfelt mit einem der beiden W√ºrfel, es f√§llt die sechs. Ist das nun der unfaire W√ºrfel?

Wir definieren uns folgende Ereignisse und Wahrscheinlichkeiten:

- Ereignis $A$: Der W√ºrfel ist fair.
- Ereignis $B$: Eine 6 f√§llt.

Die Wahrscheinlichkeit von $B$ h√§ngt von $A$ ab!

- $A$: W√ºrfel ist fair; $\rightarrow P(B|A) = 1/6$
- $\bar{A}$: W√ºrfel ist unfair; $\rightarrow P(B|\bar{A}) = 1$

Nach Laplace gehen wir au√üerdem von $P(A) = 1/2$ aus; sprich: Der Bekannte hat zuf√§llig einen W√ºrfel ausgew√§hlt. (Das ist eine Vornahme oder _Vorwissen_. Sie kennen den Bekannten besser, k√∂nnen diese Wahrscheinlichkeit vielleicht besser einsch√§tzen.)

#### Anwendung des Satz von Bayes

Dann gilt mit dem Satz von Bayes:

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B|A) \cdot P(A) + P(B|\bar{A}) \cdot P(\bar{A})}
$$

$$
= \frac{\frac{1}{6} \cdot \frac{1}{2}}{\frac{1}{6} \cdot \frac{1}{2} + 1 \cdot \frac{1}{2}}
$$

$$
= \frac{1}{\frac{1}{6} \cdot \frac{1}{2} + \frac{5}{6} \cdot \frac{1}{2}}
$$

$$
= \frac{1}{\frac{1}{6} \cdot 1 + \frac{5}{6} \cdot 1}
$$

$$
= \frac{1}{\frac{1}{6} + \frac{5}{6}}
$$

$$
= \frac{1}{1} = 1
$$

So erhalten wir $P(A|B) = 1$, was bedeutet, dass unter der Bedingung, dass B eingetreten ist, das Ereignis A mit Sicherheit stattfindet.

# Quiz zur Wahrscheinlichkeit

## Aufgabe 1

> [!faq] Auf einem Campus gibt es 250 Mathematik-Studierende und 750 Soziologie-Studierenden. Sie begegnen zuf√§llig einer Person auf dem Campus. Ohne weiteres Wissen, wie gro√ü ist die Wahrscheinlichkeit, dass die Person Mathematik studiert?
>
> - 0.5
> - 0.25
> - 5
> - 25
> - 0
>   > [!success]- L√∂sung
>   > 0.25

## Aufgabe 2

> [!faq] Sie wissen, dass 50 der Mathematik-Studierenden weiblich sind. Sie begegnen zuf√§llig einer Person auf dem Campus. Wie gro√ü ist die Wahrscheinlichkeit, dass es sich um eine Mathematikerin handelt?
>
> - 0.5
> - 0
> - 0.25
> - 0.05
>   > [!success]- L√∂sung
>   > 0.05

> [!faq] Sie begegnen auf dem Campus zuf√§llig einer Person, die Mathematik studiert. Wie gro√ü ist die Wahrscheinlichkeit, dass diese weiblich ist?
>
> - 0.25
> - 0.05
> - 0.5
> - 0.2
> - 0
>   > [!success]- L√∂sung
>   > 0.2

> [!faq] Dabei handelt es sich um eine:
>
> - marginale Wahrscheinlichkeit
> - bedingte Wahrscheinlichkeit
> - inverse Wahrscheinlichkeit
>   > [!success]- L√∂sung
>   > bedingte Wahrscheinlichkeit

## Frage 3

> [!faq] Sie wissen, dass 450 der Soziologie-Studierenden weiblich sind. Sie begegnen zuf√§llig einer Person auf dem Campus. Wie gro√ü ist die Wahrscheinlichkeit, dass es sich um eine Soziologin handelt?
>
> - 0.05
> - 0.6
> - 0.75
> - 0.45
>   > [!success]- L√∂sung
>   > 0.6

> [!faq] Sie begegnen zuf√§llig einer Person auf dem Campus. Wie gro√ü ist die Wahrscheinlichkeit, dass diese Person weiblich ist?
>
> - 0.75
> - 0.05
> - 0.45
> - 0.5
>   > [!success]- L√∂sung
>   > 0.5

> [!faq] Dabei handelt es sich um eine:
>
> - bedingte Wahrscheinlichkeit
> - marginale Wahrscheinlichkeit
> - inverse Wahrscheinlichkeit
>   > [!success]- L√∂sung
>   > marginale Wahrscheinlichkeit

## Frage 4

> [!faq] Sie begegnen zuf√§llig einer weiblichen Person auf dem Campus. Wie gro√ü ist die Wahrscheinlichkeit, dass es sich um eine Mathematikerin handelt?
>
> - 0.5
> - 0.25
> - 0.75
> - 0.1
>   > [!success]- L√∂sung
>   > 0.1

> [!faq] Um das zu berechnen, benutzen wir den:
>
> - Satz von Gauss
> - Satz von Bayes
> - Satz von Pythagoras
>   > [!success]- L√∂sung
>   > Satz von Bayes

# Der Satz von Bayes

## Beispiel

Ein einfaches Beispiel soll die Wirkungsweise des Satz von Bayes verdeutlichen:

### Medizinischer Test

Ein medizinischer Test soll das Vorliegen einer Krankheit feststellen. Solche Tests sind nicht ganz fehlerfrei, es kommt zu falsch positiven und falsch negativen Ergebnissen.

Wir definieren uns folgende Ereignisse:

- $A$: Eine Person ist krank
- $B$: Der Test zeigt ein positives Ergebnis

Der Test wird durchgef√ºhrt, wenn gewisse Symptome auftreten. Aus Erfahrung wei√ü man, dass 2% derjenigen, die den Test machen, wirklich die Krankheit haben. Bevor jemand den Test macht, nehmen wir also an, dass sie Wahrscheinlichkeit f√ºr $A$ 2% ist. Wir nennen diese auch _Priori-Wahrscheinlichkeit_ - Wahrscheinlichkeit vor der Beobachtung (lateinisch _a priori_, etwa "von vorher"):

- $P(A) = 0.02$ (Wahrscheinlichkeit, die Krankheit zu haben)
- $P(\bar{A}) = 0.98$ (Wahrscheinlichkeit, die Krankheit nicht zu haben)

Liegt die Krankheit vor, zeigt der Test in 95% der F√§lle ein (korrektes) positives Ergebnis, in 5% der F√§lle ein (falsches) negatives Ergebnis:

- $P(B|A) = 0.95$ (korrekt positiv)
- $P(B|\bar{A}) = 0.05$ (falsch negativ)

Liegt keine Krankheit vor, zeigt der Test in 90% der F√§lle ein (korrektes) negatives Ergebnis, in 10% der F√§lle ein (falsches) positives Ergebnis:

- $P(\bar{B}|A) = 0.9$ (korrekt negativ)
- $P(\bar{B}|\bar{A}) = 0.1$ (falsch positiv)

Die Annahmen √ºber die Wahrscheinlichkeit von $B$ gegeben $A$ nennen wir _Modell-Annahmen_. Ihnen liegt ein stochastisches Modell zugrunde, hier die _Bernoulli-Verteilung_ (Binomial-Verteilung mit $n = 1$).

### Fragestellung

Frage: Wie gro√ü ist die Wahrscheinlichkeit, krank zu sein, wenn der Test positiv ausf√§llt?

Wir nennen diese gesuchte Wahrscheinlichkeit die _Posteriori-Wahrscheinlichkeit_, von lateinisch _a posteriori_, etwa "von nachher".

F√ºr die Beantwortung dieser Frage brauchen wir den _Satz von Bayes_.

## Der Satz von Bayes

Der Satz von Bayes erm√∂glicht es uns, die bedingte Wahrscheinlichkeit "umzudrehen" (bis ins 20. Jahrhundert sprach man auch von _inverser Wahrscheinlichkeit_). Wir wissen die bedingte Wahrscheinlichkeit eines Ereignisses $B$ gegeben das Ereignis $A$ eingetreten ist. Daraus k√∂nnen wir schlie√üen, wie die Wahrscheinlichkeit des Ereignisses $A$ gegeben das Ereignis $B$ eingetreten ist.

Der Satz von Bayes lautet in der einfachsten Form

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
$$

oder auch:

$$
\text{Posteriori} = \frac{\text{Bedingte Wahrscheinlichkeit d. Beobachtung} \cdot \text{Priori}}{\text{Marginale Wahrscheinlichkeit d. Beobachtung}}
$$

Wenn wir $P(B)$ nicht kennen, k√∂nnen wir die Wahrscheinlichkeit wie folgt √ºber die bedingten Wahrscheinlichkeiten berechnen. Zusammengenommen lautet der Satz von Bayes dann:

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B|A)P(A) + P(B|\bar{A})P(\bar{A})}
$$

## Medizinischer Test

Zur√ºck zum Beispiel medizinischer Test. Unsere Frage war: Wie gro√ü ist die Wahrscheinlichkeit, krank zu sein, wenn der Test positiv ausf√§llt?

### Priori-Annahmen:

- $P(A) = 0.02$ (Person ist krank)
- $P(\bar{A}) = 0.98$ (Person ist gesund)

### Modell-Annahmen

- $P(B|A) = 0.95$ (richtig positiv)
- $P(B|\bar{A}) = 0.05$ (falsch negativ)
- $P(\bar{B}|A) = 0.9$ (richtig negativ)
- $P(\bar{B}|\bar{A}) = 0.1$ (falsch positiv)

Wir setzen die Priori-Wahrscheinlichkeit $P(A)$ und die bedingten Wahrscheinlichkeiten $P(B|A)$ und $P(B|\bar{A})$ in den Satz von Bayes ein:

$$
\begin{aligned}
P(A|B) &= \frac{P(B|A) \cdot P(A)}{P(B|A)P(A) + P(B|\bar{A})P(\bar{A})} \\
&= \frac{0.95 \cdot 0.02}{0.95 \cdot 0.02 + 0.05 \cdot 0.98} \\
&= \frac{0.019}{0.019 + 0.049} \\
&= 0.162‚Ä¶
\end{aligned}
$$

### Interpretation

Nach Beobachtung des positiven Testergebnisses ist also die Wahrscheinlichkeit, dass die Person krank ist etwa 16,2%. Aus unserer Priori-Wahrscheinlichkeit wurde durch die Beobachtung die Posteriori-Wahrscheinlichkeit.

Die Posteriori-Wahrscheinlichkeit $P(A|B)$ ist hier relativ gering, weil schon die Priori-Wahrscheinlichkeit $P(A)$ sehr gering war.

Auch der Effekt eines negativen Tests l√§sst sich berechnen:

$$
\begin{aligned}
P(A|\bar{B}) &= \frac{P(\bar{B}|A) \cdot P(A)}{P(\bar{B}|A)P(A) + P(\bar{B}|\bar{A})P(\bar{A})} \\
&= \frac{0.9 \cdot 0.02}{0.9 \cdot 0.02 + 0.1 \cdot 0.98} \\
&= \frac{0.018}{0.018 + 0.098} \\
&= 0.155‚Ä¶
\end{aligned}
$$

Ist der Test also negativ, ist die Wahrscheinlichkeit, dass die Person krank ist, bei etwa 15,5%. Praktisch k√∂nnen wir in diesem Fall also mit gro√üer Wahrscheinlichkeit ausschlie√üen, dass die Person Krankheit hat.

Im Kontext des medizinischen Tests ben√∂tigen wir $P(B|\bar{A})P(\bar{A})$ im Nenner der Bayes-Formel, weil wir nicht nur die Wahrscheinlichkeit ber√ºcksichtigen wollen, dass eine kranke Person positiv getestet wird, sondern auch die Wahrscheinlichkeit, dass eine gesunde Person f√§lschlicherweise positiv getestet wird.

Der Term $P(B|A)P(A)$ gibt uns die Wahrscheinlichkeit, dass jemand, der krank ist, auch einen positiven Test hat, w√§hrend $P(B|\bar{A})P(\bar{A})$ die Wahrscheinlichkeit darstellt, dass jemand, der nicht krank ist, dennoch ein positives Testergebnis erh√§lt. Ohne diesen zweiten Term w√ºrden wir die H√§ufigkeit von falsch positiven Ergebnissen im Bezug auf die gesamte Population ignorieren, was zu einer √úbersch√§tzung der tats√§chlichen Wahrscheinlichkeit f√ºhren w√ºrde, dass eine Person mit einem positiven Test tats√§chlich krank ist. Der Satz von Bayes ber√ºcksichtigt beide Aspekte, um ein umfassendes Bild der Posteriori-Wahrscheinlichkeit zu geben.

## Bemerkungen

- **Priori-Wahrscheinlichkeit** ($P(A)$) gleich 0, dann ist auch die **Posteriori-Wahrscheinlichkeit** unabh√§ngig vom Modell immer gleich 0 - wir schlie√üen ja schon **a priori** aus, dass die Person krank ist.

- Ist die **Priori-Wahrscheinlichkeit** gleich 1, dann ist auch die **Posteriori-Wahrscheinlichkeit** unabh√§ngig vom Modell immer gleich 1 - wir sind ja schon **a priori** sicher, dass die Person krank ist.

- Ist die Wahrscheinlichkeit f√ºr einen **falsch positiven Test** gleich 0, dann ist die **Posteriori-Wahrscheinlichkeit** bei positivem Test gleich 1.

- Ist die Wahrscheinlichkeit f√ºr den **falsch positiven Test** und die Wahrscheinlichkeit f√ºr einen **richtig positiven Test** jeweils gleich 0.5, dann ist die **Posteriori-Wahrscheinlichkeit** gleich der **Priori-Wahrscheinlichkeit** - der Test sagt dann ja nicht aus, das Testergebnis ($B$) ist stochastisch unabh√§ngig von $A$.

- Mit gr√∂√üerer **Priori-Wahrscheinlichkeit** ist auch die **Posteriori-Wahrscheinlichkeit** gr√∂√üer - wir "**glauben**" ja schon vorher eher daran, dass die Person krank ist.

- Bei **positivem Testergebnis** ist die **Posteriori-Wahrscheinlichkeit** gr√∂√üer (oder gleich) als die **Priori-Wahrscheinlichkeit** - die Beobachtung des Testergebnisses "**dr√ºckt**" die Wahrscheinlichkeit also in eine Richtung; wir **lernen** aus der Beobachtung.

- Analog ist bei **negativem Testergebnis** die **Posteriori-Wahrscheinlichkeit** kleiner (oder gleich) als die **Priori-Wahrscheinlichkeit**.

- F√ºr "**schlechte Test**" (also geringe Wahrscheinlichkeit f√ºr **richtig positiven Test** oder hohe Wahrscheinlichkeit f√ºr **falsch positive Tests**) ist der Unterschied zwischen **Priori-** und **Posteriori-Wahrscheinlichkeit** geringer - wir **lernen** weniger aus der Beobachtung.

# Bayesianisches Lernen

> [!summary] Zusammenfassung
> In der Anwendung des Satzes von Bayes auf medizinische Tests und Qualit√§tskontrolle lernen wir, wie man anhand von Daten Wahrscheinlichkeiten aktualisiert. Im medizinischen Kontext helfen uns _a priori_ und _a posteriori_ Wahrscheinlichkeiten zu verstehen, wie sich die Einsch√§tzung der Krankheitswahrscheinlichkeit eines Patienten nach einem Testergebnis √§ndert. In der Qualit√§tskontrolle nutzen wir den Satz von Bayes, um die Wahrscheinlichkeit zu bestimmen, dass ein Produkt von einer bestimmten Firma stammt, basierend auf der Anzahl der gefundenen Ausschussst√ºcke. Diese fortgeschrittenen Bayesianischen Methoden erm√∂glichen es uns, unsere Sch√§tzungen zu verfeinern und zu verbessern, w√§hrend wir mehr Daten sammeln, und illustrieren die dynamische Natur von Wahrscheinlichkeiten in der statistischen Inferenz.

Der Satz von Bayes hilft also, aus $B$ f√ºr $A$ zu lernen. Beim Beispiel "medizinischer Test" war

- _a priori_, also vor dem Test die Wahrscheinlichkeit, dass der Patient krank ist, bei 2%,
- _a Posteriori_, also nach positivem Testergebnis, lag die Wahrscheinlichkeit, dass der Patient krank ist, bei 16,2%.

Durch die Beobachtung (des Testergebnisses) haben wir Wissen (Information) hinzugewonnen. Information wird durch eine Wahrscheinlichkeitsverteilung ausgedr√ºckt.

Wir k√∂nnen allerdings nur dann Wissen hinzugewinnen, wenn $A$ und $B$ nicht (stochastisch) unabh√§ngig sind. Sind $A$ und $B$ unabh√§ngig, gilt n√§mlich

$$
P(A \cap B) = P(A)P(B)
$$

und nach Definition der bedingten Wahrscheinlichkeit

$$
P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{P(A)P(B)}{P(B)} = P(A)
$$

Das hei√üt, das Eintreten (oder Nicht-Eintreten) von $B$ √§ndert die Wahrscheinlichkeit von $A$ nicht, liefert also keine Information √ºber $A$.

## Qualit√§tskontrolle

Wir sehen uns ein weiteres Beispiel aus der Qualit√§tskontrolle an:

In einer Fabrik werden Vorprodukte von zwei verschiedenen Firmen (A Productions und B-warez) weiterverarbeitet. Dabei stammen 70% der Vorprodukte von Firma A und 30% von Firma B. Aus langj√§hriger Erfahrung wissen die Arbeiter der Fabrik:

- Die Ausschussquoten betragen 1% bei Firma A und 5% bei Firma B.

Die Arbeiter finden eine neutrale Kiste des Vorprodukts (mit sehr vielen Teilen) ohne weitere Information √ºber den Hersteller. Sie kontrollieren $n = 100$ St√ºck und entdecken $y$ Ausschussst√ºcke. Ist aus diesem Ergebnis ein R√ºckschluss auf den Produzenten m√∂glich?

Sei also:

- Ereignis $A$: Los kommt von Firma A Productions
- Zufallsvariable $Y$: "Anzahl der Ausschussst√ºcke" bei $n = 100$

F√ºr unsere Beobachtung k√∂nnen wir eine Verteilung angeben, die jedoch vom Eintreten von $A$ abh√§ngt. Es handelt sich um eine Binomial-Verteilung mit $n = 100$, wobei die Wahrscheinlichkeit des Eintretens von $A$ abh√§ngt:

- Ist $A$ eingetreten, also die Kiste kommt von Firma A, dann ist die Wahrscheinlichkeit f√ºr die Produktion eines Ausschussst√ºckes $p_A = 0.01$
- Ist dagegen $\bar{A}$ eingetreten, also die Kiste kommt aus Firma B, dann ist die Wahrscheinlichkeit $p_B = 0.05$

Bemerkung: Eigentlich wird hier Ziehen ohne Zur√ºcklegen gemacht, sprich wir m√ºssten die Hypergeometrische Verteilung benutzen. Da wir aber keine Angabe √ºber die Anzahl der Teile in der Kiste haben (nur "sehr viele"), nehmen wir die Binomialverteilung als Ann√§herung.

Dementsprechend ergibt sich die bedingte Verteilung bzw. Datenverteilung von $Y$:

$$
Y|A \sim B(n, p_A)
$$

$$
Y|\bar{A} \sim B(n, p_B)
$$

mit der Wahrscheinlichkeit der Binomialverteilung:

$$
P(Y = y|A) = \binom{n}{y} p_A^y (1 - p_A)^{n-y}
$$

## Satz von Bayes

Der Satz von Bayes l√§sst sich analog wie zuvor anwenden:

$$
P(A|Y = y) = \frac{P(Y = y|A) \cdot P(A)}{P(Y = y)}
$$

## Posteriori-Wahrscheinlichkeiten

Es ergeben sich folgende Posteriori-Wahrscheinlichkeiten:

| y                  | 0     | 1     | 2     | 3     | 4     | 5     | 6     |
| ------------------ | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| P(A &#124; Y = y)  | 0.993 | 0.965 | 0.842 | 0.505 | 0.164 | 0.036 | 0.007 |
| P(¬¨A &#124; Y = y) | 0.007 | 0.035 | 0.158 | 0.495 | 0.836 | 0.964 | 0.993 |

Je nach H√∂he von y k√∂nnen wir also mehr oder weniger gut angeben, aus welcher Firma das Los wahrscheinlich kommt.

Bei y = 3 k√∂nnen wir uns nicht wirklich zwischen den Firmen entscheiden, aber die Posteriori-Wahrscheinlichkeit

$$
P(A|Y = y) = 0.505
$$

ist kleiner als unsere urspr√ºngliche Priori-Wahrscheinlichkeit $P(A) = 0.7$.

## Weiter Lernen

In diesem Fall k√∂nnen wir die Posteriori-Wahrscheinlichkeit $P(A|Y = y)$ wiederum als Priori f√ºr eine neue Stichprobe verwenden.

Sei nun:

- Zufallsvariable $Z$: "Anzahl der Ausschussst√ºcke" bei weiteren $n = 100$

Offensichtlich gilt wieder $Z \sim B(n,p)$. Nun l√§sst sich $P(A|Z = z, Y = y)$ wie folgt berechnen:

$$
P(A|Z = z, Y = y) = \frac{P(Z = z|A) \cdot P(A|Y = y)}{P(Z =z)}
$$

Die Wahrscheinlichkeitsverteilung $P(Z = z|A)$ der Daten h√§ngt nicht von $Y$ ab. Als Priori benutzen wir hier die vorherige Posteriori-Wahrscheinlichkeit.

## Neue Posteriori-Wahrscheinlichkeiten

Sehen wir nach den $y = 3$ St√ºcken Ausschuss unter den ersten 100 untersuchten St√ºcken erneut $z$ St√ºcke Ausschuss, so erhalten wir folgende Posteriori-Wahrscheinlichkeiten:

F√ºr $z$ St√ºcke Ausschuss erhalten wir neue Posteriori-Wahrscheinlichkeiten:

$$
P(A | Z = z, Y = y) = \ldots
$$

Zum Beispiel geht bei erneut $z = 3$ Ausschussst√ºcken unsere Tendenz nun klarer in Richtung Firma B.

# Quiz

Bei einem Radrennen wird ein Doping-Test durchgef√ºhrt. Die Firma, die den Test herstellt, gibt an, dass der Test zu 99.5% positiv ausf√§llt, falls ein Sportler gedopt ist. Ist ein Sportler nicht gedopt, so betr√§gt die Wahrscheinlichkeit f√ºr einen positiven Test 1%. Aus Erfahrung sch√§tzt man, dass ein Viertel der Sportler gedopt ist.

Sei¬†$D$¬†die Zufallsvariable:¬†*Der Sportler ist gedopt*¬†und¬†$T$¬†die Zufallsvariable:¬†*Der Test f√§llt positiv aus*.

> [!faq] Welche der folgenden Aussagen sind richtig? (Mehrere Antworten k√∂nnen richtig sein)
>
> - P(D)=0.01
> - P(D¬Ø)=0.75
> - P(D)=0.995
> - P(D¬Ø)=0.995
>   > [!success]- L√∂sung
>   > P(D¬Ø)=0.75

> [!faq] Welche der folgenden Aussagen sind richtig? (Mehrere Antworten k√∂nnen richtig sein)
>
> - P(T|D)=0.995
> - P(T|D¬Ø)=0.01
> - P(T|D)=0.01
> - P(T|D)=0.25
>   > [!success]- L√∂sung
>   > P(T|D)=0.995
>   > P(T|D¬Ø)=0.01

> [!faq] Wie gro√ü ist die Wahrscheinlichkeit, dass der Test positiv ausf√§llt?
>
> - P(T|D)=0.48
> - P(T)=0.48
> - P(T)=0.25625
> - P(T)=0.995
>   > [!success]- L√∂sung
>   > P(T)=0.25625

> [!faq] Wie gro√ü ist die Wahrscheinlichkeit, dass ein Sportler nicht gedopt ist, obwohl der Test positiv ausf√§llt?
>
> - P(D¬Ø|T)‚âà0.168
> - P(D¬Ø|T)‚âà0.039
> - P(D¬Ø|T)‚âà0.029
>   > [!success]- L√∂sung
>   > P(D¬Ø|T)‚âà0.168

> [!faq] Um das zu berechnen, benutzen wir den:
>
> - Satz von Gauss
> - Satz von Bayes
> - Satz von Pythagoras
>   > [!success]- L√∂sung
>   > Satz von Bayes

# N√§chstes Kapitel: [[BaySta-Kapitel-Grundlagen]]

<!-- DISQUS SCRIPT COMMENT START -->

<hr style="border: none; height: 2px; background: linear-gradient(to right, #f0f0f0, #ccc, #f0f0f0); margin-top: 4rem; margin-bottom: 5rem;">
<div id="disqus_thread"></div>
<script>
    /**
    * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://myuninotes.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

<!-- DISQUS SCRIPT COMMENT END -->

<!-- Modal START -->
<div id="myModal" class="modal">
  <div class="modal-content">
    <span id="closeModal" class="close">&times;</span>
    <p class="modal-text">
      <span class="modal-highlight">MyUniNotes is a personal, non-revenue project as I believe in accessible education for everyone.</span> I manage this project alongside my studies, with all materials handwritten by me trying to help others understand challenging concepts.
    </p>
    <p class="modal-text">
      If MyUniNotes has been helpful and you‚Äôd like to support my efforts, <span class="modal-highlight"> you can contribute with a donation: <a class="modal-dono-link" href="https://paypal.me/myuninotes4u">Donate via PayPal</a> :) </span> Your support will help me continue improving the content, but there is no obligation to donate.
    </p>
  </div>
</div>

<script>
  // JavaScript to display the modal on page load
  document.addEventListener('DOMContentLoaded', function() {
    // Generate a random number between 1 and 1
    // Wanted it to load with a adjustable probability for every page load but did not work, as DOM is loaded only once. Therefore now loading it every time website is visited and DOM is loaded.
    const randomNumber = Math.floor(Math.random() * 1) + 1; 
    console.log(randomNumber)
    if (randomNumber === 1) {
      setTimeout(function() {
        const modal = document.getElementById('myModal');
        if (modal) {
          modal.classList.add('show');
        }
      }, 1000); // Adjust the delay as needed

      const closeModal = document.getElementById('closeModal');
      if (closeModal) {
        closeModal.addEventListener('click', function() {
          const modal = document.getElementById('myModal');
          if (modal) {
            modal.classList.remove('show');
          }
        });
      }
    } else {
      // Ensure the modal is hidden if the random number is not 1
      const modal = document.getElementById('myModal');
      if (modal) {
        modal.style.display = 'none';
      }
    }
  });
</script>
<!-- Modal END -->
