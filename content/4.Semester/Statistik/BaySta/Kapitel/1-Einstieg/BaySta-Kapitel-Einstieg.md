---
tags:
  - 4semester
  - BaySta
  - statistik
fach: "[[BaySta]]"
Thema:
  - "[[Priori und Posteriori Wahrscheinlichkeit]]"
date created: Wednesday, 24. April 2024, 21:17
date modified: Sunday, 14. July 2024, 13:29
---

# Kurze Wiederholung der Theorie der Wahrscheinlichkeit

## Wahrscheinlichkeiten

Dieses Kapitel gibt eine kurze EinfÃ¼hrung bzw. Wiederholung in die Theorie der Wahrscheinlichkeit.

Wir interessieren uns (vorerst) fÃ¼r _zufÃ¤llige Ergebnisse_ in einem Ergebnisraum $Î©$. Jedem _Ereignis_ $AâŠ†Î©$ kann eine _Wahrscheinlichkeit_ $ð‘ƒ(ð´)$ zugeordnet werden, fÃ¼r die die Axiome von Kolmogorov gelten:

- $0 â‰¤ P(A) â‰¤ 1$ (Wahrscheinlichkeiten liegen zwischen 0 und 1)
- FÃ¼r das sichere Ereignis $Î©$ gilt: $P(Î©) = 1$ (irgendein Ergebnis aus $Î©$ tritt sicher ein)
- FÃ¼r beliebige disjunkte (nicht Ã¼berschneidende) Ereignisse $A$ und $B$ gilt $P(A âˆª B) = P(A) + P(B)$ (die Wahrscheinlichkeit, dass $A$ _oder_ $B$ eintritt ist Summe der einzelnen Wahrscheinlichkeiten, wenn beide nicht gleichzeitig eintreten kÃ¶nnen)

Beispiel: Wir interessieren uns fÃ¼r das zufÃ¤llige Ereignis _Niederschlag am morgigen Tag_. Unser Ergebnisraum sei: $Î© = \{"Es regnet", "Es schneit", "Es regnet und schneit nicht"\}$

Ein Ergebnis war dann zum Beispiel $A = \{"Es regnet", "Es schneit"\} = "Es gibt Niederschlag"$. Aus den Axiomen von Kolmogorov folgt:

$$
P(A) = P(\text{"Es regnet"}) + P(\text{"Es schneit"})
$$

### Folgerungen

Daraus folgt direkt:

- Die Wahrscheinlichkeit fÃ¼r das unmÃ¶gliche Ereignis $âˆ…$ (leere Menge) ist: $P(âˆ…) = 0$
- Die Wahrscheinlichkeit des Gegenereignisses $A$ zu $A$ (d.Â h. $A$ tritt nicht ein) ist: $P(A') = 1 - P(A)$

### Beispiel: WÃ¼rfel

Wir werfen einen fairen sechsseitigen WÃ¼rfel.

Die Annahme â€žfairer WÃ¼rfelâ€œ entspricht dabei der Annahme, dass jede Seite dieselbe Wahrscheinlichkeit hat. Zum Beispiel gilt fÃ¼r die Wahrscheinlichkeit des Ereignisses $A$: â€žEs fÃ¤llt eine 6â€œ

$$
P(A) = \frac{1}{6}
$$

Oder allgemein:

$$
P(A) = \frac{|A|}{|\Omega|}
$$

Wobei $|A|$ die â€žMÃ¤chtigkeitâ€œ von $A$, also die Anzahl der Elemente in $A$ ist. Man nennt diese Definition einer Wahrscheinlichkeit auch _Laplace-Wahrscheinlichkeit._

## OddsAlternativ lassen sich Wahrscheinlichkeiten auch als _Odds_ oder _Chance_ darstellen:

### Definition

Die Odds eines Ereignisses $A$ sind definiert als:

$$
\text{Odds}(A) = \frac{P(A)}{P(\bar{A})}
$$

wobei $\bar{A}$ das Gegenereignis zu $A$ ist. Es gilt $P(\bar{A}) = 1 - P(A)$.

Ein Odds von 1 entspricht also einer Wahrscheinlichkeit von 50%.

### Fortsetzung Beispiel: WÃ¼rfel

Der Odds fÃ¼r $A$: "Der WÃ¼rfel zeigt die Zahl 6" ist:

$$
\text{Odds}(A) = \frac{1/6}{5/6} = 1 : 5
$$

Man kennt den Odds auch als Wettquote. Bei einer Wahrscheinlichkeit $P(A) = 1/6$ ist die Wettquote fÃ¼r das Eintreten von $A$ dementsprechend $5 : 1$. Wettet man auf $A$, erhÃ¤lt man - neben dem Einsatz - das FÃ¼nffache des Einsatzes zurÃ¼ck, zusammen also das Sechsfache des Einsatzes.

## Interpretation

Der mathematische Begriff _Wahrscheinlichkeit_ kann dabei unterschiedlich interpretiert werden:

- klassisch: Alle Elementarereignisse haben dieselbe Wahrscheinlichkeit (_Laplace-Wahrscheinlichkeit_)
- als relative HÃ¤ufigkeit bei unendlicher Wiederholung (_Frequentistischer Wahrscheinlichkeitsbegriff_)
- subjektiv als MaÃŸ fÃ¼r den Glauben an das Eintreten (_Bayesscher Wahrscheinlichkeitsbegriff_)
- als Eigenschaft eines physikalischen Systems (z.Â B. _PropensitÃ¤t_ nach Karl Popper)

### Frequentistischer Wahrscheinlichkeitsbegriff

Die Frequentistische Interpretation basiert auf dem _Gesetz der groÃŸen Zahlen_:

Wiederholt man ein Experiment, bei dem das Ereignis $A$ mit Wahrscheinlichkeit $P(A)$ eintritt, $n$-mal, dann nÃ¤hert sich die relative HÃ¤ufigkeit

$$
P = \frac{h_n}{n}
$$

mit steigendem $n$ immer mehr dem Wert $P(A)$. Dabei bezeichnet $h_n$ die Anzahl der Experimente, in denen $A$ eingetreten ist.

_Relative HÃ¤ufigkeit einer 6 beim fairen WÃ¼rfel bei simulierten $n$ Wiederholungen_

(Graphische Darstellung der relativen HÃ¤ufigkeit Ã¼ber die Anzahl der Wiederholungen)

### Bayesscher Wahrscheinlichkeitsbegriff

Der Bayessche Wahrscheinlichkeitsbegriff ist subjektiv. Er versteht Wahrscheinlichkeit als _Grad persÃ¶nlicher Ãœberzeugung_, dass ein Ereignis eintritt.

Dieser Grad lÃ¤sst sich z.B. dadurch messen, wieviel man darauf wetten wÃ¼rde, dass ein Ereignis eintritt (welchen _Odds_ man geben wÃ¼rde). Bei einem fairen WÃ¼rfel wÃ¼rde man fÃ¼r das WÃ¼rfeln der 6 z.B. einen Odds von 5:1 geben.

Die persÃ¶nliche Ãœberzeugung wird dabei durch Informationen gebildet. Das kann z.B. das Wissen sein, dass ein industriell gefertigter WÃ¼rfel in der Regel fair ist (_Vorwissen_). Alternativ kann das Wissen auch durch Beobachtung (_Daten_) entstehen, z.B. in dem man die relative HÃ¤ufigkeit bei n Wiederholungen betrachtet.

Der Bayessche Wahrscheinlichkeitsbegriff ist nicht notwendig fÃ¼r die Benutzung Bayesischer Statistik. Aber er verdeutlicht schon einen ersten Aspekt der Bayesischen Statistik:

_Wahrscheinlichkeit_ entspricht _Wissen_ gleich _Information_.

## Verteilung und Zufallsvariablen

### Verteilung

Wenn wir fÃ¼r jedes mÃ¶gliche Ereignis $A \subseteq \Omega$ die Wahrscheinlichkeit $P(A)$ definieren, sprechen wir insgesamt von einer _Verteilung_.

Im Beispiel des fairen WÃ¼rfels haben wir eine _Gleich-Verteilung_ angenommen; jedes gleichgroÃŸe Ereignis $A$ hat die selbe Wahrscheinlichkeit.

### Zufallsvariablen

Unter einer Zufallsvariablen verstehen wir die Zuordnung von Zahlen, zu jedem mÃ¶glichen Ereignis zuordnen. Tritt ein Ereignis ein, dann sprechen wir von der _Realisation_ der Zufallsvariable.

### Beispiel WÃ¼rfel

- Ereignis $A_1$: "Die Seite mit einem Auge liegt oben"
- Ereignis $A_2$: "Die Seite mit zwei Augen liegt oben"
- Ereignis $A_3$: "Die Seite mit drei Augen liegt oben"
- Ereignis $A_4$: "Die Seite mit vier Augen liegt oben"
- Ereignis $A_5$: "Die Seite mit fÃ¼nf Augen liegt oben"
- Ereignis $A_6$: "Die Seite mit sechs Augen liegt oben"

Sei die Zufallsvariable $X$ "Anzahl der Augen", dann gilt fÃ¼r alle $i = 1, \ldots, 6$:

- tritt $A_i$ ein, dann ist $X = i$

Damit lassen sich auch fÃ¼r Zufallsvariablen Wahrscheinlichkeiten und damit Verteilungen definieren:

- $P(X = 1) = P(A_1) = \frac{1}{6}$
- $P(X > 5) = P(A_5) + P(A_6) = \frac{1}{3}$

### Verteilung einer Zufallsvariablen

Die Verteilung einer Zufallsvariablen wird dadurch spezifiziert, dass alle Wahrscheinlichkeiten fÃ¼r alle mÃ¶glichen Realisationen angegeben werden.

### Binomialverteilung

Sei $Y$ die Zufallsvariable "Bei $n$-maligen WÃ¼rfeln wir $y$-mal die 6 gewÃ¼rfelt. Dann ist $Y$ _Binomialverteilt_, wir schreiben $Y \sim B(n,p)$, und es gilt fÃ¼r $0 \leq y \leq n$

$$
P(Y = y) = \binom{n}{y}p^y(1 - p)^{n-y}
$$

wobei hier $p = \frac{1}{6}$.

# Bedingten Wahrscheinlichkeiten

## UnabhÃ¤ngigkeit

Ein wichtiges Grundkonzept von zufÃ¤lligen Ereignissen ist die UnabhÃ¤ngigkeit, dass also das Eintreten eines Ereignisses $A$ nicht das Eintreten eines anderen Ereignisses $B$ beeinflusst.

Interessanter ist in der Regel die AbhÃ¤ngigkeit von Ereignissen. In diesem Fall Ã¤ndert sich die Wahrscheinlichkeit fÃ¼r das Eintreten von $B$ durch das Eintreten von $A$. Bayesisch betrachtet gewinnen wir durch das Eintreten von $A$ Information Ã¼ber das Eintreten von $B$.

### Stochastische UnabhÃ¤ngigkeit

Zwei Ereignisse heiÃŸen _stochastisch unabhÃ¤ngig_, wenn gilt:

$$
P(A \cap B) = P(A) \cdot P(B)
$$

Dabei meint $A \cap B$, dass beide Ereignisse eintreten.

Zwei Zufallsvariablen heiÃŸen _stochastisch unabhÃ¤ngig_, wenn gilt:

$$
P(X = x, Y = y) = P(X = x) \cdot P(Y = y)
$$

fÃ¼r alle mÃ¶glichen Werte von $x$ und $y$. Dabei meint $X = x, Y = y$, dass beide Ereignisse eintreten, also dass $X$ den Wert $x$ annimmt und $Y$ den Wert $y$.

#### Beispiel: Fairer WÃ¼rfel

Sei $A$: "Es fÃ¤llt eine 5 oder 6", $B$: "Es fÃ¤llt eine gerade Zahl". Dann ist $A \cap B$: "Es fÃ¤llt eine 6". Es gilt:

$$
P(A) \cdot P(B) = \frac{1}{3} \cdot \frac{1}{2} = \frac{1}{6} = P(A \cap B)
$$

Die beiden Ereignisse sind also voneinander unabhÃ¤ngig!

Wir nennen

- $P(A \cap B)$ gemeinsame Wahrscheinlichkeit
- $P(A)$ bzw. $P(B)$ Rand- oder marginale Wahrscheinlichkeit

## Satz von Bayes

Aus der Definition der bedingten Wahrscheinlichkeit $P(A|B)$ ergeben sich folgende ZusammenhÃ¤nge:

$$
P(A \cap B) = P(A|B) \cdot P(B)
$$

$$
P(A \cap B) = P(B|A) \cdot P(A)
$$

Daraus folgt, dass

$$
P(A|B) \cdot P(B) = P(B|A) \cdot P(A)
$$

und somit der _Satz von Bayes_:

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
$$

### Satz von der totalen Wahrscheinlichkeit

$P(B)$ kÃ¶nnen wir dabei mit dem _Satz von der totalen Wahrscheinlichkeit_ berechnen:

$$
P(B) = P(B \cap A) + P(B \cap \bar{A}) = P(B|A) \cdot P(A) + P(B|\bar{A}) \cdot P(\bar{A})
$$

Wir erhalten eine weitere Version des Satzes von Bayes:

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B|A) \cdot P(A) + P(B|\bar{A}) \cdot P(\bar{A})}
$$

### Beispiel: unfairer WÃ¼rfel?

Als erstes Beispiel Ã¼berlegen wir uns folgende Situation. Ein Bekannter von Ihnen besitzt zwei identische aussehende WÃ¼rfel. Einer davon ist fair, einer WÃ¼rfel immer die 6. Der Bekannte wÃ¼rfelt mit einem der beiden WÃ¼rfel, es fÃ¤llt die sechs. Ist das nun der unfaire WÃ¼rfel?

Wir definieren uns folgende Ereignisse und Wahrscheinlichkeiten:

- Ereignis $A$: Der WÃ¼rfel ist fair.
- Ereignis $B$: Eine 6 fÃ¤llt.

Die Wahrscheinlichkeit von $B$ hÃ¤ngt von $A$ ab!

- $A$: WÃ¼rfel ist fair; $\rightarrow P(B|A) = 1/6$
- $\bar{A}$: WÃ¼rfel ist unfair; $\rightarrow P(B|\bar{A}) = 1$

Nach Laplace gehen wir auÃŸerdem von $P(A) = 1/2$ aus; sprich: Der Bekannte hat zufÃ¤llig einen WÃ¼rfel ausgewÃ¤hlt. (Das ist eine Vornahme oder _Vorwissen_. Sie kennen den Bekannten besser, kÃ¶nnen diese Wahrscheinlichkeit vielleicht besser einschÃ¤tzen.)

#### Anwendung des Satz von Bayes

Dann gilt mit dem Satz von Bayes:

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B|A) \cdot P(A) + P(B|\bar{A}) \cdot P(\bar{A})}
$$

$$
= \frac{\frac{1}{6} \cdot \frac{1}{2}}{\frac{1}{6} \cdot \frac{1}{2} + 1 \cdot \frac{1}{2}}
$$

$$
= \frac{1}{\frac{1}{6} \cdot \frac{1}{2} + \frac{5}{6} \cdot \frac{1}{2}}
$$

$$
= \frac{1}{\frac{1}{6} \cdot 1 + \frac{5}{6} \cdot 1}
$$

$$
= \frac{1}{\frac{1}{6} + \frac{5}{6}}
$$

$$
= \frac{1}{1} = 1
$$

So erhalten wir $P(A|B) = 1$, was bedeutet, dass unter der Bedingung, dass B eingetreten ist, das Ereignis A mit Sicherheit stattfindet.

# Quiz zur Wahrscheinlichkeit

## Aufgabe 1

> [!faq] Auf einem Campus gibt es 250 Mathematik-Studierende und 750 Soziologie-Studierenden. Sie begegnen zufÃ¤llig einer Person auf dem Campus. Ohne weiteres Wissen, wie groÃŸ ist die Wahrscheinlichkeit, dass die Person Mathematik studiert?
>
> - 0.5
> - 0.25
> - 5
> - 25
> - 0
>   > [!success]- LÃ¶sung
>   > 0.25

## Aufgabe 2

> [!faq] Sie wissen, dass 50 der Mathematik-Studierenden weiblich sind. Sie begegnen zufÃ¤llig einer Person auf dem Campus. Wie groÃŸ ist die Wahrscheinlichkeit, dass es sich um eine Mathematikerin handelt?
>
> - 0.5
> - 0
> - 0.25
> - 0.05
>   > [!success]- LÃ¶sung
>   > 0.05

> [!faq] Sie begegnen auf dem Campus zufÃ¤llig einer Person, die Mathematik studiert. Wie groÃŸ ist die Wahrscheinlichkeit, dass diese weiblich ist?
>
> - 0.25
> - 0.05
> - 0.5
> - 0.2
> - 0
>   > [!success]- LÃ¶sung
>   > 0.2

> [!faq] Dabei handelt es sich um eine:
>
> - marginale Wahrscheinlichkeit
> - bedingte Wahrscheinlichkeit
> - inverse Wahrscheinlichkeit
>   > [!success]- LÃ¶sung
>   > bedingte Wahrscheinlichkeit

## Frage 3

> [!faq] Sie wissen, dass 450 der Soziologie-Studierenden weiblich sind. Sie begegnen zufÃ¤llig einer Person auf dem Campus. Wie groÃŸ ist die Wahrscheinlichkeit, dass es sich um eine Soziologin handelt?
>
> - 0.05
> - 0.6
> - 0.75
> - 0.45
>   > [!success]- LÃ¶sung
>   > 0.6

> [!faq] Sie begegnen zufÃ¤llig einer Person auf dem Campus. Wie groÃŸ ist die Wahrscheinlichkeit, dass diese Person weiblich ist?
>
> - 0.75
> - 0.05
> - 0.45
> - 0.5
>   > [!success]- LÃ¶sung
>   > 0.5

> [!faq] Dabei handelt es sich um eine:
>
> - bedingte Wahrscheinlichkeit
> - marginale Wahrscheinlichkeit
> - inverse Wahrscheinlichkeit
>   > [!success]- LÃ¶sung
>   > marginale Wahrscheinlichkeit

## Frage 4

> [!faq] Sie begegnen zufÃ¤llig einer weiblichen Person auf dem Campus. Wie groÃŸ ist die Wahrscheinlichkeit, dass es sich um eine Mathematikerin handelt?
>
> - 0.5
> - 0.25
> - 0.75
> - 0.1
>   > [!success]- LÃ¶sung
>   > 0.1

> [!faq] Um das zu berechnen, benutzen wir den:
>
> - Satz von Gauss
> - Satz von Bayes
> - Satz von Pythagoras
>   > [!success]- LÃ¶sung
>   > Satz von Bayes

# Der Satz von Bayes

## Beispiel

Ein einfaches Beispiel soll die Wirkungsweise des Satz von Bayes verdeutlichen:

### Medizinischer Test

Ein medizinischer Test soll das Vorliegen einer Krankheit feststellen. Solche Tests sind nicht ganz fehlerfrei, es kommt zu falsch positiven und falsch negativen Ergebnissen.

Wir definieren uns folgende Ereignisse:

- $A$: Eine Person ist krank
- $B$: Der Test zeigt ein positives Ergebnis

Der Test wird durchgefÃ¼hrt, wenn gewisse Symptome auftreten. Aus Erfahrung weiÃŸ man, dass 2% derjenigen, die den Test machen, wirklich die Krankheit haben. Bevor jemand den Test macht, nehmen wir also an, dass sie Wahrscheinlichkeit fÃ¼r $A$ 2% ist. Wir nennen diese auch _Priori-Wahrscheinlichkeit_ - Wahrscheinlichkeit vor der Beobachtung (lateinisch _a priori_, etwa "von vorher"):

- $P(A) = 0.02$ (Wahrscheinlichkeit, die Krankheit zu haben)
- $P(\bar{A}) = 0.98$ (Wahrscheinlichkeit, die Krankheit nicht zu haben)

Liegt die Krankheit vor, zeigt der Test in 95% der FÃ¤lle ein (korrektes) positives Ergebnis, in 5% der FÃ¤lle ein (falsches) negatives Ergebnis:

- $P(B|A) = 0.95$ (korrekt positiv)
- $P(B|\bar{A}) = 0.05$ (falsch negativ)

Liegt keine Krankheit vor, zeigt der Test in 90% der FÃ¤lle ein (korrektes) negatives Ergebnis, in 10% der FÃ¤lle ein (falsches) positives Ergebnis:

- $P(\bar{B}|A) = 0.9$ (korrekt negativ)
- $P(\bar{B}|\bar{A}) = 0.1$ (falsch positiv)

Die Annahmen Ã¼ber die Wahrscheinlichkeit von $B$ gegeben $A$ nennen wir _Modell-Annahmen_. Ihnen liegt ein stochastisches Modell zugrunde, hier die _Bernoulli-Verteilung_ (Binomial-Verteilung mit $n = 1$).

### Fragestellung

Frage: Wie groÃŸ ist die Wahrscheinlichkeit, krank zu sein, wenn der Test positiv ausfÃ¤llt?

Wir nennen diese gesuchte Wahrscheinlichkeit die _Posteriori-Wahrscheinlichkeit_, von lateinisch _a posteriori_, etwa "von nachher".

FÃ¼r die Beantwortung dieser Frage brauchen wir den _Satz von Bayes_.

## Der Satz von Bayes

Der Satz von Bayes ermÃ¶glicht es uns, die bedingte Wahrscheinlichkeit "umzudrehen" (bis ins 20. Jahrhundert sprach man auch von _inverser Wahrscheinlichkeit_). Wir wissen die bedingte Wahrscheinlichkeit eines Ereignisses $B$ gegeben das Ereignis $A$ eingetreten ist. Daraus kÃ¶nnen wir schlieÃŸen, wie die Wahrscheinlichkeit des Ereignisses $A$ gegeben das Ereignis $B$ eingetreten ist.

Der Satz von Bayes lautet in der einfachsten Form

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
$$

oder auch:

$$
\text{Posteriori} = \frac{\text{Bedingte Wahrscheinlichkeit d. Beobachtung} \cdot \text{Priori}}{\text{Marginale Wahrscheinlichkeit d. Beobachtung}}
$$

Wenn wir $P(B)$ nicht kennen, kÃ¶nnen wir die Wahrscheinlichkeit wie folgt Ã¼ber die bedingten Wahrscheinlichkeiten berechnen. Zusammengenommen lautet der Satz von Bayes dann:

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B|A)P(A) + P(B|\bar{A})P(\bar{A})}
$$

## Medizinischer Test

ZurÃ¼ck zum Beispiel medizinischer Test. Unsere Frage war: Wie groÃŸ ist die Wahrscheinlichkeit, krank zu sein, wenn der Test positiv ausfÃ¤llt?

### Priori-Annahmen:

- $P(A) = 0.02$ (Person ist krank)
- $P(\bar{A}) = 0.98$ (Person ist gesund)

### Modell-Annahmen

- $P(B|A) = 0.95$ (richtig positiv)
- $P(B|\bar{A}) = 0.05$ (falsch negativ)
- $P(\bar{B}|A) = 0.9$ (richtig negativ)
- $P(\bar{B}|\bar{A}) = 0.1$ (falsch positiv)

Wir setzen die Priori-Wahrscheinlichkeit $P(A)$ und die bedingten Wahrscheinlichkeiten $P(B|A)$ und $P(B|\bar{A})$ in den Satz von Bayes ein:

$$
\begin{aligned}
P(A|B) &= \frac{P(B|A) \cdot P(A)}{P(B|A)P(A) + P(B|\bar{A})P(\bar{A})} \\
&= \frac{0.95 \cdot 0.02}{0.95 \cdot 0.02 + 0.05 \cdot 0.98} \\
&= \frac{0.019}{0.019 + 0.049} \\
&= 0.162â€¦
\end{aligned}
$$

### Interpretation

Nach Beobachtung des positiven Testergebnisses ist also die Wahrscheinlichkeit, dass die Person krank ist etwa 16,2%. Aus unserer Priori-Wahrscheinlichkeit wurde durch die Beobachtung die Posteriori-Wahrscheinlichkeit.

Die Posteriori-Wahrscheinlichkeit $P(A|B)$ ist hier relativ gering, weil schon die Priori-Wahrscheinlichkeit $P(A)$ sehr gering war.

Auch der Effekt eines negativen Tests lÃ¤sst sich berechnen:

$$
\begin{aligned}
P(A|\bar{B}) &= \frac{P(\bar{B}|A) \cdot P(A)}{P(\bar{B}|A)P(A) + P(\bar{B}|\bar{A})P(\bar{A})} \\
&= \frac{0.9 \cdot 0.02}{0.9 \cdot 0.02 + 0.1 \cdot 0.98} \\
&= \frac{0.018}{0.018 + 0.098} \\
&= 0.155â€¦
\end{aligned}
$$

Ist der Test also negativ, ist die Wahrscheinlichkeit, dass die Person krank ist, bei etwa 15,5%. Praktisch kÃ¶nnen wir in diesem Fall also mit groÃŸer Wahrscheinlichkeit ausschlieÃŸen, dass die Person Krankheit hat.

Im Kontext des medizinischen Tests benÃ¶tigen wir $P(B|\bar{A})P(\bar{A})$ im Nenner der Bayes-Formel, weil wir nicht nur die Wahrscheinlichkeit berÃ¼cksichtigen wollen, dass eine kranke Person positiv getestet wird, sondern auch die Wahrscheinlichkeit, dass eine gesunde Person fÃ¤lschlicherweise positiv getestet wird.

Der Term $P(B|A)P(A)$ gibt uns die Wahrscheinlichkeit, dass jemand, der krank ist, auch einen positiven Test hat, wÃ¤hrend $P(B|\bar{A})P(\bar{A})$ die Wahrscheinlichkeit darstellt, dass jemand, der nicht krank ist, dennoch ein positives Testergebnis erhÃ¤lt. Ohne diesen zweiten Term wÃ¼rden wir die HÃ¤ufigkeit von falsch positiven Ergebnissen im Bezug auf die gesamte Population ignorieren, was zu einer ÃœberschÃ¤tzung der tatsÃ¤chlichen Wahrscheinlichkeit fÃ¼hren wÃ¼rde, dass eine Person mit einem positiven Test tatsÃ¤chlich krank ist. Der Satz von Bayes berÃ¼cksichtigt beide Aspekte, um ein umfassendes Bild der Posteriori-Wahrscheinlichkeit zu geben.

## Bemerkungen

- **Priori-Wahrscheinlichkeit** ($P(A)$) gleich 0, dann ist auch die **Posteriori-Wahrscheinlichkeit** unabhÃ¤ngig vom Modell immer gleich 0 - wir schlieÃŸen ja schon **a priori** aus, dass die Person krank ist.

- Ist die **Priori-Wahrscheinlichkeit** gleich 1, dann ist auch die **Posteriori-Wahrscheinlichkeit** unabhÃ¤ngig vom Modell immer gleich 1 - wir sind ja schon **a priori** sicher, dass die Person krank ist.

- Ist die Wahrscheinlichkeit fÃ¼r einen **falsch positiven Test** gleich 0, dann ist die **Posteriori-Wahrscheinlichkeit** bei positivem Test gleich 1.

- Ist die Wahrscheinlichkeit fÃ¼r den **falsch positiven Test** und die Wahrscheinlichkeit fÃ¼r einen **richtig positiven Test** jeweils gleich 0.5, dann ist die **Posteriori-Wahrscheinlichkeit** gleich der **Priori-Wahrscheinlichkeit** - der Test sagt dann ja nicht aus, das Testergebnis ($B$) ist stochastisch unabhÃ¤ngig von $A$.

- Mit grÃ¶ÃŸerer **Priori-Wahrscheinlichkeit** ist auch die **Posteriori-Wahrscheinlichkeit** grÃ¶ÃŸer - wir "**glauben**" ja schon vorher eher daran, dass die Person krank ist.

- Bei **positivem Testergebnis** ist die **Posteriori-Wahrscheinlichkeit** grÃ¶ÃŸer (oder gleich) als die **Priori-Wahrscheinlichkeit** - die Beobachtung des Testergebnisses "**drÃ¼ckt**" die Wahrscheinlichkeit also in eine Richtung; wir **lernen** aus der Beobachtung.

- Analog ist bei **negativem Testergebnis** die **Posteriori-Wahrscheinlichkeit** kleiner (oder gleich) als die **Priori-Wahrscheinlichkeit**.

- FÃ¼r "**schlechte Test**" (also geringe Wahrscheinlichkeit fÃ¼r **richtig positiven Test** oder hohe Wahrscheinlichkeit fÃ¼r **falsch positive Tests**) ist der Unterschied zwischen **Priori-** und **Posteriori-Wahrscheinlichkeit** geringer - wir **lernen** weniger aus der Beobachtung.

# Bayesianisches Lernen

> [!summary] Zusammenfassung
> In der Anwendung des Satzes von Bayes auf medizinische Tests und QualitÃ¤tskontrolle lernen wir, wie man anhand von Daten Wahrscheinlichkeiten aktualisiert. Im medizinischen Kontext helfen uns _a priori_ und _a posteriori_ Wahrscheinlichkeiten zu verstehen, wie sich die EinschÃ¤tzung der Krankheitswahrscheinlichkeit eines Patienten nach einem Testergebnis Ã¤ndert. In der QualitÃ¤tskontrolle nutzen wir den Satz von Bayes, um die Wahrscheinlichkeit zu bestimmen, dass ein Produkt von einer bestimmten Firma stammt, basierend auf der Anzahl der gefundenen AusschussstÃ¼cke. Diese fortgeschrittenen Bayesianischen Methoden ermÃ¶glichen es uns, unsere SchÃ¤tzungen zu verfeinern und zu verbessern, wÃ¤hrend wir mehr Daten sammeln, und illustrieren die dynamische Natur von Wahrscheinlichkeiten in der statistischen Inferenz.

Der Satz von Bayes hilft also, aus $B$ fÃ¼r $A$ zu lernen. Beim Beispiel "medizinischer Test" war

- _a priori_, also vor dem Test die Wahrscheinlichkeit, dass der Patient krank ist, bei 2%,
- _a Posteriori_, also nach positivem Testergebnis, lag die Wahrscheinlichkeit, dass der Patient krank ist, bei 16,2%.

Durch die Beobachtung (des Testergebnisses) haben wir Wissen (Information) hinzugewonnen. Information wird durch eine Wahrscheinlichkeitsverteilung ausgedrÃ¼ckt.

Wir kÃ¶nnen allerdings nur dann Wissen hinzugewinnen, wenn $A$ und $B$ nicht (stochastisch) unabhÃ¤ngig sind. Sind $A$ und $B$ unabhÃ¤ngig, gilt nÃ¤mlich

$$
P(A \cap B) = P(A)P(B)
$$

und nach Definition der bedingten Wahrscheinlichkeit

$$
P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{P(A)P(B)}{P(B)} = P(A)
$$

Das heiÃŸt, das Eintreten (oder Nicht-Eintreten) von $B$ Ã¤ndert die Wahrscheinlichkeit von $A$ nicht, liefert also keine Information Ã¼ber $A$.

## QualitÃ¤tskontrolle

Wir sehen uns ein weiteres Beispiel aus der QualitÃ¤tskontrolle an:

In einer Fabrik werden Vorprodukte von zwei verschiedenen Firmen (A Productions und B-warez) weiterverarbeitet. Dabei stammen 70% der Vorprodukte von Firma A und 30% von Firma B. Aus langjÃ¤hriger Erfahrung wissen die Arbeiter der Fabrik:

- Die Ausschussquoten betragen 1% bei Firma A und 5% bei Firma B.

Die Arbeiter finden eine neutrale Kiste des Vorprodukts (mit sehr vielen Teilen) ohne weitere Information Ã¼ber den Hersteller. Sie kontrollieren $n = 100$ StÃ¼ck und entdecken $y$ AusschussstÃ¼cke. Ist aus diesem Ergebnis ein RÃ¼ckschluss auf den Produzenten mÃ¶glich?

Sei also:

- Ereignis $A$: Los kommt von Firma A Productions
- Zufallsvariable $Y$: "Anzahl der AusschussstÃ¼cke" bei $n = 100$

FÃ¼r unsere Beobachtung kÃ¶nnen wir eine Verteilung angeben, die jedoch vom Eintreten von $A$ abhÃ¤ngt. Es handelt sich um eine Binomial-Verteilung mit $n = 100$, wobei die Wahrscheinlichkeit des Eintretens von $A$ abhÃ¤ngt:

- Ist $A$ eingetreten, also die Kiste kommt von Firma A, dann ist die Wahrscheinlichkeit fÃ¼r die Produktion eines AusschussstÃ¼ckes $p_A = 0.01$
- Ist dagegen $\bar{A}$ eingetreten, also die Kiste kommt aus Firma B, dann ist die Wahrscheinlichkeit $p_B = 0.05$

Bemerkung: Eigentlich wird hier Ziehen ohne ZurÃ¼cklegen gemacht, sprich wir mÃ¼ssten die Hypergeometrische Verteilung benutzen. Da wir aber keine Angabe Ã¼ber die Anzahl der Teile in der Kiste haben (nur "sehr viele"), nehmen wir die Binomialverteilung als AnnÃ¤herung.

Dementsprechend ergibt sich die bedingte Verteilung bzw. Datenverteilung von $Y$:

$$
Y|A \sim B(n, p_A)
$$

$$
Y|\bar{A} \sim B(n, p_B)
$$

mit der Wahrscheinlichkeit der Binomialverteilung:

$$
P(Y = y|A) = \binom{n}{y} p_A^y (1 - p_A)^{n-y}
$$

## Satz von Bayes

Der Satz von Bayes lÃ¤sst sich analog wie zuvor anwenden:

$$
P(A|Y = y) = \frac{P(Y = y|A) \cdot P(A)}{P(Y = y)}
$$

## Posteriori-Wahrscheinlichkeiten

Es ergeben sich folgende Posteriori-Wahrscheinlichkeiten:

| y                  | 0     | 1     | 2     | 3     | 4     | 5     | 6     |
| ------------------ | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| P(A &#124; Y = y)  | 0.993 | 0.965 | 0.842 | 0.505 | 0.164 | 0.036 | 0.007 |
| P(Â¬A &#124; Y = y) | 0.007 | 0.035 | 0.158 | 0.495 | 0.836 | 0.964 | 0.993 |

Je nach HÃ¶he von y kÃ¶nnen wir also mehr oder weniger gut angeben, aus welcher Firma das Los wahrscheinlich kommt.

Bei y = 3 kÃ¶nnen wir uns nicht wirklich zwischen den Firmen entscheiden, aber die Posteriori-Wahrscheinlichkeit

$$
P(A|Y = y) = 0.505
$$

ist kleiner als unsere ursprÃ¼ngliche Priori-Wahrscheinlichkeit $P(A) = 0.7$.

## Weiter Lernen

In diesem Fall kÃ¶nnen wir die Posteriori-Wahrscheinlichkeit $P(A|Y = y)$ wiederum als Priori fÃ¼r eine neue Stichprobe verwenden.

Sei nun:

- Zufallsvariable $Z$: "Anzahl der AusschussstÃ¼cke" bei weiteren $n = 100$

Offensichtlich gilt wieder $Z \sim B(n,p)$. Nun lÃ¤sst sich $P(A|Z = z, Y = y)$ wie folgt berechnen:

$$
P(A|Z = z, Y = y) = \frac{P(Z = z|A) \cdot P(A|Y = y)}{P(Z =z)}
$$

Die Wahrscheinlichkeitsverteilung $P(Z = z|A)$ der Daten hÃ¤ngt nicht von $Y$ ab. Als Priori benutzen wir hier die vorherige Posteriori-Wahrscheinlichkeit.

## Neue Posteriori-Wahrscheinlichkeiten

Sehen wir nach den $y = 3$ StÃ¼cken Ausschuss unter den ersten 100 untersuchten StÃ¼cken erneut $z$ StÃ¼cke Ausschuss, so erhalten wir folgende Posteriori-Wahrscheinlichkeiten:

FÃ¼r $z$ StÃ¼cke Ausschuss erhalten wir neue Posteriori-Wahrscheinlichkeiten:

$$
P(A | Z = z, Y = y) = \ldots
$$

Zum Beispiel geht bei erneut $z = 3$ AusschussstÃ¼cken unsere Tendenz nun klarer in Richtung Firma B.

# Quiz

Bei einem Radrennen wird ein Doping-Test durchgefÃ¼hrt. Die Firma, die den Test herstellt, gibt an, dass der Test zu 99.5% positiv ausfÃ¤llt, falls ein Sportler gedopt ist. Ist ein Sportler nicht gedopt, so betrÃ¤gt die Wahrscheinlichkeit fÃ¼r einen positiven Test 1%. Aus Erfahrung schÃ¤tzt man, dass ein Viertel der Sportler gedopt ist.

SeiÂ $D$Â die Zufallsvariable:Â *Der Sportler ist gedopt*Â undÂ $T$Â die Zufallsvariable:Â *Der Test fÃ¤llt positiv aus*.

> [!faq] Welche der folgenden Aussagen sind richtig? (Mehrere Antworten kÃ¶nnen richtig sein)
>
> - P(D)=0.01
> - P(DÂ¯)=0.75
> - P(D)=0.995
> - P(DÂ¯)=0.995
>   > [!success]- LÃ¶sung
>   > P(DÂ¯)=0.75

> [!faq] Welche der folgenden Aussagen sind richtig? (Mehrere Antworten kÃ¶nnen richtig sein)
>
> - P(T|D)=0.995
> - P(T|DÂ¯)=0.01
> - P(T|D)=0.01
> - P(T|D)=0.25
>   > [!success]- LÃ¶sung
>   > P(T|D)=0.995
>   > P(T|DÂ¯)=0.01

> [!faq] Wie groÃŸ ist die Wahrscheinlichkeit, dass der Test positiv ausfÃ¤llt?
>
> - P(T|D)=0.48
> - P(T)=0.48
> - P(T)=0.25625
> - P(T)=0.995
>   > [!success]- LÃ¶sung
>   > P(T)=0.25625

> [!faq] Wie groÃŸ ist die Wahrscheinlichkeit, dass ein Sportler nicht gedopt ist, obwohl der Test positiv ausfÃ¤llt?
>
> - P(DÂ¯|T)â‰ˆ0.168
> - P(DÂ¯|T)â‰ˆ0.039
> - P(DÂ¯|T)â‰ˆ0.029
>   > [!success]- LÃ¶sung
>   > P(DÂ¯|T)â‰ˆ0.168

> [!faq] Um das zu berechnen, benutzen wir den:
>
> - Satz von Gauss
> - Satz von Bayes
> - Satz von Pythagoras
>   > [!success]- LÃ¶sung
>   > Satz von Bayes

# NÃ¤chstes Kapitel: [[BaySta-Kapitel-Grundlagen]]

<!-- DISQUS SCRIPT COMMENT START -->

<hr style="border: none; height: 2px; background: linear-gradient(to right, #f0f0f0, #ccc, #f0f0f0); margin-top: 4rem; margin-bottom: 5rem;">
<div id="disqus_thread"></div>
<script>
    /**
    * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://myuninotes.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

<!-- DISQUS SCRIPT COMMENT END -->

<!-- Modal START -->
<div id="myModal" class="modal">
  <div class="modal-content">
    <span id="closeModal" class="close">&times;</span>
    <p class="modal-text">
      <span class="modal-highlight">MyUniNotes is a personal, non-revenue project as I believe in accessible education for everyone.</span> I manage this project alongside my studies, with all materials handwritten by me trying to help others understand challenging concepts.
    </p>
    <p class="modal-text">
      If MyUniNotes has been helpful and youâ€™d like to support my efforts, <span class="modal-highlight"> you can contribute with a donation: <a class="modal-dono-link" href="https://paypal.me/myuninotes4u">Donate via PayPal</a> :) </span> Your support will help me continue improving the content, but there is no obligation to donate.
    </p>
  </div>
</div>

<script>
  // JavaScript to display the modal on page load
  document.addEventListener('DOMContentLoaded', function() {
    // Generate a random number between 1 and 1
    // Wanted it to load with a adjustable probability for every page load but did not work, as DOM is loaded only once. Therefore now loading it every time website is visited and DOM is loaded.
    const randomNumber = Math.floor(Math.random() * 1) + 1; 
    console.log(randomNumber)
    if (randomNumber === 1) {
      setTimeout(function() {
        const modal = document.getElementById('myModal');
        if (modal) {
          modal.classList.add('show');
        }
      }, 1000); // Adjust the delay as needed

      const closeModal = document.getElementById('closeModal');
      if (closeModal) {
        closeModal.addEventListener('click', function() {
          const modal = document.getElementById('myModal');
          if (modal) {
            modal.classList.remove('show');
          }
        });
      }
    } else {
      // Ensure the modal is hidden if the random number is not 1
      const modal = document.getElementById('myModal');
      if (modal) {
        modal.style.display = 'none';
      }
    }
  });
</script>
<!-- Modal END -->
