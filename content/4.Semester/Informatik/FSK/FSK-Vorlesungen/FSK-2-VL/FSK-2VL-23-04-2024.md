---
tags:
  - 4semester
  - FSK
  - vorlesung
  - informatik
fach: "[[FSK]]"
Thema:
date created: Tuesday, 23. April 2024, 14:29
date modified: Tuesday, 23. April 2024, 15:30
---

# Skript

- VL-02a-f-grammtikbeispiele-mehrdeutigkeit-und-Entfernen von $\varepsilon$-Produktion 
- vl-02b-ft-deterministische-endliche-automaten

# VL-02a)
# $\varepsilon$-Produktionen: Sonderregeln

Die Verwendung von $\varepsilon$-Produktionen, also Produktionen, die das leere Wort $\varepsilon$ erzeugen, ist in der formalen Sprachtheorie von besonderer Bedeutung. Diese Produktionen ermöglichen es, Wörter der Länge null in der Sprache einer Grammatik zu repräsentieren. Jedoch gibt es spezifische Regeln und Einschränkungen für ihre Anwendung in den verschiedenen Typen von Chomsky-Grammatiken.

## Allgemeine Definition

In den Chomsky-Grammatiken werden vier Typen unterschieden:

- **Typ 0:** Unbeschränkte Grammatiken
- **Typ 1:** Kontextsensitive Grammatiken
- **Typ 2:** Kontextfreie Grammatiken
- **Typ 3:** Reguläre Grammatiken (erstmal Fokus hierrauf)

Für Typ 0-Grammatiken gibt es keine Einschränkungen bezüglich $\varepsilon$-Produktionen, solange jede Produktion die Form $\alpha \rightarrow \beta$ hat, wobei $|\alpha| \leq |\beta|$. Die anderen Grammatiktypen haben jedoch spezifische Regeln.

## $\varepsilon$-Produktionen In Typ 1, 2 und 3 Grammatiken

Das leere Wort $\varepsilon$ kann normalerweise nicht direkt in Typ 1, 2 und 3 Grammatiken erzeugt werden, da die Produktion $S \rightarrow \varepsilon$ die Bedingung $|S| \leq |ε|$ nicht erfüllt. Hierbei ist $|S|$ die Länge der linken Seite (hier 1) und $|ε|$ die Länge des leeren Wortes (hier 0).

### Sonderregel für $\varepsilon$-Produktionen

Um dennoch $\varepsilon$ in diesen Grammatiktypen zulassen zu können, wird eine Sonderregel eingeführt:

>[!info] **Sonderregel: E-Produktion in Typ 1, 2, 3 Grammatiken**
>
>Eine Grammatik $G = (V, Σ, P, S)$ vom Typ 1, 2 oder 3 darf eine Produktion $S \rightarrow \varepsilon \in P$ enthalten, vorausgesetzt, dass $S$ auf keiner rechten Seite einer Produktion in $P$ vorkommt. Diese Regel stellt sicher, dass keine Widersprüche oder Reduktionen zu unendlichen Schleifen führen.

#### Nicht erlaubte Konfiguration
>[!info] **Beispiel für eine nicht erlaubte Grammatik**
> $G = (\{S\}, \{a\}, \{ S \rightarrow \varepsilon, S \rightarrow aSa \}, S)$
>
> Hier verletzt die Grammatik die Sonderregel, da $S$ sowohl auf der linken als auch auf der rechten Seite einer Produktion vorkommt, was zu Konflikten führen kann.

#### Erlaubte Konfiguration
>[!info] **Beispiel für eine erlaubte Grammatik**
> $G = (\{S', S\}, \{a\}, \{ S' \rightarrow \varepsilon, S' \rightarrow aSa, S \rightarrow aSa \}, S')$
>
> In diesem Fall wird die Sonderregel eingehalten, da $S'$, das auf $\varepsilon$ abgebildet wird, nicht auf der rechten Seite anderer Produktionen vorkommt.

## Zusammenfassung

Die Verwendung von $\varepsilon$-Produktionen ermöglicht es Grammatiken, auch das leere Wort zu modellieren, was in vielen praktischen Anwendungen nützlich sein kann. Die Sonderregel für $\varepsilon$-Produktionen in Typ 1, 2 und 3 Grammatiken stellt jedoch sicher, dass die Grammatik wohldefiniert und frei von Ambiguitäten oder unerwünschten Schleifen bleibt. Durch die Einhaltung dieser Regel kann die Struktur und Effektivität der Grammatik beibehalten werden.

# Entfernung von $\varepsilon$-Produktionen

Die Entfernung von $\varepsilon$-Produktionen aus einer Grammatik ist ein wichtiger Schritt in der Vereinfachung und Optimierung von formalen Sprachen. $\varepsilon$-Produktionen sind solche, die das leere Wort $\varepsilon$ erzeugen. Obwohl sie in bestimmten Kontexten nützlich sind, können sie die Analyse und Verarbeitung der Grammatik komplizieren. Daher gibt es Verfahren, diese Produktionen systematisch zu entfernen.

## Warum $\varepsilon$-Produktionen entfernen?

- **Vereinfachung der Analyse:** Grammatiken ohne $\varepsilon$-Produktionen sind oft einfacher zu analysieren und zu verarbeiten.
- **Vermeidung von Komplikationen:** In vielen Algorithmen zur Grammatikanalyse, wie dem Parsing, können $\varepsilon$-Produktionen spezielle Fälle erfordern, die den Algorithmus verkomplizieren.
- **Optimierung:** Entfernen von $\varepsilon$-Produktionen kann die Effizienz von Algorithmen verbessern, die auf der Grammatik operieren.

## Wie entfernt man $\varepsilon$-Produktionen?

Die Entfernung von $\varepsilon$-Produktionen erfolgt in mehreren Schritten und basiert darauf, alle Möglichkeiten zu erkennen, bei denen diese Produktionen verwendet werden könnten, um ein Wort zu erzeugen. Hier ist ein allgemeines Verfahren:

1. **Identifiziere alle nichtterminalen Symbole, die $\varepsilon$ direkt erzeugen können:** Dies sind alle Symbole $A$ mit einer Produktion $A \rightarrow \varepsilon$.
2. **Ersetze diese Symbole in anderen Produktionen:** Für jedes Symbol, das $\varepsilon$ erzeugen kann, betrachte alle Produktionen, die dieses Symbol enthalten. Ersetze das Symbol durch die Option, es zu inkludieren oder zu exkludieren.
3. **Entferne redundante $\varepsilon$-Produktionen:** Nachdem alle möglichen Ersetzungen gemacht wurden, entferne die ursprüngliche $\varepsilon$-Produktion aus der Grammatik.

### Beispiel

Betrachten wir die Grammatik $G = (\{S, A\}, \{a, b\}, P, S)$ mit den Produktionen:

$$
P = \{ S \rightarrow ASb, A \rightarrow a, A \rightarrow \varepsilon \}
$$

**Schritt 1:** Identifiziere $\varepsilon$-erzeugende Symbole. Hier ist $A$ ein solches Symbol, da $A \rightarrow \varepsilon$.

**Schritt 2:** Ersetze $A$ in anderen Produktionen. Die Produktion $S \rightarrow ASb$ kann umgeschrieben werden zu:

$$
S \rightarrow ASb \,|\, Sb
$$

**Schritt 3:** Entferne die $\varepsilon$-Produktion $A \rightarrow \varepsilon$. Die neue Grammatik sieht nun wie folgt aus:

$$
G' = (\{S, A\}, \{a, b\}, \{ S \rightarrow ASb \,|\, Sb, A \rightarrow a \}, S)
$$

## Zusammenfassung

Die Entfernung von $\varepsilon$-Produktionen trägt dazu bei, die Struktur einer Grammatik zu vereinfachen und die Effizienz von darauf basierenden Algorithmen zu steigern. Durch das methodische Vorgehen können alle Instanzen von $\varepsilon$-Produktionen sicher und effektiv aus der Grammatik entfernt werden, wodurch die resultierende Sprache klarer und einfacher zu verarbeiten ist.

# VL-02b)

# Formalismen in der Theorie der formalen Sprachen

Die Theorie der formalen Sprachen nutzt verschiedene Formalismen, um Sprachen zu definieren und zu manipulieren. Zwei der wichtigsten Ansätze sind:

## Grammatiken

Grammatiken sind Regelsysteme, die angeben, wie Wörter einer Sprache erzeugt werden können. Sie bestehen aus:

- Einer Reihe von Symbolen, die das Alphabet der Sprache bilden.
- Einem Satz von Produktionen, die angeben, wie Symbole kombiniert werden können, um gültige Wörter oder Sätze der Sprache zu formen.
- Einem Startsymbol, von dem aus die Erzeugung beginnt.

Grammatiken werden oft genutzt, um die Syntax von Programmiersprachen zu definieren, aber auch in der Linguistik, um die Struktur natürlicher Sprachen zu beschreiben.

## Maschinenmodelle

Maschinenmodelle sind abstrakte Rechner, die die Fähigkeit besitzen, Wörter einer Sprache zu erkennen oder zu verarbeiten. Einige der bekanntesten Modelle sind:

- **Endliche Automaten:** Geeignet für reguläre Sprachen.
- **Kellerautomaten (Pushdown Automata):** Für kontextfreie Sprachen.
- **Turingmaschinen:** Können jede berechenbare Sprache erkennen.

Diese Modelle helfen zu verstehen, was berechenbar ist und welche Ressourcen (wie Zeit und Speicher) zur Berechnung benötigt werden.

## Wahl des geeigneten Formalismus

Die Entscheidung, ob Grammatiken oder Maschinenmodelle verwendet werden sollten, hängt von der spezifischen Anwendung und den Anforderungen ab. Eine wichtige Überlegung ist die Frage:

**Welche Maschine akzeptiert welche Sprachklasse?**

Die Antwort auf diese Frage hilft dabei, den passenden Formalismus für das Erkennen oder Erzeugen einer bestimmten Sprache auszuwählen.

- Für **reguläre Sprachen** sind endliche Automaten ausreichend.
- **Kontextfreie Sprachen** benötigen Kellerautomaten.
- **Kontextsensitive Sprachen** und andere komplexere Sprachen erfordern mächtigere Modelle wie Turingmaschinen.

Durch die Auswahl des angemessenen Modells kann man die Effizienz von Algorithmen verbessern und die Grenzen der Berechenbarkeit und Komplexität besser verstehen.

# Überblick über Grammatiken und Maschinenmodelle

Die Chomsky-Hierarchie klassifiziert formale Sprachen und ihre zugehörigen Berechnungsmodelle. Dieser Abschnitt bietet einen Überblick über die unterschiedlichen Typen von Grammatiken und Maschinen.

## Grammatiken und ihre Eigenschaften

Die Hierarchie unterteilt Grammatiken in vier Typen:

### Typ 0-Grammatik

- **Eigenschaften:** Keine Beschränkungen für die Produktionen.
- **Produktionen:** Form $\ell \rightarrow r$ wobei $\ell$ und $r$ beliebige Strings von Terminalen und Nichtterminalen sein können.
- **Entsprechendes Maschinenmodell:** Turingmaschine (deterministisch und nichtdeterministisch).

### Typ 1-Grammatik (Kontextsensitiv)

- **Eigenschaften:** Die Länge der linken Seite einer Produktion darf nicht größer sein als die der rechten Seite.
- **Produktionen:** Form $\ell \rightarrow r$ mit $|\ell| \leq |r|$.
- **Entsprechendes Maschinenmodell:** Linear beschränkte Turingmaschine (nichtdeterministisch).

### Typ 2-Grammatik (Kontextfrei)

- **Eigenschaften:** Jede Produktion wandelt ein Nichtterminal in eine Folge von Terminalen und Nichtterminalen um.
- **Produktionen:** Form $A \rightarrow r$ wobei $A$ ein Nichtterminal ist und $r$ eine Folge von Terminalen und Nichtterminalen.
- **Entsprechendes Maschinenmodell:** Kellerautomat (nichtdeterministisch).

### Typ 3-Grammatik (Regulär)

- **Eigenschaften:** Produktionen dürfen ein Nichtterminal nur in ein Terminal wandeln, eventuell gefolgt von einem weiteren Nichtterminal.
- **Produktionen:** Form $A \rightarrow a[B]$ wobei $A$ und $B$ Nichtterminale und $a$ ein Terminal ist.
- **Entsprechendes Maschinenmodell:** Endlicher Automat (deterministisch und nichtdeterministisch).

## Sprachklassen und Berechnungsmodelle

Die Zuordnung von Grammatiken zu Maschinenmodellen zeigt auf, welche Berechnungsmodelle zur Erkennung der Sprachen der jeweiligen Grammatikklasse geeignet sind:

- **Alle Sprachen (rekursiv aufzählbar):** Turingmaschinen sind in der Lage, diese Sprachen zu erkennen.
- **Kontextsensitive Sprachen:** Durch linear beschränkte Turingmaschinen erkennbar.
- **Kontextfreie Sprachen:** Kellerautomaten können diese Sprachen erkennen.
- **Reguläre Sprachen:** Durch endliche Automaten erkennbar.

Diese Zuordnung ist wichtig für das Verständnis der Berechenbarkeit und Komplexitätstheorie, da sie aufzeigt, welche Sprachklassen von welchen Berechnungsmodellen verarbeitet werden können und welche Ressourcen hierfür erforderlich sind.

# Wiederholung: Reguläre Sprachen

Reguläre Sprachen sind die einfachste Klasse formaler Sprachen in der Chomsky-Hierarchie und werden durch Typ-3-Grammatiken oder reguläre Grammatiken beschrieben. Die Charakteristik und Definition dieser Sprachklasse ist wie folgt:

## Definition einer Typ-3-Grammatik

Eine Grammatik $G$ ist definiert als ein 4-Tupel $G = (V, \Sigma, P, S)$, wobei:

- $V$ eine endliche Menge von Nichtterminalsymbolen ist.
- $\Sigma$ ein endliches Alphabet von Terminalsymbolen ist.
- $P$ eine endliche Menge von Produktionsregeln ist.
- $S$ das Startsymbol ist.

Die Grammatik $G$ wird als **Typ-3** oder **regulär** bezeichnet, wenn alle Produktionsregeln in $P$ die Form $A \rightarrow r$ haben, wobei:

- $r = a$ für ein $a \in \Sigma$ (Übergang zu einem Terminalsymbol).
- $r = aA'$ für ein $a \in \Sigma$ und $A' \in V$ (Übergang zu einem Terminalsymbol gefolgt von einem Nichtterminal).

## Charakteristik regulärer Sprachen

Eine Sprache $L$ ist Teil der Klasse regulärer Sprachen ($L \subseteq \Sigma^*$), wenn sie durch eine Typ-3-Grammatik $G$ erzeugt werden kann, sodass die von $G$ generierte Sprache $L(G)$ gleich $L$ ist.

Dies bedeutet, dass reguläre Sprachen vollständig durch endliche Automaten erkannt werden können und dass ihre Struktur einfach genug ist, um sie mit linearen Durchläufen über die Wörter zu verarbeiten. Typ-3-Grammatiken erlauben die Beschreibung regulärer Ausdrücke, die in der Textverarbeitung und in der Programmierung weit verbreitet sind.

## Beispiel

Betrachten wir die Grammatik $G = (\{A, B\}, \{a, b\}, P, A)$ mit den Produktionsregeln:

$$
P = \{ A \rightarrow aB, B \rightarrow b \}
$$

Diese Grammatik ist regulär, da sie den Vorschriften für Typ-3-Grammatiken folgt. Die Sprache $L(G)$, die sie erzeugt, besteht aus allen Wörtern, die mit dem Muster "ab" beginnen.

# Deterministische endliche Automaten

Deterministische endliche Automaten (DEAs) sind ein Kernkonzept im Bereich der regulären Sprachen und Automatentheorie. Sie werden durch eine Reihe einfacher Prinzipien und Eigenschaften definiert:

## Informelle Kurzfassung eines DEA

- **Start im Startzustand:** Ein DEA beginnt seine Verarbeitung in einem definierten Startzustand.
- **Zeichenweise Eingabe:** Das Eingabewort wird zeichenweise gelesen. Für jedes Zeichen gibt es einen definierten Übergang.
- **Zustandswechsel:** Bei der Verarbeitung eines Zeichens wechselt der Automat in einen neuen Zustand, der für jede Eingabe eindeutig ist.
- **Endliche Zustände:** Es gibt eine begrenzte Anzahl von Zuständen innerhalb des Automaten.

Nachdem der Automat ein Eingabewort komplett gelesen hat, kommt es zu einer der folgenden Entscheidungen:

- **Akzeptieren:** Wenn der Automat in einem Endzustand endet, wird das Eingabewort akzeptiert.
- **Verwerfen:** Wenn der Automat in einem Zustand endet, der kein Endzustand ist, wird das Eingabewort verworfen.

## Akzeptierte Sprache

Die von einem DEA akzeptierte Sprache ist die Menge aller Wörter, die vom Automaten akzeptiert werden. Formal ausgedrückt ist dies die Sprache $L$ für die gilt: Ein Wort $w$ gehört zu $L$, wenn der DEA nach der Verarbeitung von $w$ in einem Endzustand endet.

Deterministische endliche Automaten spielen eine entscheidende Rolle in der Praxis und Theorie, da sie dazu verwendet werden, reguläre Ausdrücke zu implementieren und einfache Syntaxanalyse durchzuführen. Sie sind auch ein wichtiger Bestandteil bei der Modellierung von Software- und Hardware-Systemen, in denen vorhersagbares Verhalten erforderlich ist.

# Definition eines DFA

Ein deterministischer endlicher Automat (DFA) ist ein mathematisches Modell eines abstrakten Automaten, der eine Reihe von Zuständen und Übergängen zwischen diesen Zuständen definiert. Ein DFA wird formal durch ein 5-Tupel dargestellt:

## Formale Struktur eines DFA

Ein DFA wird durch folgende Komponenten definiert:

- **$M$:** Das 5-Tupel, das den DFA darstellt.
- **$Z$:** Eine endliche Menge von Zuständen.
- **$\Sigma$:** Das endliche Eingabealphabet. Kein Symbol aus dem Alphabet darf in der Menge der Zustände enthalten sein, d.h. $Z \cap \Sigma = \emptyset$.
- **$\delta$:** Die Übergangsfunktion, die definiert, wie der Automat von einem Zustand zum nächsten übergeht. Es ist eine Funktion von $Z \times \Sigma$ nach $Z$, die für jede Kombination aus aktuellem Zustand und Eingabezeichen genau einen Folgezustand angibt.
- **$z_0$:** Der Startzustand, aus dem der Automat die Verarbeitung beginnt. Es ist ein Element aus der Menge $Z$.
- **$E$:** Die Menge der Endzustände, welche Teilmenge von $Z$ ist. Wenn der Automat nach der Verarbeitung eines Wortes in einem dieser Zustände endet, wird das Wort akzeptiert.

In mathematischer Schreibweise wird der DFA ausgedrückt als:

$$
M = (Z, \Sigma, \delta, z_0, E)
$$

Die Definition eines DFA ist zentral für das Verständnis, wie reguläre Sprachen verarbeitet und erkannt werden können. DFAs werden aufgrund ihrer Determiniertheit und der Einfachheit, mit der sie modelliert und implementiert werden können, in verschiedenen Bereichen der Informatik und verwandten Disziplinen genutzt.

# Zustandsgraph eines DFA

Ein Zustandsgraph ist eine visuelle Darstellung eines DFA, die die Zustände und die Übergänge zwischen ihnen zeigt. Für einen DFA $M = (Z, \Sigma, \delta, z_0, E)$ wird der Zustandsgraph wie folgt konstruiert:

## Konstruktion des Zustandsgraphen

- **Knoten für Zustände:** Jeder Zustand $z \in Z$ wird als Knoten dargestellt.
- **Startzustand:** Der Startzustand $z_0 \in Z$ wird durch einen eingehenden Pfeil gekennzeichnet.
- **Endzustände:** Die Endzustände $z \in E$ werden durch doppelte Kreise dargestellt.
- **Übergänge:** Die Übergänge $\delta(z_i, a) = z_j$ werden als gerichtete Kanten von Knoten $z_i$ zu Knoten $z_j$ dargestellt, beschriftet mit dem Eingabesymbol $a$.

Für eine kompakte Darstellung werden mehrere Übergänge zwischen zwei Zuständen mit verschiedenen Eingabesymbolen als eine Kante mit mehreren Beschriftungen dargestellt.

## Beispiel für einen DFA

Ein Beispiel für einen DFA könnte wie folgt definiert sein:

$$
M = (\{z_0, z_1, z_2\}, \{a, b\}, \delta, z_0, \{z_2\})
$$

mit den Übergangsfunktionen:

$$
\begin{align*}
\delta(z_0, a) &= z_1 \\
\delta(z_0, b) &= z_0 \\
\delta(z_1, a) &= z_2 \\
\delta(z_1, b) &= z_0 \\
\delta(z_2, a) &= z_2 \\
\delta(z_2, b) &= z_2
\end{align*}
$$

In einem solchen Zustandsgraph würden die Zustände $z_0$, $z_1$ und $z_2$ als Knoten dargestellt. Vom Startzustand $z_0$ führen Übergänge mit $a$ zu $z_1$ und mit $b$ zurück zu $z_0$. Von $z_1$ führen Übergänge mit $a$ zu $z_2$ und mit $b$ wieder zurück zu $z_0$. Der Zustand $z_2$ ist ein Endzustand und bildet mit jedem Eingabesymbol einen Übergang zu sich selbst.

Die Verwendung von Zustandsgraphen ermöglicht es, DFAs intuitiv zu verstehen und zu analysieren. Sie sind besonders hilfreich beim Entwurf von Automaten und bei der Überprüfung ihrer Funktionalität.

# Beispiel für einen akzeptierenden Lauf

Um zu demonstrieren, wie ein DFA ein Eingabewort verarbeitet, betrachten wir einen akzeptierenden Lauf. Ein akzeptierender Lauf ist eine Sequenz von Zustandsübergängen, die mit dem Startzustand beginnt und in einem Endzustand endet, nachdem das gesamte Eingabewort gelesen wurde.

## Visualisierung des Laufs

Der Lauf des DFA durch das Eingabewort wird oft mithilfe eines Zustandsgraphen visualisiert. Für den DFA $M$ mit den Zuständen $Z = \{z_0, z_1, z_2\}$ und der Eingabe $\text{abbbaaa}$, würde der akzeptierende Lauf wie folgt aussehen:

- Starte im Startzustand $z_0$.
- Lies das erste Zeichen $a$ und wechsle zum Zustand $z_1$.
- Lies das nächste Zeichen $b$ und kehre zum Zustand $z_0$ zurück.
- Lies ein weiteres Zeichen $b$ und bleibe im Zustand $z_0$.
- Mit dem nächsten Zeichen $b$, bleibe weiterhin in $z_0$.
- Lies dann das Zeichen $a$ und wechsle zum Zustand $z_1$.
- Mit dem nächsten $a$ wechsle zum Endzustand $z_2$.
- Lies das letzte Zeichen $a$ und bleibe im Endzustand $z_2$, wo das Wort akzeptiert wird.

## Verarbeitungsschritte

Die genauen Schritte der Verarbeitung sind:

1. `Starte in z_0.`
2. `Lies a und wechsle in z1.`
3. `Lies b und wechsle in z0.`
4. `Lies b und wechsle in z0.`
5. `Lies b und wechsle in z0.`
6. `Lies a und wechsle in z1.`
7. `Lies a und wechsle in z2.`
8. `Lies a und bleibe in z2.`
9. `Akzeptiere das Eingabewort, da z2 ein Endzustand ist.`

Das Eingabewort wird akzeptiert, da der Automat in einem Endzustand endet, nachdem das letzte Zeichen gelesen wurde. Dieses Beispiel veranschaulicht, wie ein DFA systematisch ein Eingabewort prüft und entscheidet, ob es zur Sprache des Automaten gehört.

# Akzeptanz bei DFAs

Die Akzeptanz eines Wortes durch einen DFA wird durch die Nutzung einer erweiterten Übergangsfunktion definiert, die es ermöglicht, ganze Wörter anstelle von einzelnen Symbolen zu verarbeiten.

## Erweiterte Übergangsfunktion

Für einen DFA $M = (Z, \Sigma, \delta, z_0, E)$ definieren wir die erweiterte Übergangsfunktion $\tilde{\delta}$, die rekursiv wie folgt funktioniert:

- $\tilde{\delta}(z, \epsilon) = z$: Wenn das Eingabewort das leere Wort $\epsilon$ ist, bleibt der Zustand unverändert.
- $\tilde{\delta}(z, aw) = \delta(\tilde{\delta}(z, a), w)$: Für ein Wort, das mit dem Symbol $a$ beginnt, gefolgt von einem Wort $w$, wende zuerst die Übergangsfunktion auf das Symbol $a$ an, um einen neuen Zustand zu erhalten, und wende dann rekursiv $\tilde{\delta}$ auf diesen neuen Zustand und das verbleibende Wort $w$ an.

## Akzeptierte Sprache

Die von $M$ akzeptierte Sprache $L(M)$ ist die Menge aller Wörter, die von $M$ akzeptiert werden. Formal definieren wir die akzeptierte Sprache als:

$$
L(M) = \{ w \in \Sigma^* \,|\, \tilde{\delta}(z_0, w) \in E \}
$$

Ein Wort $w$ gehört zur Sprache $L(M)$, wenn, nach der Verarbeitung des gesamten Wortes $w$ ausgehend vom Startzustand $z_0$, der Automat in einem der Endzustände $E$ endet.

Die erweiterte Übergangsfunktion ermöglicht es uns, die Akzeptanz eines Wortes durch einen DFA in einem einzigen mathematischen Ausdruck darzustellen und zu berechnen. Sie ist ein zentrales Werkzeug bei der Analyse der Funktionsweise von DFAs.


Um die Funktionsweise der erweiterten Übergangsfunktion \(\tilde{\delta}\) eines DFA zu veranschaulichen, betrachten wir einen konkreten Automaten und die Verarbeitung eines Eingabewortes.

## DFA und seine Übergangsfunktion

Gegeben sei der DFA \( M = (\{z_0, z_1, z_2\}, \{a, b\}, \delta, z_0, E) \) mit \( E = \{z_2\} \) und den folgenden Übergangsfunktionen:

- \(\delta(z_0, a) = z_1\)
- \(\delta(z_0, b) = z_0\)
- \(\delta(z_1, a) = z_2\)
- \(\delta(z_1, b) = z_0\)
- \(\delta(z_2, a) = z_2\)
- \(\delta(z_2, b) = z_2\)

## Zustandsgraph

Der Zustandsgraph für \( M \) zeigt die Zustände \( z_0, z_1, z_2 \) und die Übergänge zwischen ihnen, beschriftet mit den Eingabesymbolen.

## Verarbeitung eines Eingabewortes

Die Abarbeitung des Eingabewortes \( abbbaaa \) durch die erweiterte Übergangsfunktion würde wie folgt aussehen:

\[
\tilde{\delta}(z_0, abbbaaa) = \delta(\delta(\delta(\delta(\delta(\delta(\delta(z_0, a), b), b), b), a), a), a)
\]

Schritt für Schritt verarbeitet der Automat das Wort, indem er mit jedem Symbol den entsprechenden Zustandsübergang nimmt. Das Ergebnis dieses Prozesses zeigt, ob das Wort akzeptiert oder verworfen wird, basierend darauf, in welchem Zustand der Automat am Ende des Wortes landet.

Durch die rekursive Anwendung der Übergangsfunktion \(\delta\) kann die erweiterte Funktion \(\tilde{\delta}\) komplexe Berechnungen auf einfache Weise ausdrücken und damit bestimmen, ob ein Wort von einem DFA akzeptiert wird oder nicht.

# Beispiel für die δ~-Funktion

Um die Funktionsweise der erweiterten Übergangsfunktion δ~ eines DFAs zu veranschaulichen, betrachten wir einen konkreten Automaten und die Verarbeitung eines Eingabewortes.

## DFA und seine Übergangsfunktion

Gegeben sei der DFA M=({z0​,z1​,z2​},{a,b},δ,z0​,E) mit E={z2​} und den folgenden Übergangsfunktionen:

- δ(z0​,a)=z1​
- δ(z0​,b)=z0​
- δ(z1​,a)=z2​
- δ(z1​,b)=z0​
- δ(z2​,a)=z2​
- δ(z2​,b)=z2​

## Zustandsgraph

Der Zustandsgraph für M zeigt die Zustände z0​,z1​,z2​ und die Übergänge zwischen ihnen, beschriftet mit den Eingabesymbolen.

## Verarbeitung eines Eingabewortes

Die Abarbeitung des Eingabewortes abbbaaa durch die erweiterte Übergangsfunktion würde wie folgt aussehen:

[\tilde{\delta}(z_0, abbbaaa) = \delta(\delta(\delta(\delta(\delta(\delta(\delta(z_0, a), b), b), b), a), a), a)]

Schritt für Schritt verarbeitet der Automat das Wort, indem er mit jedem Symbol den entsprechenden Zustandsübergang nimmt. Das Ergebnis dieses Prozesses zeigt, ob das Wort akzeptiert oder verworfen wird, basierend darauf, in welchem Zustand der Automat am Ende des Wortes landet.

Durch die rekursive Anwendung der Übergangsfunktion δ kann die erweiterte Funktion δ~ komplexe Berechnungen auf einfache Weise ausdrücken und damit bestimmen, ob ein Wort von einem DFA akzeptiert wird oder nicht.