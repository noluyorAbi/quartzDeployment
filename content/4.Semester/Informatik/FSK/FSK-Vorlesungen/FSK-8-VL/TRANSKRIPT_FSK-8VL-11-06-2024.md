---
tags:
  - 4semester
  - FSK
  - informatik
fach: "[[Formale Sprachen und Komplexität (FSK)]]"
Thema:
Benötigte Zeit:
date created: Tuesday, 11. June 2024, 18:51
date modified: Monday, 22. July 2024, 01:44
---

Videos vom 14.06. das ist VL 07 statt 08

# VL-08a

Willkommen zur Vorlesung Formale Sprachen und Komplexität und Theoretische Informatik für Medieninformatiker. Nachdem wir die Typ 3 Sprachen, also die regulären Sprachen, gesehen haben und das Maschinenmodell, die endlichen Automaten, haben wir die Typ 2 Sprachen, das heißt die kontextfreien Sprachen, gesehen und das Automatenmodell, nämlich die Kellerautomaten. Es bleiben natürlich noch die Typ 1 und die Typ 0 Sprachen der Chomsky-Hierarchie übrig. Das Automatenmodell für beide Sprachen sind die sogenannten Turing-Maschinen, die Sie vielleicht schon mal gehört haben, die ziemlich bekannt sind, von Alan Turing eben vorgeschlagen. Und sie sind sozusagen für beide Sprachen nützlich oder allgemeine Turing-Maschinen beschreiben die Typ 0 Sprachen und die linear platzbesträngten Turing-Maschinen die Typ 1 Sprachen. Deswegen dürfen wir uns jetzt schon mit den Turing-Maschinen beschäftigen. Wiederholen wir noch mal kurz, was waren denn die Typ 1 Sprachen, was waren die Typ 0 Sprachen? Die Typ 1 Sprachen haben die Forderung, dass die Produktionen die Worte nicht schrumpfen dürfen. Das heißt, die linke Seite muss höchstens genauso lang sein wie die rechte Seite. Also es ist verboten, dass die rechte Seite der Produktion kürzer ist als die linke Seite. Die Typ 1 Grammatiken waren die kontextsensitiven Grammatiken, wobei die auf der linken Seite beliebige Satzformen haben dürfen, im Gegensatz zu den Typ 2 Sprachen, wo wir nicht Terminale erlaubt haben. In Typ 0 Sprachen ist alles erlaubt und man muss einfach nur Produktionen haben. In manchen Büchern werden unsere Typ 1 Grammatiken, so wie wir sie definiert haben über diese Bedingungen, auch monotone Grammatiken genannt, weil sie eben diese Monotonie-Bedingungen haben. Und die kontextiven Grammatiken fordern anderes Regelformat. Ein eingeschränkteres Regelformat. Nämlich, dass man sozusagen das Nicht-Terminal A nur in dem Kontext Alpha 1, Alpha 2 ersetzen darf durch Alpha 3. Wir verwenden die allgemeinere Definition der nicht schrumpfenden Regeln. Jetzt sehen wir das Maschinenmodell, das zu Typ 1 und Typ 0 passt. Nämlich die Turing-Maschinen für Typ 1 natürlich mit Einschränkung. Wir müssen immer daran denken, es gilt nicht, dass die Turing-Maschinen das äquivalente Modell zu den Kontextsensitiven Grammatiken haben. Sondern es sind die sogenannten linear platzbeschränkten Turing-Maschinen. Ja, ein bisschen Motivation zu den Turing-Maschinen. Die Kellerautomaten, die erkennen ja genau die kontextfreien Sprachen. Das haben wir die ganze Zeit behandelt. Und daher müssen die Automaten für Typ 1 und Typ 0 Sprachen einfach mehr können als die Kellerautomaten. Die wesentliche Beschränkung der Kellerautomaten ist, dass wir eben diesen Kellerspeicher haben, auf den man nur von oben zugreifen darf. Also von oben reinstecken darf oder rausnehmen darf. Deswegen kann man zum Beispiel diese Sprache a hoch i, b hoch i, c hoch i nicht mit dem Kellerautomaten erkennen. Da man diese Anzahl i in dem Wort, wenn man so ein fixes Wort hat, zwar beim Lesen der a's im Keller speichern kann, indem man z.B. große a's da rein tut. Aber beim Lesen der b's muss man die vergleichen und dadurch entleert man den Keller sukzessive. Das heißt, beim Lesen der c's, beim dritten Lesen, hat man diese Zahl i verloren, man hat sie nicht mehr im Speicher. Wenn man den Kellerautomaten vergleicht, dann hat man die Anzahl c's im Keller nicht mehr im Speicher. Wenn man den Keller beliebig irgendwie lesen dürfte, wäre es kein Problem. Also wenn man einfach z.B. so von oben nach unten hier einmal durchrennen dürfte, ohne dass man es rausnehmen muss, wäre es ja kein Problem, das Wort a hoch i, b hoch i, c hoch i zu erkennen. Das ist vermutlich sehr, sehr offensichtlich. Genau das versuchen die Turing-Maschinen jetzt zu beheben und deswegen sieht das Modell ein bisschen anders aus als bei den Kellerautomaten. Ich mal nochmal, nur damit wir sozusagen die Vergleiche wirklich dann auch sehen. Ich mal nochmal, nur damit wir sozusagen die Vergleiche wirklich dann auch sehen. Mal ich nochmal das Bild dazu wie der Kellerautomat aussah. Der Kellerautomat hat irgendwie die Eingabe stehen, hat ein Lesekopf, hat auch natürlich eine endliche Steuerung und hatte irgendwie noch den Zugriff auf diesen Keller … von oben. Der Lesekopf hat aber ziemlich viele Einschränkungen, der hat nämlich wirklich nur gelesen und da hat sich nur die Eingabe von links nach rechts einmal gelesen. Von links nach rechts. Jetzt unsere Turing-Maschine, die ist viel toller. Die hat die Eingabe auf einem Band stehen, und zwar ein Band mit Feldern. Und das Band ist beliebig groß nach links und nach rechts. Das heißt, wir haben irgendwo die Eingabe stehen. Wir haben über links und rechts ganz viel Band, unendlich viel Band. Und statt nur einem Lesekopf haben wir einen Schreiblesekopf. Das heißt, wir dürfen hier auch schreiben auf das Band. Und wir dürfen den Kopf bewegen nach links und nach rechts, beliebig wie wir wollen. Das heißt, alle Bewegungen nach links und nach rechts sind möglich. Und wie die genau dann ausgeführt werden, legt die endliche Steuerung wieder fest. Wir brauchen keinen Kellerspeicher mehr, da wir alles auf dem Band speichern können. Wir schreiben alles auf das Band. Also man kann sich vorstellen, die Turing-Maschine ist so ein bisschen wie eine Nähmaschine. Das Band ist der Stoff, der ist beliebig groß. Der rattert da durch. Und Sie können bei einer Nähmaschine ja auch vor und zurück, wenn man schon mal eine Nähmaschine benutzt hat, und können da irgendwas drauf nähen. Wir können hier was draufschreiben mit den Symbolen. Das ist also eine ganz gute Vorstellung. Tatsächlich kann man damit alles machen, was man mit einem modernen Computer sozusagen machen kann. Mit diesem einfachen Modell. Aber wir müssen es natürlich noch formal definieren. Die formale Definition von einer Turing-Maschine, abgekürzt TM, ist folgende. Also eine Turing-Maschine ist ein Siebentupel, bestehend aus Z, Sigma, Gamma, Delta, Z0, dem Planck-Symbol und den Endzuständen E. Dabei ist Z, wie immer, eine endliche Menge von Zuständen. Sigma ist das endliche Eingabealphabet. Gamma ist das endliche Bandalphabet. Tatsächlich ist Gamma eine Obermenge des Eingabealphabets. Also das Symbol ist ein Endzustand. Das sind die Symbole, die wir auf dem Band stehen haben. Und es ist eine echte Obermenge, weil wir ein Symbol mehr schon mal auf jeden Fall haben. Und das ist genau dieses Planck-Symbol. Delta ist die Zustandsüberführungsfunktion, die wir uns gleich anschauen. Z0 ist der Startzustand. Und dieses Symbol, diese Box, ist das Planck-Symbol. Das zeigt einfach einen leeren Inhalt auf dem Band an. Also wir haben ja so ein Band. Und dann wissen wir, wann eine Zelle leer ist. Dann steht dann das Planck-Symbol. Und E ist die Menge der Endzustände. So, die Zustandsüberführungsfunktion unterscheidet sich jetzt je nachdem, ob wir eine deterministische Turing-Maschine, also eine DTM, oder eine nicht-deterministische Turing-Maschine, eine NTM, vorliegen haben. Schauen wir uns erstmal die deterministische Turing-Maschine an. Die nimmt einen Zustand und ein Symbol aus dem Bandalphabet, so ein kleines A zum Beispiel, und liefert uns dann ein Trippel aus neuem Zustand Z' neuem Band-Symbol A' und einer Richtung, links, rechts oder neutral, also L, R oder N. Ich schreibe mal hier eine Richtung. Bei der nicht-deterministischen Turing-Maschine kriegen wir hier wieder eine Menge dieser möglichen Trippel aus Z, Gamma und N. Das heißt, wir haben einfach wieder viele Möglichkeiten, was wir machen. Jetzt die Frage, was bedeutet genau dieses, aus Z A wird Z' A' und eine Richtung? Ja, so ein Eintrag bedeutet, also wenn Delta von Z A gleich Z' B X, bedeutet das, falls die Turing-Maschine im Zustand Z ist. Also wir nehmen an, die ähnliche Steuerung ist im Zustand Z. Und das Zeichen an der… der aktuellen Position auf dem Band. Das heißt, was ist die aktuelle Position? Das ist die aktuelle Position unseres Schreib-Lese-Kopfes. Wenn da jetzt ein A steht, dann wird genau nachgeschaut, was ist der Eintrag von Delta Z A. Wenn der Eintrag Z' B X ist, dann wechselt danach die Turing-Maschine in den Zustand Z' und auf dem Band ersetzt sie das A und auf dem Band ersetzt sie das A und auf dem Band ersetzt sie das B. Und das X sagt ja die Richtung. Das X sagt uns, wo der Kopf danach ist. Wenn das neutral ist, dann bleibt der Kopf, wo er vorher war. Das heißt, er steht jetzt über dem B. Bei N. Wenn es ein L war, dann steht der Kopf jetzt links davon, um 1 verschoben. Und wenn es ein R war, dann steht der Kopf rechts davon. Bei dem ursprünglichen Eintrag. Das heißt, in jedem Schritt liest die Maschine ein Zeichen, ersetzt das Zeichen und wechselt den Kopf um eine Position oder um 0 Positionen. Die Position darf nach links oder nach rechts wechseln. Das macht eine Turing-Maschine. Bei der nicht-deterministischen Turing-Maschine, die macht eigentlich das Gleiche, nur dass wieder viele Schritte, viele verschiedene Schritte möglich sind. Das heißt, wir haben eine Menge von möglichen Nachfolgekonfigurationen. Und die nicht-deterministische macht irgendeinen davon nicht-deterministisch. So kann man es sich vorstellen, in einem Lauf. Das heißt, wir können ganz viele Zustände auf einmal durchlaufen. Das ist der Unterschied zwischen der deterministischen und der nicht-deterministischen Turing-Maschine. Ja, ich habe es eben schon benutzt, das Wort. Wir brauchen irgendwie, um über Läufe und im Ablauf von der Turing-Maschine zu sprechen, die Notation einer Konfiguration. So etwas hatten wir ja auch schon bei den Kellerautomaten. Jetzt machen wir das Gleiche bei den Turing-Maschinen. Eine Konfiguration ist ein Wort aus Gamma-Stern, Z-Gamma-Stern. Was bedeutet das? Das bedeutet,

Also wir haben so ein Wort W, Z, W', und diese Konfiguration meint, dass wir im Zustand Z sind und auf dem Band steht das Wort W, W', und links und rechts davon sind nur Blank-Symbole, und unser Kopf, Schreiblesekopf, steht auf dem ersten Symbol von dem W'. Deswegen haben wir das Z sozusagen zwischen W und W' geschrieben, weil der Kopf auf dem ersten Symbol von dem W' steht. Das meint diese Konfiguration. Die Startkonfiguration der Turing-Maschine für ein Eingabewort W ist dann eben der Startzustand, hier muss ich unterstreichen, und das Wort W. So, jetzt haben wir ein Problem. Was sollen wir machen, wenn das Wort das leere Wort ist? Dann hätten wir eigentlich ein Problem, wenn wir die Definition hier nehmen, weil dann irgendwie nicht klar ist, wo der Kopf steht so ganz, weil das ist das erste Symbol von dem W, gibt es ja nicht. Ja, wir nehmen einfach ein Blank-Symbol dazu. Das heißt, für den Spezialfall des leeren Wortes sei die Startkonfiguration als Wort geschrieben, Z0, Blank-Symbol. Das heißt, in diesem Fall. Steht der Kopf ja auf dem Blank-Symbol. Das ist eigentlich auch völlig egal, weil bei der Startkonfiguration, wie sieht das Band dann wirklich aus in Wirklichkeit? Das Band ist komplett leer, wenn das Wort leer ist. Das heißt, es ist völlig egal, wo wir eigentlich den Kopf hinmalen, weil wir haben ja unendlich viele Zellen nach links und nach rechts. Bei einer Turing-Maschine. Nachher ist es vielleicht nicht mehr ganz egal, wenn wir das Band irgendwie beschränken wollen. So, die Transitionsrelation ist natürlich ein bisschen mühselig jetzt zu definieren, weil wir diese vielen Richtungen haben, aber wir machen es trotzdem. Also wir nehmen wieder an, dass Z Sigma Gamma Delta Z0 Blank-Symbol E eine Turing-Maschine ist und definieren jetzt diese Relation V-M als Transitionsrelation für Konfigurationen der Turing-Maschine wie folgt. Wobei wir natürlich die ganze Zeit die Zustandsübergangskontrolle nicht machen. Wobei wir natürlich die ganze Zeit die Zustandsübergangsfunktion Delta verwenden. Für eine deterministische Turing-Maschine ist es klar, bei der nicht-deterministischen nehmen wir immer an, dass es eine Möglichkeit ist, die hier definiert wird. Die erste Möglichkeit sagt, wir haben, ich male es immer noch dazu, wir haben irgendwie das Wort B1 bis BM auf dem Band stehen. Dann kommt das Wort A1 bis AN auf dem Band und danach kommen ja nur noch Blanks. Wir müssen immer daran denken, unendlich viele nach links und nach rechts. Unser Kopf steht auf dem A1. Wenn wir dann Übergang haben nach Z'CN, was passiert dann? Wir sind ja noch im Zustand Z, dann sind wir danach im Zustand Z' und danach steht auf dem Band B1 BM und wir haben C geschrieben. Also C jetzt statt dem A1, dann A2 bis AN. Wo ist der Kopf? Wir haben ja neutral gesagt N. Also ist der Kopf jetzt weiterhin auf dem C. Das ist der Fall, also Z darf kein Endzustand sein für alle diese Fälle, sonst ist kein Übergang mehr definiert, wenn Z in dem E drin ist. Das habe ich vergessen zu sagen. Jetzt kommen die nächsten Fälle. Der nächste Fall sieht genauso aus, nur wir haben kein N, sondern wir haben jetzt ein L. Dann male ich jetzt einfach mal hier. Pünktchen, Pünktchen, Pünktchen, weil es sieht ja genauso aus. Und wenn wir aber ein L haben, dann steht danach eben der Kopf auf dem BM. Dann kommt immer noch das C, A2 bis AN. Und wir sind natürlich im Zustand Z'. Das war für das L. Für das R ist es natürlich klar, können Sie sich schon denken, der Kopf geht jetzt nach rechts. Das heißt danach haben wir B1 bis BM, das C, A2 bis AM. AN ist das hier eigentlich, genau. Und wir sind auch im Zustand Z'. Und der Kopf steht jetzt auf dem A2, weil er ist ja nach rechts gewandert. So, jetzt gibt es noch so Spezialfälle. Die letzten beiden sind Spezialfälle, nämlich wenn wir sozusagen am Ende des Wortes sind. Das heißt, wenn es vorher so aussieht, dann brauche ich wieder eine neue Farbe am besten. Wir haben irgendwie auf dem Band B1 bis BM stehen. Natürlich Blank-Symbol beliebig viele. Und dann kommt unser A1, unser Kopf steht ja dann auf dem A1. Jetzt kommt schon das Blank-Symbol, jetzt ist es vorbei. Und wir machen einen Schritt nach rechts. Dann passiert natürlich genau das, was man sich denkt. Der Kopf geht um 1 nach rechts und wir setzen natürlich das A1 durch C. Das heißt, der Kopf ist danach auf dem Blank-Symbol. Und das muss man eben hinschreiben hier, dass vor allem ein Blank-Symbol da erscheint. Die letzte Regel habe ich keinen Platz mehr, es hinzumalen. Das ist aber genau die gleiche Regel. Nur, dass wir nach links gehen und unser Kopf ganz links schon steht. Dann müssen wir halt links tatsächlich so ein Blank-Symbol hinzufügen, neben dem C. Und das sind jetzt die ganzen Möglichkeiten für die Transition, hingeschrieben mit den Konfigurationen. Das heißt, wir können jetzt schön spielen mit diesen Turing-Maschinen, können die laufen lassen. Zunächst noch ein bisschen weitere Notationen. Für die ifache Anwendung der Transitionsrelation. Schreiben wir einfach die Relation hoch I für die reflexiv-transitive Hülle. Das heißt, null- oder mehrfache Anwendung. Schreiben wir das Sternchen und wir lassen den Index m für die Maschine hier weg. Wenn er klar ist, dann schreiben wir nur dieses V-Symbol bzw. V-hoch I bzw. V-hoch Stern. Wir nehmen an, dass die Turing-Maschine anhält, sobald sie den Endzustand erreicht. In dem Schöning-Buch ist es ein bisschen anders definiert. Man kann immer die Definition ein bisschen variieren. Wir nehmen einfach an. Dass wir anhalten, sobald es nicht mehr weiter geht. So hatten wir das ja auch genau hier in der Transitionsrelation definiert. Wir haben immer gesagt, der Zustand Z darf kein Endzustand sein. Wenn wir einen Endzustand haben, dann machen wir keine weiteren Schritte mehr. Die akzeptierte Sprache einer Turing-Maschine können wir jetzt endlich definieren. Also sei M gleich Z Sigma Gamma Delta Z Null Blank Symbol E eine Turing-Maschine. Die von M akzeptierte Sprache ist einfach definiert als alle Worte aus Sigma Stern. So, dass es UV aus dem Band-Alphabet gibt, also Worte über dem Band-Alphabet gibt. Und ein Zustand Z, der ein Endzustand ist. So, dass wir mit der Start-Konfiguration, also Startzustand und dem Wort W, mit beliebig vielen Schritten in den Zustand kommen mit der Konfiguration UZV. Das heißt, ein beliebiges Wort auf dem Band, aber der Zustand Z hier, der muss ein Endzustand sein. Das ist die wichtige Bedingung. Und so ist die akzeptierte Sprache in der Turing-Maschine festgelegt. Triviale Beispiele für Turing-Maschinen der Form Z Sigma Gamma Delta Z Null Blank Symbol E mit Z Null in E. Also wenn der Startzustand ein Endzustand ist, dann gilt sofort, dass die Maschine alles akzeptiert, weil sie jede Eingabe sofort akzeptieren. Wir müssen gar nicht losrechnen, wir können auch gar nicht rechnen. Für Turing-Maschinen der Form Z Sigma Gamma Delta Z Null Blank Symbol leere Menge. Das heißt, es gibt keine Endzustände, gilt natürlich, dass sie gar nichts akzeptieren. Das heißt, die leere Sprache nur akzeptieren, weil sie können nie akzeptieren, nie anhalten. Sie kommen ja nie in Endzustand. Für die Darstellung als Zustandsgraph machen wir das Ganze wieder analog, wie wir es vorher schon gemacht haben. Wenn wir so einen Übergang haben mit vom Zustand Z in den Zustand Z', dann gibt es eben eine Kante in dem Graph. Und die ist beschriftet mit A ist das Bandsymbol, was wir lesen müssen. B ist das, was A ersetzt, das Bandsymbol. Und X ist die Richtung, die schreiben wir hier mit dran. Also A Doppelpunkt B Komma X meint, wir lesen im Zustand Z das Symbol A unter dem Schreiblesekopf. Und danach überschreiben wir es mit dem Buchstaben B und wechseln unseren Kopf entsprechend der Richtung X. Schauen wir uns ein Beispiel an. Es kommt aus dem Schöning-Buch, das Beispiel. Es hat vier Zustände. Wir sehen hier auch gleich den Zustandsgraph. Wir haben also die vier Zustände. Das Eingabealphabet ist 0,1. Das Bandalphabet ist 0,1 und Plank. Startzustand ist Z0. Das Plank-Symbol ist eben diese Box. Und nur der einzige Endzustand ist Z3. Und wir haben hier diese Übergänge. Da kann man sich mal angucken, was die sagen. Wenn wir Plank lesen im Zustand Z0, dann gehen wir in den Zustand Z1. Überschreiben Plank mit Plank. Und der Kopf wechselt nach links. Wenn wir im Zustand Z0 eine 0 lesen, dann lassen wir die 0 stehen und wechseln nach rechts. Wenn wir eine 1 lesen, lassen wir die 1 stehen und wechseln nach rechts. Das heißt, im Zustand Z0 rattern wir die ganze Zeit. So kann man es sich vorstellen. Wir sind irgendwie am Anfang in dem Band irgendwo. Unser Kopf hier steht hier. Und es stehen hier irgendwie Nullen und Einsen drauf auf dem Band. Was wir machen, wir rattern die ganze Zeit nach rechts, bis wir irgendwann auf ein Plank-Symbol treffen. Und wenn wir an dem Plank-Symbol sind, dann gehen wir hier in den Zustand Z1. Das heißt, dann springt die Maschine mit dem Kopf um ein Symbol zurück. Das heißt, der Kopf ist dann hier, weil der Kopf springt ja nach links. Also im Zustand Z1, wenn wir den zum ersten Mal erreichen, haben wir die ganze Binärzahl, die da steht, abgearbeitet nach rechts. Und stehen jetzt auf dem letzten Symbol. So, was machen wir jetzt als nächstes? Wenn wir eine 1 lesen, ersetzen wir sie durch eine 0. Und wenn wir eine 0 lesen, ersetzen wir sie durch eine 0. Und wenn wir eine 0 lesen, ersetzen wir sie durch eine 1. Aber beim 1 lesen, also 1 durch 0 ersetzen, verbleiben wir in Z1. Während wir beim 0, wenn wir die erste 0 lesen, dann wechseln wir in den Zustand Z2.

Das heißt, wir rattern jetzt wieder hier zurück, kann man sich das vorstellen, und tauschen aber Einsen durch Nullen und Nullen durch Einsen. Aber nur einmal eine Null durch eine Eins. Sobald wir eine Null durch eine Eins tauschen, sind wir im Zustand Z2. Was machen wir da? Da rattern wir weiter nach links, aber wir tauschen nichts mehr, sondern die Symbole sind gleich. Das machen wir so lange im Zustand Z2, bis wir jetzt hier vorne sind, bis wir wieder bei dem Planck-Symbol sind, was davor steht. Beziehungsweise, es geht auch von dem Zustand Z1 aus, also wenn wir nie in Z2 gekommen sind, dann rattern wir auch bis zum Planck-Symbol. Es passiert hier noch etwas Unterschiedliches, wenn man genau hinschaut. Wenn wir vom Zustand Z1 auskommen, dann ersetzen wir das Planck-Symbol durch eine Eins. Wenn wir vom Zustand Z2 auskommen, dann ersetzen wir das Planck-Symbol gar nicht, sondern es bleibt beim Planck-Symbol. Zustand Z3 akzeptieren wir. Die Übergänge hier brauchen wir trotzdem, weil wir ja eine deterministische Turing-Maschine vielleicht definieren wollen. Das heißt, dann müssen alle Zustände auch definiert werden. Was macht jetzt die Turing-Maschine? Sie interpretiert die Eingabe als Binärzahl und addiert 1. Deswegen haben wir genau bei den Nullen immer aus einer 0 eine 1 gemacht und sind dann gewechselt in den Zustand, dass sich nichts mehr ändert. Und wenn wir aus einer 1 eine 0 machen, haben wir noch einen Übertrag. Das heißt, wir bleiben in Z1. In Z0 wird das rechte Ende gesucht, dann wird in Z1 gewechselt. In Z1 wird versucht, 1 zur aktuellen Ziffer hinzuzuadieren. Gelingt das ohne Übertrag, dann wechseln wir in Z2. Bei Übertrag bleiben wir in Z1. Und müssen plus 1 zur nächsten Ziffer links addieren. In Z2 laufen wir bis zum Anfang, dann in Z3 und in Z3 wird akzeptiert. Ja, schauen wir uns ein Beispiel an für den Ablauf von der Turing-Maschine. Unsere Anfangskonfiguration ist Z00111. Ich male die auch nochmal hin, damit es irgendwie besser ist. Wir haben auf dem Band stehen 00111. Und daneben stehen natürlich unendlich viele Blank-Symbole, die ich auch mal hinmale. Und dann haben wir hier die Z3. Und wir haben den Kopf. Und der Kopf steht auf der ersten Null. Deswegen steht das Z0 hier vorne. Und der Automat ist im Zustand Z0. So, jetzt machen wir den ersten Schritt. Das heißt, wir sind im Zustand Z0. Und lesen ja eine Null auf dem Band. Und jetzt sagt uns die Maschine, was wir machen sollen. Wir sollen eine Null schreiben und den Kopf nach rechts wechseln. Das heißt, der nächste Zustand sieht so aus. Ich muss hier ein bisschen kleiner schreiben. Dass sich nichts geändert hat. Auf dem Band, weil wir die Null durch eine Null ersetzt haben. Unser Kopf ist um 1 weiter nach rechts gewechselt. Und ist immer noch im Zustand Z0 die Steuerung. So, jetzt kommt das Gleiche nochmal. Das heißt, der Kopf wechselt nochmal nach rechts. Ich versuche es hier hinzumalen. 0011. Immer noch in Z0. Jetzt lesen wir eine 1. Das heißt, wir nehmen jetzt hier diesen Übergang. Der sieht aber im Grunde auch genauso aus. Er ersetzt die 1 durch eine 1 und wechselt nach rechts. Auch das machen wir jetzt zweimal. Also ich mache mal hier. Ich kann mal beides hinmalen. Ich versuche es hinzumalen. Wir haben 0011. Der Kopf ist hier. Immer noch in Z0. Und jetzt machen wir das Gleiche nochmal. Dann haben wir 0011 blank. Das heißt, der Kopf ist jetzt auf dem blank-Symbol Z0. Jetzt müssen wir gucken, was passiert, weil es im Zustand Z0 bei dem blank-Symbol A ist. Dann nehmen wir den Übergang hier. Hier zu Z1 und was machen wir da? Ja, wir ersetzen blank durch blank und der Kopf wandert aber nach links. Das heißt, der nächste Zustand sieht so aus 0011 blank. Und der Kopf zeigt jetzt auf die 1 hier und wir sind im Zustand Z1. Im Zustand Z1 lesen wir jetzt eine 1, müssen wir die 1 dazu addieren. Zustand Z1 gehen wir mit der 1, bleiben wir im Zustand 1, wie wir sehen, ersetzen die 1 durch eine 0 und der Kopf wechselt nach links. Das heißt, danach haben wir jetzt das Stehen 0010, weil wir die 1 durch eine 0 ersetzt haben. Und der Kopf ist wieder 1 nach links gewechselt. Jetzt ist er auf dieser 1, immer noch im Zustand Z1. Jetzt passiert das Gleiche nochmal. Das heißt, wir haben das Stehen 0000 und der Kopf ist noch 1 weiter rüber gewechselt, hier auf diese 0. Das heißt, jetzt sind wir im Zustand Z1 und lesen jetzt eine 0, das heißt, wir nehmen hier diese Kante. Dabei wird die 0 durch eine 1 ersetzt und wir wechseln in den Zustand Z2. Das heißt, ich mache mal hier irgendwo hier unten weiter. Wir sind dann jetzt bei 0100 blank und unser Kopf ist hier und wir sind im Zustand Z2. So, Z2 mit einer 0 sind wir hier, verbleiben wir in Z2. Und wir ändern auch nichts an dem Band. Wir schreiben wieder eine 0 raus und unser Kopf ist noch 1 weiter nach links gewechselt. Das ist jetzt hier. Jetzt nehmen wir im letzten Schritt dann hier diese Kante und wechseln damit in den Zustand Z3. Also hier waren wir noch in Z2. Wechseln jetzt in den Zustand Z3 mit 0100. Da blinkt es davor. Und unser Kopf steht jetzt auf 0100. Und unser Kopf steht jetzt auf 0100. Auf der 0 und wir sind in Zustand Z3 und akzeptieren jetzt. Das heißt, wir sind jetzt fertig. Jetzt könnte man irgendwie noch fragen, muss man den Kopf immer noch richtig rücken, sonst wie? Also es ist so eine gute Praxis, wenn der Kopf, wenn er am Anfang auf dem ersten Symbol der Eingabe steht, dass er am Ende auf dem ersten Symbol der Ausgabe steht. Hat den Vorteil, wenn man zum Beispiel jetzt mehrere solche Turing-Maschinen hat oder die zweimal laufen lassen würde, in Anführungszeichen, würde sie nichts falsch machen. Also wenn Sie jetzt zweimal eins addieren, können Sie einfach die Turing-Maschine zweimal hintereinander ausführen und es würde funktionieren. Wenn Sie den Kopf sonst wo stehen hätten, würde es eben halt nicht funktionieren, die einfach so aneinander zu hängen. Dann müssten Sie erst den Kopf zurückfahren. Können wir noch gucken, ob die Maschine richtig gerechnet hat, also ob sie wirklich eins addiert hat. 0, 0, 1, 1 plus 1 ergibt, das kann man nochmal so rechnen, gibt hier eine 0, Übertrag 1, gibt eine 0, Übertrag 1, gibt eine 1 und eine 0. Also ist korrekt gerechnet, das heißt, die Turing-Maschine addiert 1 dazu. Die… Jetzt kommen wir zu einer Variante der Turing-Maschinen, die LBAs. Das sind linear beschränkte Turing-Maschinen. Die Idee ist, der Schreib-Lese-Kopf darf den Bereich der Eingabe auf dem Band nicht verlassen. Das heißt, Sie können sich vorstellen, wir haben irgendwie diese Eingabe, da steht unser Wort W und eigentlich habe ich ja gesagt, wir haben hier unendlich viele Zellen, die alle mit dem Blank-Symbol belegt sind. Beim LBA, bei einer linear beschränkten Turing-Maschine, ist die Idee, dass die Turing-Maschine im Grunde nur in diesem Bereich mit ihrem Kopf bleibt und der Kopf… Der Kopf darf hier nie rausrutschen. Also dafür müssen wir aber das Ende erkennen. Das heißt, die Turing-Maschine muss wissen, wann sie das letzte Symbol der Eingabe liest, wann sie hier ist. Und das wird gemacht, indem einfach eine Kopie des Alphabets genommen wird. Also nehmen wir an, das Alphabet ist A1 bis An. Dann nehmen wir noch so eine Kopie mit einem Hütchen drüber. Hütchen A1 bis Hütchen An. Das heißt, und dann ist die Eingabe der LBAs statt dem Wort W A1 bis Am nun A1 bis Am minus 1 und dann kommt Hütchen An. Das heißt, das letzte Symbol ist markiert mit dem Hütchen Am, um zu erkennen, hier ist Ende. Hier steht also ein Hütchen mit drin. Dadurch kann die Maschine weiße, wann es am Ende ist und dass sie nie hier rausspringen darf. Das linke Ende ist am Anfang nicht markiert. Das muss die Maschine selbst markieren, wenn sie das markieren will. Sie kann als ersten Schritt einfach zum Beispiel A1 ersetzen durch Hütchen A1. Definitionen, nicht-deterministische Turing-Maschine, Z Sigma vereinigt, Hütchen Sigma, Sigma Gamma, Delta Z 0, blanks und blanks. Z 0 E heißt linear beschränkt, LBA im Englischen für Linear Bounded Automated. Wenn für alle A1 bis Am in Sigma plus und alle Konfigurationen UZV mit Z 0 A1 bis Am minus 1 Hütchen Am geht über mit der Transitionsrelation in UZV, gilt die Länge von UV ist kleiner gleich m. So ziemlich viel Notation. Das heißt aber alles, was wir erreichen. Mit der Transitionsrelation, alles, was erreichbar ist, jeder Zustand hat niemals mehr als m Symbole auf dem Band und m war genau unsere Eingabelänge. Die akzeptierte Sprache ist klar. Die sind alle Worte A1 bis Am, sodass wir mit Z 0 A1 bis Am minus 1 Hütchen Am starten, in eine Endkonfiguration kommen, wo der Zustand Z ein Endzustand ist. LBAs sind definiert als nicht-deterministische Turing-Maschinen. Wichtig, wenn später vielleicht noch. Resultate dazu sehen. Ich denke heute nicht. Aber wie das aussieht mit den deterministischen, deterministischen Variante. Ein wichtiger Satz ist der Satz von Coroda, den wir hier in dieser Vorlesung heute nicht beweisen werden, aber in FSK beweisen werden, ist, dass die kontextsensitiven Sprachen genau von den LBAs erkannt werden. Das heißt genau diese linear beschränkten Turing-Maschinen, die beschreiben genau die kontextsensitiven Sprachen, also die Typ 1 Sprachen. Für die TIMI-Zuhörer werden wir diesen Satz ja gar nicht beweisen, sondern die müssen den sozusagen als gegeben hinnehmen. Für die FSK-Zuhörer werden wir den Satz von Coroda dann noch beweisen. Trotzdem möchte ich hier schon die Idee des Beweises kurz erklären. Da hat er halt zwei Richtungen. Schau mal, muss man sich wieder klar machen. Man hat zwei Richtungen. Einmal muss man zeigen, wenn L kontextsensitiv ist, dann wird L von einem LBA erkannt. Ja, es gibt ein LBA. Der LBA erkennt oder akzeptiert. Was man dafür macht, ist, was macht der LBA? Der LBA versucht einfach alle Worte der Wortlänge, Länge von W, versucht alle Worte mit Länge höchstens W, Länge von W herzuleiten, abzuleiten und zu prüfen, ob W abgeleitet wurde. So, jetzt muss er sich nur noch klar machen. HOch, das ist gut. Okay. OK.

dass das im Grunde in den Platz der Eingabe geht. Also man hat die Länge W, man hat das Wort, also von der Länge W an Platz nur zur Verfügung im Grunde und muss jetzt gucken, dass man nie darüber hinauskommt. Das funktioniert genau aufgrund dieser Beschränkung der Produktionsregeln, dass sie nämlich nicht schrumpfen dürfen. Das heißt, wenn wir einmal über ein Wort haben, was über die Länge W hinausgehen würde, können wir aufhören, weil wir wissen dann, das Wort oder die Satzform wird nicht mehr kleiner, sondern die wird auf jeden Fall zu groß. Genau aus diesem Grund reicht uns dieser Platz aus, weil wir müssen nie weiterkommen. Wir müssen Worte herleiten, die größer oder länger sind als das Zielwort. Das war genau dieses Bild vom Anfang. Wenn Sie irgendwie die Produktionsschritte sehen, dann wächst das sozusagen monoton, die Ableitung in der Wortlänge bei einer kontextsensitiven Sprache, während es bei einer allgemeinen nicht kontextsensitiven Sprache passieren kann, dass sie erst größer werden und dann wieder schrumpfen. Genau das ist nicht möglich, wenn Sie sich an dieses Bild von einer der ersten Vorlesungen erinnern. Das ist die eine Richtung. Für die andere Richtung, es gibt ja noch eine zweite Richtung, müssen Sie zeigen. Das ist die eine Richtung. Für die andere Richtung, es gibt ja noch eine zweite Richtung, müssen Sie zeigen. Das ist, wenn es ein LBA in der Sprache L akzeptiert, dass es dann auch eine kontextsensitive Grammatik gibt, die L akzeptiert, die L-Herd erzeugt. Das ist ein bisschen aufwendiger. Das heißt, Sie müssen eine Grammatik konstruieren, die genau den Ablauf von diesen LBAs oder Turing-Maschinen, das ist ein bisschen aufwendiger. Das heißt, Sie müssen eine Grammatik konstruieren, die genau den Ablauf von diesen LBAs oder Turing-Maschinen, und die linear beschränkte Turing-Maschine ein Modell für die Typ-1-Sprache. Deswegen haben wir die Turing-Maschine auch jetzt eingeführt, weil es sozusagen die letzten beiden Sprachklassen sind, die wir noch nicht betrachtet haben. Und bei beiden Sprachklassen die Turing-Maschine das richtige Modell ist. Nur bei den kontextsensitiven Sprachen sind es eben die linear beschränkten Turing-Maschinen, während es bei den beliebigen, bei den rekursiv aufzählbaren Sprachen, die Typ-0-Sprachen, eben beliebige Turing-Maschinen sind. So, wie ist es jetzt mit den nicht deterministischen? Bei den nicht deterministischen und deterministischen Turing-Maschinen, ja, bei den allgemeinen Turing-Maschinen, also ohne die lineare Beschränkung, können nicht deterministische Turing-Maschinen einfach durch deterministische simuliert werden, indem man einfach alle Möglichkeiten nacheinander durchprobiert. Das heißt, man zählt irgendwie so ab, was für Möglichkeiten hat die Turing-Maschine. Der Verzweigungsgrad ist ja immer endlich mit den Möglichkeiten, mit den nicht deterministischen. Probiert die einfach nacheinander aus, wie in so einem Berechnungsbaum, können Sie sich das vorstellen. Daher gilt der letzte Satz, also der Satz, dass die nicht deterministischen Turing-Maschinen die Typ-0-Sprachen akzeptieren, tatsächlich auch für die deterministischen Turing-Maschinen, weil die sich nicht unterscheiden bezüglich der Ausdruckskraft, was sie akzeptieren. Der Unterschied zwischen nicht deterministischen Turing-Maschinen und deterministischen Turing-Maschinen kommt erst zum Tragen, wenn wir das Laufzeitverhalten dann genauer betrachten, das kommt erst im Kapitel zur Komplexitätstheorie. Was wichtig ist, dieses Resultat gilt natürlich erstmal nicht für die LBAs, beziehungsweise man weiß es nicht so genau, was da gilt. Aber die LBAs sind immer nicht deterministisch definiert. So, damit sind wir jetzt tatsächlich mit den formalen Sprachen durch. Wir haben noch ein paar Beweise offen, die die FSK-Zuhörer in den nächsten beiden Videos oder Vorlesungen sehen werden. Die TIMI-Zuhörer nicht. Die TIMI-Zuhörer sollten sich aber die Turing-Maschinen gut merken, weil wir werden mit den Turing-Maschinen jetzt viel arbeiten. Und um Rechenbarkeit, mit Kümmern und Problemen, welche berechenbar sind. Bevor wir dazu kommen, möchte ich aber hier zum Ende dieser Vorlesung nochmal einen Überblick geben über die Grammatiken-Automaten für die Chomsky-Hierarchie, die wir gesehen haben. Sehen Sie hier auf dieser Folie schon. Wir haben hier die Chomsky-Hierarchie mit Typ 0, Typ 1, Typ 2, Typ 3 und wir haben zwischendrin noch die deterministisch-kontextfreien Sprachen, die ja eine Teilmenge der Typ-2-Sprachen sind. Sie sind echt größer als die Typ-3-Sprachen. Die passenden Grammatiken dazu sind die Typ-0-Grammatiken, die Kontext-7-Grammatiken, die kontextfreien Grammatiken, die regulären Grammatiken. Bei deterministisch-kontextfreien gibt es natürlich auch eine Klasse von Grammatiken, das sind die LRK-Grammatiken, die haben wir nicht gesehen. Werden wir auch nicht sehen, aber damit Sie es wissen, habe ich es hier hingeschrieben. Die Automaten-Modelle sind die endlichen Automaten bei den regulären Sprachen, sowohl deterministisch als auch nicht deterministisch. Es sind die deterministischen Kellerautomaten bei den deterministisch-kontextfreien Sprachen, die DPDAs. Bei den kontextfreien Sprachen sind es die Kellerautomaten, nicht deterministisch natürlich. Also man braucht nicht deterministische, weil die deterministisch in einer echten Teilmenge sind. Bei den Typ-1-Sprachen sind es die linear beschränkten Turing-Maschinen, die LBAs, die sind auch nicht deterministisch. Bei den Typ-0-Sprachen sind es eben die Turing-Maschinen, sowohl deterministisch als auch nicht deterministisch. Wir haben bei den Typ-3-Sprachen noch als sonstigen Formalismus die regulären Ausdrücke gesehen. Bei den anderen Sprachen gibt es natürlich auch noch viele weitere sonstige Formale. Hier unten bei den Typ-0-Sprachen werden wir tatsächlich auch noch ein paar sehen. Trennende Beispiele. Die Sprache A hoch N, B hoch N mit N in N ist in Typ-2 aber nicht vom Typ-3. Also ist nicht regulär, aber kontextfrei. Die Sprache W mit W ist ein Palindrom, ist Typ-2 aber nicht deterministisch kontextfrei. Das heißt, man muss raten, wann man sozusagen den Rest vom Wort rückwärts liest. Die Sprache A hoch N, B hoch N, C hoch N ist vom Typ-1, also kontextsensitiv. Aber nicht vom Typ-2, also nicht kontextfrei. Und ja, die Sprache H, die haben wir noch nicht gesehen. Das sind alle Turing-Maschinen-Beschreibungen. Also das sind alle Turing-Maschinen M, die auf dem Eingabewort W anhalten. Die ist tatsächlich vom Typ-0, aber nicht vom Typ-1. Das heißt, die Sprache ist das sogenannte Halteproblem. Das werden wir später noch genau betrachten und erläutern. Und diese Sprache ist wie gesagt Typ-0, aber nicht vom Typ-1. Und es gibt dann tatsächlich auch noch in der Hierarchie gucken. Sprachen, die in gar keinem Typ, von gar keinem Typ sind. Das ist das Komplement, diese Sprache H, die ist nicht vom Typ-0. Also die liegt sozusagen außerhalb der ganzen Hierarchie. Was gibt es noch zu sagen? Deterministisch versus nicht deterministisch. DFAs und NFAs bei den regulären Sprachen haben wir ja gesehen, die sind äquivalent. Die DPDAs und die PDAs, also Kellerautomaten und nicht deterministische Kellerautomaten sind nicht äquivalent. Haben wir gesehen. Die bei den LBAs, also den LBAs. Bei den linear beschränkten Turing-Maschinen ist es tatsächlich unbekannt. Da werden wir die FSK-Zuhörer in der nächsten Vorlesung auch noch was dazu hören. Und bei den deterministischen Turing-Maschinen und den nicht deterministischen Turing-Maschinen ist es wieder so, dass sie äquivalent sind. Weil man die einen durch die andere einfach simulieren kann. Bei den Abschlusseigenschaften, wenn Sie daran denken. Bei den regulären Sprachen, die waren sozusagen gutartig. Die sind abgeschlossen bezüglich Schnittvereinigung, Komplement, Produkt und klinischem Abschluss. Also überall ein Ja. Die deterministisch kontextfrei sind. Die sind tatsächlich nur abgeschlossen interessanterweise gegenüber dem Komplement, aber gegenüber sonst nichts. Die kontextfreien Sprachen sind abgeschlossen gegenüber Vereinigung, Produkt und klinischem Abschluss. Aber nicht abgeschlossen gegenüber Schnitt und Komplement. Die kontextsensitiven Sprachen sind wieder überall abgeschlossen. Schnittvereinigung, Komplement, Produkt, klinischer Abschluss. Haben wir nicht gesehen, aber können Sie mir glauben. Und die Typ-0-Sprachen, die sind abgeschlossen bezüglich Schnittvereinigung, Produkt, klinischer Abschluss. Aber nicht abgeschlossen. Gegenüber Komplement. Das haben wir gerade eben gesehen. H ist Typ 0, aber das Komplement vom Halteproblem ist eben nicht in Typ 0. Das ist genau so ein trennendes Beispiel, warum die Typ-0-Sprachen nicht abgeschlossen sind gegenüber dem Komplement. Entscheidbarkeiten. Das Wortproblem ist für Typ 1 und damit auch für Typ 2 und Typ 3 und deterministisch kontextfrei entscheidbar. Für Typ 0 ist es nicht mehr entscheidbar. Der Beweis steht natürlich noch aus. Das Leerheitsproblem, also ob die erzeugte Sprache leer ist, ist bei Typ 2 deterministisch kontextfrei und Typ 3 entscheidbar. Aber bei Typ 1 nicht mehr entscheidbar. Bei Typ 0 auch nicht mehr entscheidbar. Das Äquivalenzproblem, also ob zwei durch Grammatiken gegebene Sprachen die gleiche Sprache erzeugen, ist bei Typ 3, also regulär, und bei deterministisch kontextfrei noch entscheidbar. Aber bei Typ 0, Typ 1, Typ 2 nicht entscheidbar. Also selbst bei kontextfrei nicht mehr entscheidbar. Das Schnittproblem ist sogar bei deterministisch kontextfrei nicht mehr entscheidbar. Schnittproblem war, ob der Schnitt von zwei Sprachen leer ist. Letzte Folie. Ups, jetzt bin ich eins zu weit. Die Komplexität des Wortproblems. Bei Typ 3, wenn der DFA gegeben ist, ist es natürlich lineare Komplexität, weil er ist ja völlig deterministisch. Wir brauchen einfach nur den Automaten durchrennen lassen. Genauso gilt es bei den DPDAs, den deterministischen Kellerautomaten. Wenn der gegeben ist, können wir auch lineare Komplexität erreichen. Bei Typ 2, wenn wir die Chomsky-Normalform gegeben haben, ist es kubisch in der Größe der Grammatik, in der Größe des Wortes. Die Größe des Grammatiks muss man eigentlich auch noch zählen. Die Größe der Grammatik kann man aber auch einfach erstmal als konstant annehmen. Die Chomsky-Normalform muss schon gegeben sein, weil die die Grammatik sonst noch aufblähen kann. Bei Typ 1 ist es exponentiell, der Algorithmus. Und bei Typ 0 ist es ja nicht entscheidbar, daher nicht lösbar. Damit sind wir jetzt tatsächlich mit den formalen Sprachen für die TIMI-Zuhörer durch. Für die FSK-Zuhörer haben wir noch ein paar Vorlesungen, also ich glaube zwei, zu den Beweisen, zu den Aussagen, die wir heute nicht gesehen haben. Die Turing-Maschine, wie gesagt, wurde jetzt schon eingeführt. Die dürfen Sie nicht vergessen. Die Turing-Maschine wird uns jetzt ziemlich lange, also eigentlich bis zum Rest der Vorlesung, immer wieder begleiten und auch immer wieder ein wesentliches Maschinenmodell sein. Das heißt, Sie sollten die gut verinnerlichen.

# VL-08b

Willkommen zur Vorlesung Formale Sprachen und Komplexität und Theoretische Informatik für Medieninformatiker. Wir sind noch im Kapitel zu den Typ-2-Sprachen, also den kontextfreien Sprachen, haben kontextfreie Grammatiken natürlich gesehen, haben Kellerautomaten gesehen, die PDAs. Und heute sehen wir eine Untermenge der kontextfreien Sprachen, nämlich die deterministisch-kontextfreien Sprachen und noch ein paar Resultate zu Entscheidbarkeiten, also welche Probleme für kontextfreie Sprachen entscheidbar sind. Hier werden wir nicht alle Beweise sehen, auch im ersten Teil werden wir nicht alle Beweise sehen. Deswegen ist das Video relativ kurz, ein bisschen kürzer als normal. Dafür ist das zweite Video dann ein bisschen länger. Ein Teil der Beweise zu den Entscheidbarkeiten werden tatsächlich die FSK-Zuhörer, dann doch noch sehen, aber nicht im nächsten Video, sondern tatsächlich erst im übernächsten Video, weil es sich von der Struktur her einfach besser angeboten hat, das so zu machen. Im Skript ist die Struktur ein bisschen anders herum. Ich habe es nicht geändert. Man kann eben beide Strukturen machen, weil man sonst ein bisschen hin und her springt. Aber die Beweise sind nicht so übermäßig kompliziert, dass man jetzt irgendwie ein eigenes Video dafür machen sollte. Okay, fangen wir an. Die deterministisch-kontextfreien Sprachen, wie sind die definiert? Sie sind einfach definiert, dass man deterministische Kellerautomaten verwendet, und zwar deterministische Kellerautomaten, die mit Endzuständen akzeptieren, also nicht mit leerem Keller, sondern tatsächlich mit Endzuständen. Epsilon-Übergänge sind erlaubt, aber nur, wenn es keinen anderen Übergang gibt. Das heißt, wenn Sie sich daran erinnern, die deterministischen endlichen Automaten hatten ja gar keine Epsilon-Übergänge. Jetzt erlauben wir hier tatsächlich bei diesen Epsilon-Übergängen, die deterministischen Kellerautomaten, Epsilon-Übergänge, aber tatsächlich nur, wenn es keinen anderen Übergang mit einem Terminalzeichen und demselben Kellersymbol gibt. Das heißt, man kann einen Epsilon-Übergang haben mit Kellersymbol XYZ, aber dann darf es keinen anderen Übergang geben mit dem gleichen Kellersymbol. Dadurch sind die Automaten noch deterministisch. Also hier ist es genau definiert. Ein Kellerautomat mit Endzuständen ist eben so ein Siebentupel, Z, Sigma, Gamma, Delta, Z0, Raute, E. Ich wiederhole nochmal, Z sind die Zustände, Sigma ist das Eingabealphabet, Gamma ist das Kelleralphabet, Delta ist die Zustandsübergangsfunktion, Z0 ist der Startzustand, Raute ist das Startsymbol im Keller und E sind die Menge der Endzustände. So ein Kellerautomat ist deterministisch, also ein DPDA, wenn für alle Kombinationen von Z, A, A, wobei also Z ein Zustand ist, A ein Eingabensymbol und A ein Kellersymbol gilt, Delta von ZAA plus Delta von ZYA ist kleiner gleich 1. Das heißt, es gibt höchstens einen Übergang für jede Kombination aus Zustand und Kellersymbol und Terminalsymbol beziehungsweise deren Wort. Das heißt natürlich mit einem B und einem C und so weiter, mit einem kleinen B oder einem kleinen C, dürfen sie auch einen Übergang haben, aber sie dürfen niemals mehr als einen Übergang für ein A beziehungsweise sie müssen 0 für ein A haben, wenn sie einen für Y haben. Und die von DPDAs akzeptierten Sprachen heißen deterministisch kontextfrei. Das heißt, so sind die deterministisch kontextfreien Sprachen definiert über den deterministischen Kellerautomat. Eine wichtige Eigenschaft der deterministischen Kellerautomaten ist, dass sie deterministisch sind. Was bedeutet das genau? Wenn sie so eine Konfiguration haben für den Kellerautomaten, das heißt, sie haben einen Zustand, sie haben die Resteingabe W und sie haben das aktuelle Kellerinhalt W, dann ist diese Zustandstransition, die wir gesehen haben, nämlich da kommt ja der nächste Zustand, sagen wir mal Z' und das Wort ist irgendwie verändert und der Keller hat sich verändert. Diese Übergangstransition, die ist eindeutig. Das heißt, es gibt, es gibt höchstens eine Möglichkeit dafür. Entweder eine oder keine Möglichkeit dafür. Und daraus fließt man sozusagen den Determinismus. Das heißt, der Kellerautomat weiß immer, was er tun muss. Der deterministische Kellerautomat. Ja, gleich mal ein Beispiel. Die Sprache W-Dollar, W umgedreht mit W in A bis Stern ist deterministisch kontextfrei. Also was für Worte sind da drin? Da sind solche Worte drin. Irgendein Wort aus A. Also A ist und B ist. Dann kommt ein Dollarsymbol und dann kommt das gleiche Wort, aber in umgedrehter Reihenfolge. Und jetzt kann man natürlich beweisen, dass diese ganze Sprache deterministisch kontextfrei ist, indem man einen DPDA angibt, der die Sprache erkennt. Und ich mache mal hier, Sie sehen hier den kompletten DPDA. Die Idee ist, Sie haben den Startzustand Z0. Im Startzustand Z0 lesen Sie den ersten Teil, das erste W und merken, sich im Keller das ganze W in umgedrehter Reihenfolge. Das heißt, wenn Sie lesen zum Beispiel bei Kellerinhalt Raute, also am Anfang ein kleines A und speichern dafür ein großes A auf dem Keller. Das gleiche machen Sie auch, wenn ein A da schon drin liegt im Keller. Dann legen Sie einfach ein A dazu. Und wenn ein B schon drin liegt, dann legen Sie auch wieder ein A schon dazu. Das Ganze auch für das B natürlich. Dann, wenn Sie ein Dollarsymbol lesen, wechseln Sie in den Zustand Z1. Das heißt, das ist die Transition, die Sie hier sehen. Diese Möglichkeiten, also wenn Sie irgendwas haben, zum Beispiel ein A und lesen jetzt das Dollarsymbol, dann wechseln Sie in Z1 und lassen das A auf dem Keller liegen. Das gleiche auch mit dem B und mit der Raute. Dann sind Sie in Z1. In Z1 bauen Sie jetzt die Buchstaben ab wieder. Das heißt, Sie müssen immer ein A löschen, wenn Sie ein A lesen. Das heißt, wenn ein A im Keller steht und Sie lesen ein A, dann schreiben Sie danach Epsilon rein. Das sind diese Übergänge. Das machen Sie in Z1. Und wenn Sie alles gelesen haben, dann sind Sie ja wieder bei Ihrem Startkeller-Symbol im Keller. Und dann dürfen Sie wechseln in Z2. Und Z2 ist eben dieser akzeptierende Zustand des Automaten. Das heißt, dann akzeptieren Sie. Man beachtet, dass die Sprache ohne das Dollar nicht deterministisch kontextfrei ist, aber kontextfrei. Das heißt, man kann keinen deterministischen Kellerautomaten angeben. Das Problem ist, dass man bei der Sprache eben sozusagen nicht weiß, wann man von Z0 in Z1 wechseln muss. Und beim Nichtdeterminismus, der hilft. Da kann man einfach alle Möglichkeiten nichtdeterministisch ausprobieren. Aber beim Deterministischen weiß man es nicht. Deswegen kann man keinen deterministischen Automaten angeben. Das ist der Grund dafür. Ja, die Sprache A hoch I, B hoch I, die ist auch deterministisch kontextfrei, wie man sich denken konnte. Ist ein bisschen einfacher in diesem Fall noch, weil man liest einfach die ganzen As ein. Merkt die sich auf dem Stack, auf dem Keller. Bei jedem kleinen A, das man liest, merkt man sich ein großes A. Und wenn man B liest, dann wechselt man rüber. In den Zustand Z1. Pumpt dann immer eins von den großen As sozusagen ab. Mit jedem Lesen von einem B. Und hat am Ende dann einen leeren Keller. Oder wo nur noch das Startkeller-Symbol drauf liegt. Und geht dann wieder mit dem Epsilon-Übergang in den akzeptierenden Zustand. Auch da ist relativ einsichtig, dass dieser deterministische Kellerautomat die Sprache hier akzeptiert. Und keine anderen Worte akzeptiert ebenso. Ja, die Eigenschaften von deterministisch kontextfreien Sprachen. Sind irgendwie gutartig. Das Wortproblem für deterministische kontextfreie Sprachen kann tatsächlich in der Linearzeit entschieden werden. Kann man sich schon denken. Der Automat weiß ja immer, was er tun muss. Also kann man ihn einfach ausführen. Zum Beispiel. Das ist auch anders als bei allgemeinen kontextfreien Sprachen. Da haben wir nur den Algorithmus von Koch, Yanga und Kasamy gesehen. Der sozusagen kubische Laufzeit benötigt. Und hier geht das Ganze eben in die Linearzeit. Für deterministisch kontextfreie Sprachen kann man tatsächlich auch eindeutige Grammatiken angeben. Das heißt, wenn Sie eine Sprache haben gegeben durch ein DPDA, dann gibt es eine eindeutige Grammatik. Und deterministische kontextfreie Sprachen sind unter Komplementbildung abgeschlossen. Das ist eben auch eine gute Eigenschaft. Das heißt, diese kommen ja in der Chomsky-Hierarchie nicht wirklich vor. Die haben ja keinen eigenen Typ, die deterministisch kontextfreien Sprachen. Aber sie haben eigentlich so gute Eigenschaften, dass man sie in dieser Hierarchie, gerne auch aufführt. Das heißt, sie sind ja irgendwie so dazwischen. Sie sind eine Teilmenge der Typ-2-Sprachen. Aber sie haben halt eben keinen Typ. Aber man sollte sie eben kennen, weil sie diese gutartigen Eigenschaften haben. Die deterministisch kontextfreien Sprachen sind nicht abgeschlossen bezüglich Vereinigung und Schnitt. Was bedeutet das? Ja, das bedeutet eben, wenn man zwei deterministisch kontextfreie Sprachen, vereinigt oder zwei deterministisch kontextfreie Sprachen schneidet, muss man nicht notwendigerweise wieder eine deterministisch kontextfreie Sprache bekommen. Beweis ist eigentlich relativ einfach. Man nimmt diese nicht kontextfreie Sprache A hoch N, B hoch N, C hoch N und zeigt nun, dass diese durch den Schnitt dieser beiden Sprachen hier ja gebildet wird. Die beiden Sprachen hier sind einmal geschnitten. Einmal gleich viele A's und B's, aber beliebig viele C's. Also A hoch N, B hoch N, C hoch M. Und einmal gleich viele B's und C's, aber beliebig viele A's. Also A hoch N, B hoch M, C hoch M. Wenn man die beiden schneidet, dann ist der Schnitt natürlich genau diese Sprache. Das ist genau das Beispiel, um zu zeigen, dass die kontextfreien Sprachen unter dem Schnitt nicht abgeschlossen sind. Was jetzt natürlich noch fehlt, ist eigentlich der Beweis zu zeigen, dass diese beiden Sprachen jeweils deterministisch kontextfrei sind. Habe ich jetzt weggelassen. Der Beweis fehlt im Grunde. Das heißt, Sie müssen noch DP, DA's angeben für L1 und für L2. Aber das ist eigentlich nicht so schwierig, weil wir haben in den Automaten gesehen, der A hoch N, B hoch N erkannt hat, sage ich mal. Und der Automat ist sehr, sehr analog. Weil hier für die erste Sprache nehmen Sie einfach den Automaten für A hoch N, B hoch N. Und anstatt in den Zielzustand, in den Endzustand Z2 zu gehen, gehen Sie erst noch in einen Zustand, der beliebig viele C's fressen kann. Und hier machen Sie es umgekehrt. Sie fressen erstmal in einem beliebigen neuen Zustand die ganzen A's weg und gehen dann in den alten Automaten für A hoch N, B hoch M. Das heißt, die Konstruktion ist so einfach, dass ich sie hier weggelassen habe. Ja, für die Vereinigung. Kann man wieder mit dem Komplement argumentieren. Also deterministisch-kontextfreie Sprachen sind abgeschlossen bezüglich dem Komplement. Wir wissen, sie sind nicht abgeschlossen bezüglich dem Schnitt. Das heißt, man kann, aber da man den Schnitt mit dem Komplement und der Vereinigung darstellen kann, ist eigentlich klar, ist damit sofort klar, dass wir die Vereinigung, dass es bezüglich der Vereinigung nicht abgeschlossen ist. Das heißt, man braucht kein Beispiel. Also hier ist ein Beweis durch Widerspruch. Man nimmt an, die sind abgeschlossen bezüglich Vereinigung. Kriegt dann raus, dann sind sie auch abgeschlossen bezüglich dem Schnitt. Aber Schnittbildung haben wir gerade widerlegt. Das heißt, unsere Annahme war falsch. Wir haben Widerspruch hergeleitet. Die deterministisch-kontextfreien Sprachen sind nicht abgeschlossen bezüglich der Vereinigung. Ja, ein weiterer Satz, der ganz interessant ist, ist, dass man den Schnitt einer kontextfreien Sprache mit einer regulären Sprache, dass der wieder kontextfrei ist. Und das Gleiche gilt auch für die deterministisch-kontextfreien Sprachen. Das heißt, der Schnitt einer deterministisch-kontextfreien Sprache mit einer regulären Sprache ist deterministisch-kontextfrei. Der Beweis ist eigentlich relativ einfach. Der verwendet einfach Automaten, sowohl für die kontextfreie Sprache, da wird halt ein PDA oder ein DPDA verwendet, je nachdem, ob es deterministisch-kontextfrei ist oder nicht. Und zwar ein Kellerautomat mit Endzuständen, weil die deterministischen Kellerautomaten ja immer mit Endzuständen definiert sind. Und einen deterministischen endlichen Automaten, also einen DFA. Diese beiden Automaten werden nun verwendet, um einen neuen Kellerautomaten zu konstruieren mit Endzuständen. Und zwar ist das der Produktautomat im Grunde aus den beiden Automaten. Wir haben einerseits als neue Zustandsmenge das Kreuzprodukt aus der Zustandsmenge Z aus dem Kellerautomaten und den Zuständen Z' aus dem endlichen Automaten. Das Eingabealphabet ist natürlich das gleiche. Die Übergangsfunktionen kommen wir gleich dazu. Der Startzustand ist das Produkt aus Z0 und Z0', also genau die Startzustände der beiden Automaten. Das Kellersymbol bleibt gleich wie vorher, wie im Kellerautomaten. Und die Endzustände ist das Kreuzprodukt der Endzustände. Das bedeutet, da sehen wir schon, wir werden nur akzeptieren, wenn wir in beiden Automaten im Endzustand sind. Dann, wenn wir in beiden Automaten im Endzustand sind, wird die Übergangsfunktion natürlich noch definiert. Und was wir da machen ist, wir machen einen Schritt mit dem Kellerautomaten und einen Schritt mit dem endlichen Automaten. Machen die sozusagen gleichzeitig. Und so ist einfach die Übergangsfunktion definiert, mehr oder weniger. Hat man auch die Epsilon-Übergänge bei den DPDAs, da bleibt man bei dem Teil des endlichen Automaten einfach im gleichen Zustand. Das heißt, da macht der Kellerautomaten einen Schritt, einen Epsilon-Übergang, und der deterministische endliche Automaten macht einfach nichts. So kann man sich das vorstellen. Das heißt, das ist auch noch möglich. Das sind die zwei Fälle. Entweder machen beide einen Schritt, also beide Automaten machen einen Schritt, oder der PDA macht sozusagen einen Epsilon-Schritt. Ja, dann ist klar, dass dieser Automat den Schnitt der beiden vorherigen Sprachen erkennt, weil er einfach beide Automaten simuliert und akzeptiert, nur wenn beide Automaten akzeptieren. Der Automat ist auch deterministisch, sobald der Kellerautomaten deterministisch ist. Wenn der Kellerautomaten natürlich nicht deterministisch ist, dann kann man hier auch nicht deterministische Möglichkeiten einbauen. Jetzt sehe ich noch eine Preisfrage. Jetzt könnte man ja auf die Idee kommen, also wir nehmen ja hier einen Kellerautomaten und einen endlichen Automaten, konstruieren einen Kreuzautomaten, das Kreuzprodukt. Können Sie jetzt darüber nachdenken, warum funktioniert das bei kontextfreien Sprachen nicht, wenn beide Sprachen kontextfrei sind? Könnten wir doch einfach zwei Kellerautomaten nehmen und das Kreuzprodukt der Kellerautomaten nehmen? Um zu zeigen, dass die kontextfreien Sprachen abgeschlossen über dem Schnitt sind, sind sie aber nicht. Das haben wir gerade auch eben nochmal wieder bewiesen. Also da muss irgendwas falsch werden. Können Sie mal kurz darüber nachdenken, was da falsch wird, oder was das Problem ist. Vielleicht halten Sie einfach an, das Video, wenn Sie länger darüber nachdenken wollen. Ansonsten verrate ich Ihnen, was das Problem ist. Hier benutzt bei dieser Konstruktion, benutzt der Produktautomat den Keller nur für den Kellerautomaten. Wenn Sie jetzt zwei Kellerautomaten hätten, dann müssten Sie irgendwie die beiden Keller miteinander vermischen und das geht halt nicht. Tatsächlich kann man zeigen, dass das so nicht funktionieren kann. Der Witz ist, dass hier sozusagen der Keller des Produktautomaten exklusiv für den ursprünglichen einen Kellerautomaten zur Verfügung steht und der endliche Automaten ja keinen Keller hat, den er deswegen auch nicht benutzen muss und auch nicht benutzen kann. Das ist der Grund, warum die Konstruktion sozusagen funktioniert hier, aber nicht bei zwei Kellerautomaten funktionieren würde. Kommen wir zum letzten, zu den letzten Resultaten, zu den Entscheidbarkeitsfragen für kontextfreie Sprachen. Also, der CYK-Algorithmus und auch schon der Algorithmus für die Typ-1-Sprachen hat gezeigt, dass das Wortproblem für kontextfreie Grammatiken entscheidbar ist. Es ist sogar effizient entscheidbar. Wir haben es ja in, ich sag mal, polynomieller Zeit, kubischer Zeit bewiesen. Viele Fragestellungen für kontextfreie Sprachen sind tatsächlich unentscheidbar. Zum Beispiel das Äquivalenzproblem, also zwei kontextfreie Grammatiken erzeugen die die gleiche Sprache, ist unentscheidbar. Oder das Schnittproblem, ob zwei kontextfreie Sprachen, der Schnitt zweier kontextfreien Sprachen, leer ist. Weitere Entscheidungsprobleme sind tatsächlich, es gibt ein paar Probleme, die entscheidbar sind. Die stehen hier beide. Einerseits das Leerheitsproblem für kontextfreie Sprachen ist entscheidbar. Also gegeben, sage ich mal, eine kontextfreie Grammatik. Und die Frage ist, ob die leere Sprache erzeugt. Das ist die Frage. Das Problem kann man entscheiden, kann man Algorithmus angeben. Die Beweise machen wir jetzt nicht. Die sehen nur die FSK-Zuhörer, ich glaube, in der übernächsten Vorlesung. Das Endlichkeitsproblem für kontextfreie Sprachen ist auch entscheidbar. Also gegeben, eine kontextfreie Grammatik G wieder. Die Frage ist, ob die Mächtigkeit von der erzeugten Sprache sozusagen nicht unendlich ist. Also endlich ist. Das ist auch ein entscheidbares Problem. Auch dafür kann man Algorithmus angeben. Sehen wir jetzt aber nicht. Wir machen an dieser Stelle tatsächlich schon Schluss. Aber wie gesagt, dafür ist das nächste Video. Ein bisschen länger. Dafür ist dieses Video ein bisschen kürzer.

# VL-08c

Willkommen zur Vorlesung Formale Sprachen und Komplexität und Theoretische Informatik für Medieninformatiker. Nachdem wir die Typ 3 Sprachen, also die regulären Sprachen, gesehen haben und das Maschinenmodell, die endlichen Automaten, haben wir die Typ 2 Sprachen, das heißt die kontextfreien Sprachen, gesehen und das Automatenmodell, nämlich die Kellerautomaten. Es bleiben natürlich noch die Typ 1 und die Typ 0 Sprachen der Chomsky-Hierarchie übrig. Das Automatenmodell für beide Sprachen sind die sogenannten Turing-Maschinen, die Sie vielleicht schon mal gehört haben, die ziemlich bekannt sind, von Alan Turing eben vorgeschlagen. Und sie sind sozusagen für beide Sprachen nützlich oder allgemeine Turing-Maschinen beschreiben die Typ 0 Sprachen und die linear platzbesträngten Turing-Maschinen die Typ 1 Sprachen. Deswegen dürfen wir uns jetzt schon mit den Turing-Maschinen beschäftigen. Wiederholen wir noch mal kurz, was waren denn die Typ 1 Sprachen, was waren die Typ 0 Sprachen? Die Typ 1 Sprachen haben die Forderung, dass die Produktionen die Worte nicht schrumpfen dürfen. Das heißt, die linke Seite muss höchstens genauso lang sein wie die rechte Seite. Also es ist verboten, dass die rechte Seite der Produktion kürzer ist als die linke Seite. Die Typ 1 Grammatiken waren die kontextsensitiven Grammatiken, wobei die auf der linken Seite beliebige Satzformen haben dürfen, im Gegensatz zu den Typ 2 Sprachen, wo wir nicht Terminale erlaubt haben. In Typ 0 Sprachen ist alles erlaubt und man muss einfach nur Produktionen haben. In manchen Büchern werden unsere Typ 1 Grammatiken, so wie wir sie definiert haben über diese Bedingungen, auch monotone Grammatiken genannt, weil sie eben diese Monotonie-Bedingungen haben. Und die kontextiven Grammatiken fordern anderes Regelformat. Ein eingeschränkteres Regelformat. Nämlich, dass man sozusagen das Nicht-Terminal A nur in dem Kontext Alpha 1, Alpha 2 ersetzen darf durch Alpha 3. Wir verwenden die allgemeinere Definition der nicht schrumpfenden Regeln. Jetzt sehen wir das Maschinenmodell, das zu Typ 1 und Typ 0 passt. Nämlich die Turing-Maschinen für Typ 1 natürlich mit Einschränkung. Wir müssen immer daran denken, es gilt nicht, dass die Turing-Maschinen das äquivalente Modell zu den Kontextsensitiven Grammatiken haben. Sondern es sind die sogenannten linear platzbeschränkten Turing-Maschinen. Ja, ein bisschen Motivation zu den Turing-Maschinen. Die Kellerautomaten, die erkennen ja genau die kontextfreien Sprachen. Das haben wir die ganze Zeit behandelt. Und daher müssen die Automaten für Typ 1 und Typ 0 Sprachen einfach mehr können als die Kellerautomaten. Die wesentliche Beschränkung der Kellerautomaten ist, dass wir eben diesen Kellerspeicher haben, auf den man nur von oben zugreifen darf. Also von oben reinstecken darf oder rausnehmen darf. Deswegen kann man zum Beispiel diese Sprache a hoch i, b hoch i, c hoch i nicht mit dem Kellerautomaten erkennen. Da man diese Anzahl i in dem Wort, wenn man so ein fixes Wort hat, zwar beim Lesen der a's im Keller speichern kann, indem man z.B. große a's da rein tut. Aber beim Lesen der b's muss man die vergleichen und dadurch entleert man den Keller sukzessive. Das heißt, beim Lesen der c's, beim dritten Lesen, hat man diese Zahl i verloren, man hat sie nicht mehr im Speicher. Wenn man den Kellerautomaten vergleicht, dann hat man die Anzahl c's im Keller nicht mehr im Speicher. Wenn man den Keller beliebig irgendwie lesen dürfte, wäre es kein Problem. Also wenn man einfach z.B. so von oben nach unten hier einmal durchrennen dürfte, ohne dass man es rausnehmen muss, wäre es ja kein Problem, das Wort a hoch i, b hoch i, c hoch i zu erkennen. Das ist vermutlich sehr, sehr offensichtlich. Genau das versuchen die Turing-Maschinen jetzt zu beheben und deswegen sieht das Modell ein bisschen anders aus als bei den Kellerautomaten. Ich mal nochmal, nur damit wir sozusagen die Vergleiche wirklich dann auch sehen. Ich mal nochmal, nur damit wir sozusagen die Vergleiche wirklich dann auch sehen. Mal ich nochmal das Bild dazu, wie der Kellerautomat aussah. Der Kellerautomat hat irgendwie die Eingabe stehen, hat einen Lesekopf, hat auch natürlich eine endliche Steuerung und hatte irgendwie noch den Zugriff auf diesen Keller von oben. Der Lesekopf hat aber ziemlich viele Einschränkungen, der hat nämlich wirklich nur gelesen. Der Lesekopf hat aber ziemlich viele Einschränkungen, der hat nämlich wirklich nur gelesen. Eingabe von links nach rechts einmal gelesen. Von links nach rechts. Jetzt unsere Turing-Maschine, die ist viel toller. Die hat die Eingabe auf einem Band stehen, und zwar ein Band mit Feldern. Und das Band ist beliebig groß nach links und nach rechts. Das heißt, wir haben irgendwo die Eingabe stehen. Wir haben aber links und rechts ganz viel Band, unendlich viel Band. Und statt nur einem Lesekopf haben wir einen Schreiblesekopf. Das heißt, wir dürfen hier auch schreiben auf das Band. Und wir dürfen den Kopf bewegen nach links und nach rechts, beliebig wie wir wollen. Das heißt, alle Bewegungen nach links und nach rechts sind möglich. Und wie die genau dann ausgeführt werden, legt die endliche Steuerung wieder fest. Wir brauchen keinen Kellerspeicher mehr, da wir alles auf dem Band speichern können. Wir schreiben alles auf das Band. Also man kann sich vorstellen, die Turing-Maschine ist so ein bisschen wie eine Nähmaschine. Das Band ist der Stoff, der ist beliebig groß, der rattert da durch. Und Sie können bei einer Nähmaschine ja auch vor und zurück, wenn man schon mal eine Nähmaschine benutzt hat, und können da irgendwas drauf nähen. Wir können hier was draufschreiben mit den Symbolen. Das ist also eine ganz gute Vorstellung. Tatsächlich kann man damit alles machen, was man mit einem modernen Computer sozusagen machen kann. Mit diesem einfachen Modell. Aber wir müssen es natürlich noch formal definieren. Die formale Definition von einer Turing-Maschine, abgekürzt TM, ist folgende. Das ist also eine Turing-Maschine. Eine Turing-Maschine ist ein Siebentupel, bestehend aus Z, Sigma, Gamma, Delta, Z0, dem Planck-Symbol und den Endzuständen E. Dabei ist Z, wie immer, eine endliche Menge von Zuständen. Sigma ist das endliche Eingabealphabet. Gamma ist das endliche Bandalphabet. Tatsächlich ist Gamma eine Obermenge des Eingabealphabets. Also das sind die Symbole, die wir auf dem Band stehen haben. Und es ist eine echte Obermenge. Weil wir ein Symbol mehr schon mal auf jeden Fall haben. Und das ist genau dieses Planck-Symbol. Delta ist die Zustandsüberführungsfunktion, die wir uns gleich anschauen. Z0 ist der Startzustand. Und dieses Symbol, diese Box, ist das Planck-Symbol. Das zeigt einfach einen leeren Inhalt auf dem Band an. Also wir haben ja so ein Band. Und dann wissen wir, wann eine Zelle leer ist. Dann steht dann das Planck-Symbol. Und E. E ist die Menge der Endzustände. So, die Zustandsüberführungsfunktion unterscheidet sich jetzt je nachdem, ob wir eine deterministische Turing-Maschine, also eine DTM, oder eine nicht-deterministische Turing-Maschine, eine NTM, vorliegen haben. Schauen wir uns erstmal die deterministische Turing-Maschine an. Die nimmt einen Zustand und ein Symbol aus dem Bandalphabet, so ein kleines a zum Beispiel, und liefert uns dann ein… Trippel aus neuem Zustand, z.B.Strich, neuem Band-Symbol, a Strich, und einer Richtung, links, rechts oder neutral, also L, R oder N. Ich schreibe mal hier in Richtung. Bei der nicht-deterministischen Turing-Maschine kriegen wir hier wieder eine Menge dieser möglichen Trippel aus z.B.Gamma und einer Richtung. Das heißt, wir haben nicht… Wir haben einfach wieder viele Möglichkeiten, was wir machen. Jetzt ist die Frage, was bedeutet genau dieses, aus z.B.A wird z.B.Strich, a Strich und eine Richtung? Ja, so ein Eintrag bedeutet, also wenn Delta von z.B.A gleich z.B.Strich b x, bedeutet das, falls die Turing-Maschine im Zustand z.B.ist. Also wir nehmen an, die ähnliche Steuerung ist im Zustand z. Und das Zeichen an der aktuellen Position auf dem Band, das heißt, was ist die aktuelle Position? Das ist die aktuelle Position unseres Schreib-Lese-Kopfes. Wenn da jetzt ein a steht, dann wird genau nachgeschaut, was ist der Eintrag von Delta z.B.A. Wenn der Eintrag z.B.Strich b x ist, dann wechselt danach die Turing-Maschine in den Zustand z.B.Strich. Und auf dem Band ersetzt sie das a durch das b. Und das x sagt ja die Richtung, das x sagt uns, wo der Kopf danach ist. Wenn es neutral ist, dann bleibt der Kopf, wo er vorher war, das heißt, er steht jetzt über dem b, bei n. Wenn es ein l war, dann steht der Kopf jetzt links davon, um 1 verschoben. Und wenn es ein r war, dann steht der Kopf rechts davon, bei dem ursprünglichen Eintrag. Das heißt, in jedem Schritt liest die Maschine 1. Und das Zeichen ersetzt das Zeichen und wechselt den Kopf um eine Position oder um 0 Positionen. Die Position darf nach links oder nach rechts wechseln. Das macht eine Turing-Maschine. Bei der nicht-deterministischen Turing-Maschine, die macht eigentlich das Gleiche, nur dass wieder viele Schritte, viele verschiedene Schritte möglich sind. Das heißt, wir haben eine Menge von möglichen Nachfolgekonfigurationen. Und die nicht-deterministische macht irgendeinen davon nicht-deterministisch. So kann man es sich vorstellen, in einem Lauf. Das heißt, wir können ganz viele Zustände auf einmal durchlaufen. Das ist der Unterschied zwischen der deterministischen und der nicht-deterministischen Turing-Maschine. Ja, ich habe es eben schon benutzt, das Wort. Wir brauchen irgendwie, um über Läufe und den Ablauf von der Turing-Maschine zu sprechen, die Notation einer Konfiguration. So etwas hatten wir ja auch schon bei den Kellerautomaten. Jetzt machen wir das Gleiche bei den Turing-Maschinen. Eine Konfiguration ist ein Wort aus Gamma-Stern, Z-Gamma-Stern. Was bedeutet das? Das bedeutet,

Also wir haben so ein Wort W, Z, W', und diese Konfiguration meint, dass wir im Zustand Z sind und auf dem Band steht das Wort W, W', und links und rechts davon sind nur Blank-Symbole, und unser Kopf, Schreiblesekopf, steht auf dem ersten Symbol von dem W'. Deswegen haben wir das Z sozusagen zwischen W und W' geschrieben, weil der Kopf auf dem ersten Symbol von dem W' steht. Das meint diese Konfiguration. Die Startkonfiguration der Turing-Maschine für ein Eingabewort W ist dann eben der Startzustand, hier muss ich unterstreichen, und das Wort W. So, jetzt haben wir ein Problem. Was sollen wir machen, wenn das Wort das leere Wort ist? Dann hätten wir eigentlich ein Problem, wenn wir die Definition hier nehmen, weil dann irgendwie nicht klar ist, wo der Kopf steht so ganz, weil das ist das erste Symbol von dem W, gibt es ja nicht. Ja, wir nehmen einfach ein Blank-Symbol dazu. Das heißt, für den Spezialfall des leeren Wortes sei die Startkonfiguration als Wort geschrieben, Z0, Blank-Symbol. Das heißt, in diesem Fall. Steht der Kopf ja auf dem Blank-Symbol. Das ist eigentlich auch völlig egal, weil bei der Startkonfiguration, wie sieht das Band dann wirklich aus in Wirklichkeit? Das Band ist komplett leer, wenn das Wort leer ist. Das heißt, es ist völlig egal, wo wir eigentlich den Kopf hinmalen, weil wir haben ja unendlich viele Zellen nach links und nach rechts. Bei einer Turing-Maschine. Nachher ist es vielleicht nicht mehr ganz egal, wenn wir das Band irgendwie beschränken wollen. So, die Transitionsrelation ist natürlich ein bisschen mühselig zu definieren, weil wir diese vielen Richtungen haben, aber wir machen es trotzdem. Also, wir nehmen wieder an, dass Z Sigma Gamma Delta Z0 Blank-Symbol E eine Turing-Maschine ist und definieren jetzt diese Relation V-M als Transitionsrelation für Konfigurationen der Turing-Maschine wie folgt. Wobei wir natürlich die ganze Zeit die Zustandsübergang, Funktion Delta verwenden. Für eine deterministische Turing-Maschine ist es klar, bei der nicht-deterministischen nehmen wir immer an, dass es eine Möglichkeit ist, die hier definiert wird. Die erste Möglichkeit sagt, wir haben ich male es immer noch dazu, wir haben irgendwie das Wort B1 bis BM auf dem Band stehen, dann kommt das Wort A1 bis AN auf dem Band und danach kommen ja nur noch Blanks. Wir müssen immer daran denken, unendlich viele nach links und nach rechts und unser Kopf steht auf dem A1. Wenn wir dann einen Übergang haben nach Z'CN, was passiert dann? Wir sind ja noch im Zustand Z, dann sind wir danach im Zustand Z' und danach steht auf dem Band B1, BM und wir haben C geschrieben, also C jetzt statt dem A1, dann A2 bis AN. Pünktchen, Pünktchen, Pünktchen. Wo ist der Kopf? Ja, wir haben ja neutral gesagt N, also ist der Kopf jetzt weiterhin auf dem C. Das ist der Fall, also Z darf kein Endzustand sein für alle diese Fälle, sonst ist kein Übergang mehr definiert, wenn Z in dem E drin ist. Das habe ich vergessen zu sagen. Jetzt kommen die nächsten Fälle. Der nächste Fall sieht genauso aus, nur wir haben kein N, sondern wir haben jetzt ein L. Dann male ich jetzt einfach mal hier Pünktchen, Pünktchen, Pünktchen, weil es sieht ja genauso aus. Und wenn wir aber ein L haben, dann steht danach eben der Kopf auf dem BM. Dann kommt immer noch das C, A2 bis AN. Und wir sind natürlich im Zustand Z'. Das war für das L. Für das R ist es natürlich klar, ihr könnt euch schon denken, der Kopf geht jetzt nach rechts, das heißt danach haben wir B1 bis BM, A2 bis AM. AN ist das hier eigentlich, genau. Und wir sind auch im Zustand Z'. Und der Kopf steht jetzt auf dem A2, weil er ist ja nach rechts gewandert. So, jetzt gibt es noch so Spezialfälle. Die letzten beiden sind Spezialfälle, nämlich wenn wir sozusagen am Ende des Wortes sind. Das heißt, wenn es vorher so aussieht, das bräuchte ich wieder eine neue Farbe am besten. Wir haben irgendwie auf dem Band B1 bis BM stehen. Und dann kommt unser A1. Unser Kopf steht ja dann auf dem A1, jetzt kommt schon das Blank-Symbol, jetzt ist es vorbei. Und wir machen einen Schritt nach rechts, dann passiert natürlich genau das, was man sich denkt. Der Kopf geht um 1 nach rechts und wir setzen natürlich das A1 durch C. Das heißt, der Kopf ist danach auf dem Blank-Symbol. Und das muss man eben hinschreiben hier, dass vor allem ein Blank-Symbol da erscheint. Die letzte Regel habe ich keinen Platz für. Es ist aber genau die gleiche Regel, nur dass wir nach links gehen und unser Kopf ganz links schon steht. Ja, dann müssen wir halt links tatsächlich so ein Blank-Symbol hinzufügen neben dem C. Und das sind jetzt die ganzen Möglichkeiten für die Transition, hingeschrieben mit den Konfigurationen. Das heißt, wir können jetzt schön spielen mit diesen Turing-Maschinen, können die laufen lassen. Zunächst noch ein bisschen weitere Notationen. Für die i-fache Anwendung der Transitionsrelation schreiben wir einfach die Relation hoch i. Für die reflexiv-transitive Hülle, das heißt 0 oder mehrfache Anwendung, schreiben wir das Sternchen. Und wir lassen den Index m für die Maschine hier weg, wenn er klar ist. Dann schreiben wir nur dieses V-Dash-Symbol bzw. V-Dash hoch i bzw. V hoch Stern. Wir nehmen an, dass die Turing-Maschine anhält, sobald sie den Endzustand erreicht. In dem Schöning-Buch ist es ein bisschen anders definiert. Man kann immer die Definition so ein bisschen… variieren. Wir nehmen einfach an, dass wir anhalten, sobald es nicht mehr weiter geht. So hatten wir das ja auch genau hier in der Transitionsrelation definiert. Wir haben immer gesagt, der Zustand Z darf kein Endzustand sein. Wenn wir einen Endzustand haben, dann machen wir keine weiteren Schritte mehr. Die akzeptierte Sprache einer Turing-Maschine können wir jetzt endlich definieren. Also sei m gleich Z Sigma Gamma Delta Z Null Blank Symbol E eine Turing-Maschine. Die von m akzeptierte Sprache ist einfach definiert. Das sind alle Worte aus Sigma Stern. So, dass es uv aus dem Bandalphabet gibt, also Worte über dem Bandalphabet gibt und einen Zustand Z, der ein Endzustand ist, sodass wir mit der Startkonfiguration, also Startzustand und dem Wort w, mit beliebig vielen Schritten in den Zustand kommen mit der Konfiguration u, z, v. Das heißt, ein beliebiges Wort auf dem Band, aber der Zustand Z hier, der muss ein Endzustand sein. Das ist die wichtige Bedingung. Und so ist die akzeptierte Sprache einer Turing-Maschine festgelegt. Triviale Beispiele für Turing-Maschinen der Form Z Sigma Gamma Delta Z Null Blank Symbol E mit Z Null in E. Also wenn der Startzustand ein Endzustand ist, dann gilt sofort, dass die Maschine alles akzeptiert, weil sie jede Eingabe sofort akzeptieren. Wir müssen gar nicht losrechnen, wir können auch gar nicht rechnen. Wir Turing-Maschinen der Form Z Sigma Gamma Delta Z Null Blank Symbol E. Also leere Menge, das heißt es gibt keine Endzustände, gilt natürlich, dass sie gar nichts akzeptieren, das heißt die leere Sprache nur akzeptieren, weil sie können nie akzeptieren, nie anhalten. Sie kommen ja nie in Endzustand. Für die Darstellung als Zustandsgraph machen wir das Ganze wieder analog, wie wir es vorher schon gemacht haben. Wenn wir so einen Übergang haben mit vom Zustand Z in den Zustand Z', dann gibt es eben eine Kante in dem Graph. Und die ist beschriftet mit A ist das Bandsymbol, was wir lesen müssen, B ist das, was A ersetzt, das Bandsymbol und X ist die Richtung. Die schreiben wir hier mit dran. Also A Doppelpunkt B, X meint, wir lesen im Zustand Z das Symbol A unter dem Schreiblesekopf und danach überschreiben wir es mit dem Buchstaben B und wechseln in unseren Kopf entsprechend der Richtung X. Schauen wir uns ein Beispiel an, das kommt aus dem Schöning-Buch, das Beispiel. Es hat vier Zustände. Wir sehen hier auch gleich den Zustandsgraph. Wir haben also die vier Zustände. Das Eingabealphabet ist 0, 1, das Bandalphabet ist 0, 1 und Plank. Startzustand ist Z0. Das Plank-Symbol ist eben diese Box. Und nur der einzige Endzustand ist Z3. Und wir haben hier diese Übergänge. Da kann man sich mal angucken, was die sagen. Wenn wir Plank lesen im Zustand Z0, dann gehen wir in den Zustand Z1, überschreiben Plank mit Plank und der Kopf wechselt nach links. Wenn wir im Zustand Z0 eine 0 lesen, dann lassen wir die 0 stehen und wechseln nach rechts. Wenn wir eine 1 lesen, lassen wir die 1 stehen und wechseln nach rechts. Das heißt, im Zustand Z0 rattern wir die ganze Zeit. So kann man sich das vorstellen. Wir sind irgendwie am Anfang an dem Band. Irgendwo unser Kopf hier steht hier und wir stehen hier irgendwie 0 und 1 drauf auf dem Band. Was wir machen, wir rattern die ganze Zeit nach rechts, bis wir irgendwann auf ein Plank-Symbol treffen. Wenn wir an dem Plank-Symbol sind, dann gehen wir hier hin. Im Zustand Z1, das heißt, dann springt die Maschine mit dem Kopf um ein Symbol zurück. Das heißt, der Kopf ist dann hier, weil der Kopf springt ja nach links. Also im Zustand Z1, wenn wir die zum ersten Mal erreichen, haben wir die ganze Binärzahl, die da steht, abgearbeitet nach rechts und stehen jetzt auf dem letzten Symbol. So, was machen wir jetzt als nächstes? Wenn wir eine 1 lesen, ersetzen wir sie durch eine 0 und wenn wir eine 0 lesen, ersetzen wir sie durch eine 1. Aber beim 1 lesen, also 1 durch 0 ersetzen. Verbleiben wir in Z1, während wir beim 0, wenn wir die erste 0 lesen, dann wechseln wir in den Zustand Z2.

Das heißt, wir rattern jetzt wieder hier zurück, kann man sich das vorstellen, und tauschen aber Einsen durch Nullen und Nullen durch Einsen. Aber nur einmal eine Null durch eine Eins. Sobald wir eine Null durch eine Eins tauschen, sind wir im Zustand Z2. Was machen wir da? Da rattern wir weiter nach links, aber wir tauschen nichts mehr, sondern die Symbole sind gleich. Das machen wir so lange im Zustand Z2, bis wir jetzt hier vorne sind, bis wir wieder bei dem Planck-Symbol sind, was davor steht. Beziehungsweise, es geht auch von dem Zustand Z1 aus, also wenn wir nie in Z2 gekommen sind, dann rattern wir auch bis zum Planck-Symbol. Es passiert hier noch etwas Unterschiedliches, wenn man genau hinschaut. Wenn wir vom Zustand Z1 auskommen, dann ersetzen wir das Planck-Symbol durch eine Eins. Wenn wir vom Zustand Z2 auskommen, dann ersetzen wir das Planck-Symbol gar nicht, sondern es bleibt beim Planck-Symbol. Zustand Z3 akzeptieren wir. Die Übergänge hier brauchen wir trotzdem, weil wir ja eine deterministische Turing-Maschine vielleicht definieren wollen. Das heißt, dann müssen alle Zustände auch definiert werden. Was macht jetzt die Turing-Maschine? Sie interpretiert die Eingabe als Binärzahl und addiert 1. Deswegen haben wir genau bei den Nullen immer aus einer 0 eine 1 gemacht und sind dann gewechselt in den Zustand, dass sich nichts mehr ändert. Und wenn wir aus einer 1 eine 0 machen, haben wir noch einen Übertrag. Das heißt, wir bleiben in Z1. In Z0 wird das rechte Ende gesucht, dann wird in Z1 gewechselt. In Z1 wird versucht, 1 zur aktuellen Ziffer hinzuzuadieren. Gelingt das ohne Übertrag, dann wechseln wir in Z2. Bei Übertrag bleiben wir in Z1. Und müssen plus 1 zur nächsten Ziffer links addieren. In Z2 laufen wir bis zum Anfang, dann in Z3 und in Z3 wird akzeptiert. Ja, schauen wir uns ein Beispiel an für den Ablauf von der Turing-Maschine. Unsere Anfangskonfiguration ist Z00111. Ich male die auch nochmal hin, damit es irgendwie besser ist. Wir haben auf dem Band stehen 00111. Und daneben stehen natürlich unendlich viele Blank-Symbole, die ich auch mal hinmale. Und dann haben wir hier die Z3. Und wir haben den Kopf. Und der Kopf steht auf der ersten Null. Deswegen steht das Z0 hier vorne. Und der Automat ist im Zustand Z0. So, jetzt machen wir den ersten Schritt. Das heißt, wir sind im Zustand Z0. Und lesen ja eine Null auf dem Band. Und jetzt sagt uns die Maschine, was wir machen sollen. Wir sollen eine Null schreiben und den Kopf nach rechts wechseln. Das heißt, der nächste Zustand sieht so aus. Ich muss hier ein bisschen kleiner schreiben. Dass sich nichts geändert hat. Auf dem Band, weil wir die Null durch eine Null ersetzt haben. Unser Kopf ist um 1 weiter nach rechts gewechselt. Und ist immer noch im Zustand Z0 die Steuerung. So, jetzt kommt das Gleiche nochmal. Das heißt, der Kopf wechselt nochmal nach rechts. Ich versuche es hier hinzumalen. 0011. Immer noch in Z0. Jetzt lesen wir eine 1. Das heißt, wir nehmen jetzt hier diesen Übergang. Der sieht aber im Grunde auch genauso aus. Er ersetzt die 1 durch eine 1 und wechselt nach rechts. Auch das machen wir jetzt zweimal. Also ich mache mal hier. Ich kann mal beides hinmalen. Ich versuche es hinzumalen. Wir haben 0011. Der Kopf ist hier. Immer noch in Z0. Und jetzt machen wir das Gleiche nochmal. Dann haben wir 0011 blank. Das heißt, der Kopf ist jetzt auf dem blank-Symbol Z0. Jetzt müssen wir gucken, was passiert, weil es im Zustand Z0 bei dem blank-Symbol A ist. Dann nehmen wir den Übergang hier. Hier zu Z1 und was machen wir da? Ja, wir ersetzen blank durch blank und der Kopf wandert aber nach links. Das heißt, der nächste Zustand sieht so aus 0011 blank. Und der Kopf zeigt jetzt auf die 1 hier und wir sind im Zustand Z1. Im Zustand Z1 lesen wir jetzt eine 1, müssen wir die 1 dazu addieren. Zustand Z1 gehen wir mit der 1, bleiben wir im Zustand 1, wie wir sehen, ersetzen die 1 durch eine 0 und der Kopf wechselt nach links. Das heißt, danach haben wir jetzt das Stehen 0010, weil wir die 1 durch eine 0 ersetzt haben. Und der Kopf ist wieder 1 nach links gewechselt. Jetzt ist er auf dieser 1, immer noch im Zustand Z1. Jetzt passiert das Gleiche nochmal. Das heißt, wir haben das Stehen 0000 und der Kopf ist noch 1 weiter rüber gewechselt, hier auf diese 0. Das heißt, jetzt sind wir im Zustand Z1 und lesen jetzt eine 0, das heißt, wir nehmen hier diese Kante. Dabei wird die 0 durch eine 1 ersetzt und wir wechseln in den Zustand Z2. Das heißt, ich mache mal hier irgendwo hier unten weiter. Wir sind dann jetzt bei 0100 blank und unser Kopf ist hier und wir sind im Zustand Z2. So, Z2 mit einer 0 sind wir hier, verbleiben wir in Z2. Und wir ändern auch nichts an dem Band. Wir schreiben wieder eine 0 raus und unser Kopf ist noch 1 weiter nach links gewechselt. Das ist jetzt hier. Jetzt nehmen wir im letzten Schritt dann hier diese Kante und wechseln damit in den Zustand Z3. Also hier waren wir noch in Z2. Wechseln jetzt in den Zustand Z3 mit 0100. Da blinkt es davor. Und unser Kopf steht jetzt auf 0100. Und unser Kopf steht jetzt auf 0100. Auf der 0 und wir sind in Zustand Z3 und akzeptieren jetzt. Das heißt, wir sind jetzt fertig. Jetzt könnte man irgendwie noch fragen, muss man den Kopf immer noch richtig rücken, sonst wie? Also es ist so eine gute Praxis, wenn der Kopf, wenn er am Anfang auf dem ersten Symbol der Eingabe steht, dass er am Ende auf dem ersten Symbol der Ausgabe steht. Hat den Vorteil, wenn man zum Beispiel jetzt mehrere solche Turing-Maschinen hat oder die zweimal laufen lassen würde, in Anführungszeichen, würde sie nichts falsch machen. Also wenn Sie jetzt zweimal eins addieren, können Sie einfach die Turing-Maschine zweimal hintereinander ausführen und es würde funktionieren. Wenn Sie den Kopf sonst wo stehen hätten, würde es eben halt nicht funktionieren, die einfach so aneinander zu hängen. Dann müssten Sie erst den Kopf zurückfahren. Können wir noch gucken, ob die Maschine richtig gerechnet hat, also ob sie wirklich eins addiert hat. 0, 0, 1, 1 plus 1 ergibt, das kann man nochmal so rechnen, gibt hier eine 0, Übertrag 1, gibt eine 0, Übertrag 1, gibt eine 1 und eine 0. Also ist korrekt gerechnet, das heißt, die Turing-Maschine addiert 1 dazu. Die… Jetzt kommen wir zu einer Variante der Turing-Maschinen, die LBAs. Das sind linear beschränkte Turing-Maschinen. Die Idee ist, der Schreib-Lese-Kopf darf den Bereich der Eingabe auf dem Band nicht verlassen. Das heißt, Sie können sich vorstellen, wir haben irgendwie diese Eingabe, da steht unser Wort W und eigentlich habe ich ja gesagt, wir haben hier unendlich viele Zellen, die alle mit dem Blank-Symbol belegt sind. Beim LBA, bei einer linear beschränkten Turing-Maschine, ist die Idee, dass die Turing-Maschine im Grunde nur in diesem Bereich mit ihrem Kopf bleibt und der Kopf… Der Kopf darf hier nie rausrutschen. Also dafür müssen wir aber das Ende erkennen. Das heißt, die Turing-Maschine muss wissen, wann sie das letzte Symbol der Eingabe liest, wann sie hier ist. Und das wird gemacht, indem einfach eine Kopie des Alphabets genommen wird. Also nehmen wir an, das Alphabet ist A1 bis An. Dann nehmen wir noch so eine Kopie mit einem Hütchen drüber. Hütchen A1 bis Hütchen An. Das heißt, und dann ist die Eingabe der LBAs statt dem Wort W A1 bis Am nun A1 bis Am minus 1 und dann kommt Hütchen An. Das heißt, das letzte Symbol ist markiert mit dem Hütchen Am, um zu erkennen, hier ist Ende. Hier steht also ein Hütchen mit drin. Dadurch kann die Maschine weiße, wann es am Ende ist und dass sie nie hier rausspringen darf. Das linke Ende ist am Anfang nicht markiert. Das muss die Maschine selbst markieren, wenn sie das markieren will. Sie kann als ersten Schritt einfach zum Beispiel A1 ersetzen durch Hütchen A1. Definitionen, nicht-deterministische Turing-Maschine, Z Sigma vereinigt, Hütchen Sigma, Sigma Gamma, Delta Z 0, blanks und blanks. Z 0 E heißt linear beschränkt, LBA im Englischen für Linear Bounded Automated. Wenn für alle A1 bis Am in Sigma plus und alle Konfigurationen UZV mit Z 0 A1 bis Am minus 1 Hütchen Am geht über mit der Transitionsrelation in UZV, gilt die Länge von UV ist kleiner gleich m. So ziemlich viel Notation. Das heißt aber alles, was wir erreichen. Mit der Transitionsrelation, alles, was erreichbar ist, jeder Zustand hat niemals mehr als m Symbole auf dem Band und m war genau unsere Eingabelänge. Die akzeptierte Sprache ist klar. Die sind alle Worte A1 bis Am, sodass wir mit Z 0 A1 bis Am minus 1 Hütchen Am starten, in eine Endkonfiguration kommen, wo der Zustand Z ein Endzustand ist. LBAs sind definiert als nicht-deterministische Turing-Maschinen. Wichtig, wenn später vielleicht noch. Resultate dazu sehen. Ich denke heute nicht. Aber wie das aussieht mit den deterministischen, deterministischen Variante. Ein wichtiger Satz ist der Satz von Coroda, den wir hier in dieser Vorlesung heute nicht beweisen werden, aber in FSK beweisen werden, ist, dass die kontextsensitiven Sprachen genau von den LBAs erkannt werden. Das heißt genau diese linear beschränkten Turing-Maschinen, die beschreiben genau die kontextsensitiven Sprachen, also die Typ 1 Sprachen. Für die TIMI-Zuhörer werden wir diesen Satz ja gar nicht beweisen, sondern die müssen den sozusagen als gegeben hinnehmen. Für die FSK-Zuhörer werden wir den Satz von Coroda dann noch beweisen. Trotzdem möchte ich hier schon die Idee des Beweises kurz erklären. Da hat er halt zwei Richtungen. Schau mal, muss man sich wieder klar machen. Man hat zwei Richtungen. Einmal muss man zeigen, wenn L kontextsensitiv ist, dann wird L von einem LBA erkannt. Ja, es gibt ein LBA. Der LBA erkennt oder akzeptiert. Was man dafür macht, ist, was macht der LBA? Der LBA versucht einfach alle Worte der Wortlänge, Länge von W, versucht alle Worte mit Länge höchstens W, Länge von W herzuleiten, abzuleiten und zu prüfen, ob W abgeleitet wurde. So, jetzt muss er sich nur noch klar machen. Wie er sich darstellt, dass er die Worte einstellt. Jetzt kommt er dazu.

dass das im Grunde in den Platz der Eingabe geht. Also man hat die Länge W, man hat das Wort, also von der Länge W an Platz nur zur Verfügung im Grunde und muss jetzt gucken, dass man nie darüber hinauskommt. Das funktioniert genau aufgrund dieser Beschränkung der Produktionsregeln, dass sie nämlich nicht schrumpfen dürfen. Das heißt, wenn wir einmal über ein Wort haben, was über die Länge W hinausgehen würde, können wir aufhören, weil wir wissen dann, das Wort oder die Satzform wird nicht mehr kleiner, sondern die wird auf jeden Fall zu groß. Genau aus diesem Grund reicht uns dieser Platz aus, weil wir müssen nie weiterkommen. Wir müssen Worte herleiten, die größer oder länger sind als das Zielwort. Das war genau dieses Bild vom Anfang. Wenn Sie irgendwie die Produktionsschritte sehen, dann wächst das sozusagen monoton, die Ableitung in der Wortlänge bei einer kontextsensitiven Sprache, während es bei einer allgemeinen nicht kontextsensitiven Sprache passieren kann, dass sie erst größer werden und dann wieder schrumpfen. Genau das ist nicht möglich, wenn Sie sich an dieses Bild von einer der ersten Vorlesungen erinnern. Das ist die eine Richtung. Für die andere Richtung, es gibt ja noch eine zweite Richtung, müssen Sie zeigen. Das ist die eine Richtung. Für die andere Richtung, es gibt ja noch eine zweite Richtung, müssen Sie zeigen. Das ist, wenn es ein LBA in der Sprache L akzeptiert, dass es dann auch eine kontextsensitive Grammatik gibt, die L akzeptiert, die L-Herd erzeugt. Das ist ein bisschen aufwendiger. Das heißt, Sie müssen eine Grammatik konstruieren, die genau den Ablauf von diesen LBAs oder Turing-Maschinen, das ist ein bisschen aufwendiger. Das heißt, Sie müssen eine Grammatik konstruieren, die genau den Ablauf von diesen LBAs oder Turing-Maschinen, und die linear beschränkte Turing-Maschine ein Modell für die Typ-1-Sprache. Deswegen haben wir die Turing-Maschine auch jetzt eingeführt, weil es sozusagen die letzten beiden Sprachklassen sind, die wir noch nicht betrachtet haben. Und bei beiden Sprachklassen die Turing-Maschine das richtige Modell ist. Nur bei den kontextsensitiven Sprachen sind es eben die linear beschränkten Turing-Maschinen, während es bei den beliebigen, bei den rekursiv aufzählbaren Sprachen, die Typ-0-Sprachen, eben beliebige Turing-Maschinen sind. So, wie ist es jetzt mit den nicht deterministischen? Bei den nicht deterministischen Turing-Maschinen, ja, bei den allgemeinen Turing-Maschinen, also ohne die lineare Beschränkung, können nicht deterministische Turing-Maschinen einfach durch deterministische simuliert werden, indem man einfach alle Möglichkeiten nacheinander durchprobiert. Das heißt, man zählt irgendwie so ab, was für Möglichkeiten hat die Turing-Maschine, der Verzweigungsgrad ist ja immer endlich mit den Möglichkeiten, mit den nicht deterministischen, probiert die einfach nacheinander aus, wie in so einem Berechnungsbaum, können Sie sich das vorstellen. Daher gilt der letzte Satz, also der Satz, dass die nicht deterministischen Turing-Maschinen die Typ-0-Sprachen akzeptieren, tatsächlich auch für die deterministischen Turing-Maschinen, weil die sich nicht unterscheiden bezüglich der Ausdruckskraft, was sie akzeptieren. Der Unterschied zwischen nicht deterministischen Turing-Maschinen und deterministischen Turing-Maschinen kommt erst zum Tragen, wenn wir das Laufzeitverhalten dann genauer betrachten, das kommt erst im Kapitel zur Komplexitätstheorie. Was wichtig ist, dieses Resultat gilt natürlich erstmal nicht für die LBAs, beziehungsweise man weiß es nicht so genau, was da gilt. Aber die LBAs sind immer nicht deterministisch definiert. So, damit sind wir jetzt tatsächlich mit den formalen Sprachen durch. Wir haben noch ein paar Beweise offen, die die FSK-Zuhörer in den nächsten beiden Videos oder Vorlesungen sehen werden. Die TIMi-Zuhörer nicht. TIMi-Zuhörer sollten sich aber die Turing-Maschinen gut merken, weil wir werden mit den Turing-Maschinen jetzt viel arbeiten und uns um Rechenbarkeit kümmern und Probleme, welche berechenbar sind. Bevor wir dazu kommen, möchte ich aber hier zum Ende dieser Vorlesung noch mal einen Überblick geben über die Grammatiken-Automaten für die Chomsky-Hierarchie, die wir gesehen haben. Sehen Sie hier auf dieser Folie schon. Wir haben hier die Chomsky-Hierarchie mit Typ 0, Typ 1, Typ 2, Typ 3. Und wir haben zwischendrin noch die deterministisch-kontextfreien Sprachen, die ja eine Teilmenge der Typ-2-Sprachen sind. Sie sind echt größer als die Typ-3-Sprachen. Die passenden Grammatiken dazu. Das sind die Typ-0-Grammatiken, die Kontext-7-Grammatiken, die kontextfreien Grammatiken, die regulären Grammatiken. Bei deterministisch-kontextfreien gibt es natürlich auch eine Klasse von Grammatiken. Das sind die LRK-Grammatiken. Die haben wir nicht gesehen, werden wir auch nicht sehen, aber damit Sie es wissen, habe ich es hier hingeschrieben. Die Automaten-Modelle sind die endlichen Automaten bei den regulären Sprachen, sowohl deterministisch als auch nicht deterministisch. Es sind die deterministischen Kellerautomaten bei den deterministisch-kontextfreien Sprachen, die DPDAs. Bei den kontextfreien Sprachen sind es die Kellerautomaten, nicht deterministisch natürlich, also man braucht nicht deterministische, weil die deterministisch in einer echten Teilmenge sind. Bei den Typ-1-Sprachen sind es die linear beschränkten Turing-Maschinen, die LBAs, die sind auch nicht deterministisch. Bei den Typ-0-Sprachen sind es eben die Turing-Maschinen, sowohl deterministisch als auch nicht deterministisch. Wir haben bei den Typ-3-Sprachen noch als sonstigen Formalismus die regulären Ausdrücke gesehen. Bei den anderen Sprachen gibt es natürlich auch noch viele weitere sonstige Formalismen, die wir nicht gesehen haben. Hier unten bei den Typ-0-Sprachen werden wir tatsächlich auch noch ein paar sehen. Trennende Beispiele. Die Sprache A hoch N, B hoch N mit N in N ist in Typ-2 aber nicht vom Typ-3, also ist nicht regulär, aber kontextfrei. Die Sprache W mit W ist ein Palindrom, ist Typ-2 aber nicht deterministisch kontextfrei. Das heißt, man muss raten, wann man sozusagen den Rest vom Wort rückwärts liest. Die Sprache A hoch N, B hoch N, C hoch N ist vom Typ-1, also kontextsensitiv, aber nicht vom Typ-2, also nicht kontextfrei. Und die Sprache H, die haben wir noch nicht gesehen. Das sind alle Turing-Maschinen-M, die auf dem Eingabewort W anhalten. Die ist tatsächlich vom Typ-0, aber nicht vom Typ-1. Das heißt, die Sprache ist das sogenannte Halteproblem. Das werden wir später noch genau betrachten und erläutern. Und diese Sprache ist wie gesagt Typ-0, aber nicht vom Typ-1. Und es gibt dann tatsächlich auch noch Sprachen, die in der Hierarchie gucken. Sprachen, die in gar keinem Typ, von gar keinem Typ sind. Das ist das Komplement, die Sprache H, die ist nicht vom Typ-0. Die liegt sozusagen außerhalb der ganzen Hierarchie. Was gibt es noch zu sagen? Deterministisch versus nicht deterministisch. DFAs und NFAs bei den regulären Sprachen haben wir ja gesehen, die sind äquivalent. Die DPDAs und DPDAs, also Kellerautomaten und nicht deterministische Kellerautomaten sind nicht äquivalent. Haben wir gesehen. Bei den LBAs, also den linear beschränkten Turing-Maschinen, ist es tatsächlich unbekannt. Da werden wir die FSK-Zuhörer in der nächsten Vorlesung auch noch was dazu hören. Und bei den deterministischen Turing-Maschinen und den nicht deterministischen Turing-Maschinen ist es wieder so, dass sie äquivalent sind. Weil man die einen durch die andere einfach simulieren kann. Bei den Abschlusseigenschaften, wenn Sie daran denken. Bei den regulären Sprachen, die waren sozusagen gutartig. Die sind abgeschlossen bezüglich Schnittvereinigung, Komplement, Produkt und klinischen Abschluss. Also überall ein Ja. Die deterministisch-kontextfreien sind tatsächlich nur abgeschlossen, interessanterweise gegenüber dem Komplement, aber gegenüber sonst nichts. Die kontextfreien Sprachen sind abgeschlossen gegenüber Vereinigung, Produkt und klinischen Abschluss, aber nicht abgeschlossen gegenüber Schnitt und Komplement. Die kontextsensitiven Sprachen sind wieder überall abgeschlossen. Schnittvereinigung, Komplement, Produkt, klinischer Abschluss. Haben wir nicht gesehen, aber können Sie mir glauben. Und die Typ 0 Sprachen, die sind abgeschlossen bezüglich Schnittvereinigung, Produkt und klinischen Abschluss. Klinischer Abschluss, aber nicht abgeschlossen gegenüber Komplement. Das haben wir gerade eben gesehen. H ist Typ 0, aber das Komplement vom Halteproblem ist eben nicht in Typ 0. Das ist genau so ein trennendes Beispiel, warum die Typ 0 Sprachen nicht abgeschlossen sind gegenüber dem Komplement. Entscheidbarkeiten. Das Wortproblem ist für Typ 1 und damit auch für Typ 2 und Typ 3 und deterministisch-kontextfrei entscheidbar. Für Typ 0 ist es nicht mehr entscheidbar. Der Beweis steht natürlich noch aus. Das Leerheitsproblem, also ob die erzeugte Sprache leer ist, ist bei Typ 2 deterministisch-kontextfrei und Typ 3 entscheidbar. Aber bei Typ 1 nicht mehr entscheidbar, bei Typ 0 auch nicht mehr entscheidbar. Das Äquivalenzproblem, also ob zwei durch Grammatiken gegebene Sprachen die gleiche Sprache erzeugen, ist bei Typ 3, also regulär, und bei deterministisch-kontextfrei noch entscheidbar. Aber bei Typ 0, Typ 1, Typ 2 nicht entscheidbar. Also selbst bei kontextfrei nicht mehr entscheidbar. Das Schnittproblem ist sogar bei deterministisch-kontextfrei nicht mehr entscheidbar. Schnittproblem war, ob der Schnitt von zwei Sprachen leer ist. Letzte Folie. Ups, jetzt bin ich eins zu weit. Die Komplexität des Wortproblems. Bei Typ 3, wenn der DFA gegeben ist, ist es natürlich lineare Komplexität, weil er ist ja völlig deterministisch. Wir brauchen einfach nur den Automaten durchrennen lassen. Genauso gilt es bei den DPDAs, den deterministischen Kellerautomaten. Wenn der gegeben ist, können wir auch lineare Komplexität erreichen. Bei Typ 2, wenn wir die Chomsky-Normalform gegeben haben, ist es kubisch in der Größe der Grammatik, in der Größe des Wortes. Die Größe des Grammatiks muss man eigentlich auch noch zählen. Die Größe der Grammatik kann man aber auch einfach erstmal als konstant annehmen. Die Chomsky-Normalform muss schon gegeben sein, weil die die Grammatik sonst noch aufblähen kann. Bei Typ 1 ist es exponentiell, der Algorithmus, und bei Typ 0 ist es ja nicht entscheidbar, daher nicht lösbar. Damit sind wir jetzt tatsächlich mit den formalen Sprachen für die TIMi-Zuhörer durch. Für die FSK-Zuhörer haben wir noch ein paar Vorlesungen, also ich glaube zwei, zu den Beweisen, zu den Aussagen, die wir heute nicht gesehen haben. Die Turing-Maschine, wie gesagt, wurde jetzt schon eingeführt. Die dürfen Sie nicht vergessen. Die Turing-Maschine wird uns jetzt ziemlich lange, also eigentlich bis zum Rest der Vorlesung, immer wieder begleiten und auch immer wieder einführen. Das muss ein wesentliches Maschinenmodell sein, das heißt, Sie sollten die gut verinnerlichen.

<!-- DISQUS SCRIPT COMMENT START -->

<!-- DISQUS RECOMMENDATION START -->

<div id="disqus_recommendations"></div>

<script> 
(function() { // REQUIRED CONFIGURATION VARIABLE: EDIT THE SHORTNAME BELOW
var d = document, s = d.createElement('script'); // IMPORTANT: Replace EXAMPLE with your forum shortname!
s.src = 'https://myuninotes.disqus.com/recommendations.js'; s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>
Please enable JavaScript to view the 
<a href="https://disqus.com/?ref_noscript" rel="nofollow">
comments powered by Disqus.
</a>
</noscript>

<!-- DISQUS RECOMMENDATION END -->

<hr style="border: none; height: 2px; background: linear-gradient(to right, #f0f0f0, #ccc, #f0f0f0); margin-top: 4rem; margin-bottom: 5rem;">
<div id="disqus_thread"></div>
<script>
    /**
    * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://myuninotes.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

<!-- DISQUS SCRIPT COMMENT END -->

<!-- Modal START -->
<div id="myModal" class="modal">
  <div class="modal-content">
    <span id="closeModal" class="close">&times;</span>
    <p class="modal-text">
      If MyUniNotes has been helpful and you’d like to support my efforts, <span class="modal-highlight"> you can contribute with a donation: <a class="modal-dono-link" href="https://paypal.me/myuninotes4u">Donate via PayPal</a> :) </span> Your support will help me continue improving the content, but there is no obligation to donate.
    </p>
    <p class="modal-text">
      <span class="modal-highlight">MyUniNotes is a personal, non-revenue project as I believe in accessible education for everyone.</span> Please note that these are my own notes and solutions, and I cannot guarantee the complete accuracy of all solutions as I am still a student myself.
  </div>
</div>

<script>
  // JavaScript to display the modal on page load
  document.addEventListener('DOMContentLoaded', function() {
    // Generate a random number between 1 and 1
    // Wanted it to load with a adjustable probability for every page load but did not work, as DOM is loaded only once. Therefore now loading it every time website is visited and DOM is loaded.
    const randomNumber = Math.floor(Math.random() * 1) + 1; 
    // console.log(randomNumber)
    if (randomNumber === 1) {
      setTimeout(function() {
        const modal = document.getElementById('myModal');
        if (modal) {
          modal.classList.add('show');
        }
      }, 1000); // Adjust the delay as needed

      const closeModal = document.getElementById('closeModal');
      if (closeModal) {
        closeModal.addEventListener('click', function() {
          const modal = document.getElementById('myModal');
          if (modal) {
            modal.classList.remove('show');
          }
        });
      }
    } else {
      // Ensure the modal is hidden if the random number is not 1
      const modal = document.getElementById('myModal');
      if (modal) {
        modal.style.display = 'none';
      }
    }
  });
</script>
<!-- Modal END -->
