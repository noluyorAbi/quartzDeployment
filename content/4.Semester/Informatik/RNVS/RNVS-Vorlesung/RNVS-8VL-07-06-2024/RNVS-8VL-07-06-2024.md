---
tags:
  - 4semester
  - informatik
  - RNVS
fach: "[[Rechnernetze und Verteilte Systeme (RNVS)]]"
Thema:
Benötigte Zeit:
date created: Friday, 7. June 2024, 09:30
date modified: Friday, 7. June 2024, 10:51
---

# Vorlesung Rechner, Netze und Verteilte Systeme - Kapitel 3: Transportschicht (Teil 7)

## Einführung

Herzlich Willkommen zur Vorlesung „Rechner, Netze und Verteilte Systeme“. Wir befinden uns im Kapitel 3 über die Transportschicht und dies ist der siebte und letzte Teil dieses Kapitels. Bis zu diesem Punkt sollten Sie ein grundlegendes Verständnis darüber haben, wie die Transportschicht funktioniert und welche Funktionen sie bietet. In diesem Teil vertiefen wir unser Wissen weiter und betrachten spezifische Aspekte der Transportschicht im Detail.

## Rückblick und Fokus

In den vorherigen Teilen haben wir über die Erhöhung der Kommunikationsleistung gesprochen – wie wir höheren Durchsatz und bessere Auslastung erreichen können. Jetzt wollen wir einen genaueren Blick auf die Zuverlässigkeit werfen und untersuchen, wie Flusskontrolle und Staukontrolle (Überlastkontrolle) funktionieren. Unser Ziel ist es, eine höhere Leistung bei geringerer Fehlerrate zu erreichen.

## Flusskontrolle und Staukontrolle

### Flusskontrolle (Flow Control)

Flusskontrolle bezieht sich auf die Verwaltung des Senders, um zu verhindern, dass der Empfänger überlastet wird. Das Ziel ist, dass der Empfänger nur so viele Daten erhält, wie er tatsächlich verarbeiten kann. Dazu benötigen wir ein Signal vom Empfänger, ob er bereit ist, die nächste Nachricht zu empfangen.

### Staukontrolle (Congestion Control)

Staukontrolle befasst sich mit Maßnahmen zur Vermeidung der Überlastung von Transit-Netzen. Im Internet nutzen viele Teilnehmer gleichzeitig dieselben Ressourcen. Wir müssen daher Strategien entwickeln, um unsere Nachrichten zu priorisieren und Verzögerungen zu minimieren, wenn andere Teilnehmer die Transit-Netze stark beanspruchen.

## Vergleich mit Straßenverkehr

Ein anschauliches Beispiel ist der Straßenverkehr. Stellen Sie sich vor, die Sender sind einzelne Häuser, die Nachrichten (Fahrzeuge) verschicken. Das Ziel (der Empfänger) ist ein Parkplatz, der nur eine begrenzte Anzahl an Fahrzeugen aufnehmen kann. Die Transit-Netze sind die Straßen und Kreisverkehre, die von den Fahrzeugen genutzt werden. Ziel ist es, den Verkehrsfluss so zu steuern, dass weder die Straßen noch der Parkplatz überlastet werden.

### Verkehrsmanagement im Detail

Wenn Fahrzeuge (Nachrichten) gesendet werden, müssen sie durch verschiedene Kreisverkehre (Router) navigieren, bis sie ihr Ziel erreichen. Die Ampel am Parkplatz zeigt an, ob ein Fahrzeug einfahren kann (Puffer beim Empfänger ist frei). Wenn die Ampel rot ist, muss das Fahrzeug warten (Sender muss pausieren).

## Lösungsansätze zur Flusskontrolle

### Stop-and-Wait-Technik

Hierbei sendet der Sender jeweils ein Paket und wartet auf die Bestätigung, bevor er das nächste Paket sendet. Diese Methode ist einfach, aber ineffizient bei langen Rundlaufzeiten (Roundtrip Delay).

### Fenstertechnik

Statt nur ein Paket zu senden, wird eine feste oder dynamisch angepasste Anzahl von Paketen (Fenstergröße) gleichzeitig gesendet. Bei dynamischer Anpassung wird die Fenstergröße basierend auf der Netzwerkbelastung verändert.

### Pufferreservierung

Der Sender fragt den Empfänger, ob genügend Pufferplatz verfügbar ist, bevor er eine Nachricht sendet. Dies vermeidet Überlastung, führt aber zu zusätzlicher Verzögerung durch die notwendige Kommunikation.

### Kreditverfahren

Pufferplatz wird im Voraus zugewiesen und verwaltet. Dieses Verfahren kann jedoch unflexibel sein, wenn sich die Netzwerklast ändert.

### Zeitrasterabhängiges Senden

Jeder Sender hat bestimmte Zeitfenster, in denen er Nachrichten senden darf. Dies vermeidet Überlastung, kann jedoch zu langen Wartezeiten führen, wenn viele Sender beteiligt sind.

## Praktische Umsetzung der Flusskontrolle

### Sequenznummern und Puffer

Der Sender und Empfänger arbeiten mit Sequenznummern und Puffergrößen. Der Empfänger bestätigt den Erhalt von Paketen und teilt mit, wie viel Pufferplatz noch verfügbar ist (Empfangsfenster).

### Ablauf

1. Der Sender sendet ein Paket mit einer Sequenznummer.
2. Der Empfänger empfängt das Paket, speichert es im Puffer und bestätigt den Empfang.
3. Der Empfänger teilt auch mit, wie viel Platz noch im Puffer verfügbar ist.
4. Der Sender sendet weitere Pakete basierend auf der verfügbaren Puffergröße.

### Weitere Details zur Flusskontrolle

Der Sender weiß, wie groß das Empfangsfenster (Receive-Window) ist, da dies mit der letzten Bestätigung vom Empfänger mitgeteilt wird. Der Sender kennt auch das letzte Byte, das er gesendet hat, und das letzte Byte, das bestätigt wurde. Daraus leitet er ab, was er als nächstes senden kann und wie viel der Empfänger verarbeiten kann.

Der Empfänger hat den gesamten Empfangspuffer (Receive-Buffer) zur Verfügung. Er unterscheidet zwischen den Bytes, die empfangen, aber noch nicht gelesen wurden, und den Bytes, die bereits vom Anwendungsprozess verarbeitet wurden. Das Empfangsfenster (Receive-Window) berechnet sich aus der Größe des Empfangspuffers minus der empfangenen, aber nicht gelesenen Daten und abzüglich des letzten Bytes, das von der Anwendung bereits verarbeitet wurde. Das Empfangsfenster hängt also davon ab, wie schnell der Anwendungsprozess die Daten verarbeitet.

Der Sender kann mehrere Segmente senden, solange der Empfangspuffer des Empfängers nicht überlastet wird. Der Empfänger kann dann Summenquittungen senden, die mehrere empfangene Segmente bestätigen. Dies ermöglicht eine effiziente Flusskontrolle und vermeidet die Überlastung des Empfängers.

## Staukontrolle (Congestion Control)

Während sich die Flusskontrolle auf die Vermeidung der Überlastung des Empfängers konzentriert, befasst sich die Staukontrolle mit der Vermeidung der Überlastung der Netzwerke (insbesondere der Transit-Netze). Die Herausforderung besteht darin, dass die Überlastung auf den unteren Schichten (Vermittlungsschicht) auftritt, aber auf der Transportschicht spürbar wird.

### Feststellung der Netzüberlastung

Es gibt zwei Hauptansätze zur Feststellung der Netzüberlastung:

1. **Explizite Rückmeldung**: Ein Protokoll wie das Explicit Congestion Protocol (XCP) informiert die Transportschicht über überlastete Router.
2. **Indirekte Indikatoren**: Verlust von Segmenten, erkennbar durch Timeouts oder fehlende Bestätigungen, deutet auf Überlastung hin.

### Reaktionsstrategien bei Überlastung

- **Virtuelle Kanäle**: Reservierung von Netzressourcen für eine Verbindung, vergleichbar mit reservierten Fahrspuren im Straßenverkehr. Dies ist ressourcenintensiv und hat eine lange Aufbauzeit.
- **Begrenzung der Verbindungen**: Begrenzung der Anzahl der Verbindungen pro Host, um die Netzbelastung zu reduzieren.
- **Sendezeitbeschränkungen**: Begrenzung der Datenmenge, die ins Netz gesendet wird, beispielsweise durch das Leaky Bucket Verfahren, bei dem nur eine begrenzte Datenmenge kontinuierlich ins Netz fließt.
- **Garantierte Abnahmeraten**: Sicherstellung, dass der Empfänger eine Mindestmenge an Daten verarbeitet, um Staus im Netz zu vermeiden.
- **Konstante Last**: Aufrechterhaltung einer konstanten Netzlast durch Begrenzung der Anzahl der Sendungen, ähnlich dem Taxi-Verfahren in Singapur.

### Implementierung der Staukontrolle im TCP

TCP verwendet eine dreistufige Strategie zur Staukontrolle:

1. **Slow Start**: Langsames Ansteigen der Senderate zu Beginn, um die Kapazität des Netzes zu ermitteln.
2. **Congestion Avoidance**: Lineares Wachstum der Senderate, um eine Überlastung zu vermeiden.
3. **Fast Recovery**: Schnelle Reduktion der Senderate bei Überlastung und anschließende vorsichtige Erhöhung.

### Wichtige Variablen und Mechanismen

- **Congestion Window (CWND)**: Begrenzt die Menge an Daten, die gesendet werden können, bevor eine Bestätigung erforderlich ist.
- **Threshold**: Schwellwert für das Congestion Window, der den Übergang von exponentiellem zu linearem Wachstum markiert.
- **Maximale Segmentgröße (MSS)**: Bestimmt die maximale Datenmenge pro Segment.

Die Kombination dieser Mechanismen ermöglicht es TCP, effizient auf Netzüberlastungen zu reagieren und die Netzwerkauslastung zu optimieren.

### Retransmission-Timer

Ein weiterer wichtiger Mechanismus ist der Retransmission-Timer. Wenn dieser Timer abläuft und noch nicht alle gesendeten Segmente bestätigt wurden, sendet der Sender die nicht bestätigten Segmente erneut. Dies verhindert Datenverlust und stellt sicher, dass alle Pakete ihren Zielort erreichen.

## TCP Tahoe und TCP Reno

### TCP Tahoe

TCP Tahoe beginnt mit dem sogenannten Slow Start. Das bedeutet, dass das Überlastfenster (Congestion Window) mit einer sehr kleinen Größe startet. Für jedes empfangene Bestätigungspaket verdoppelt sich die Größe des Überlastfensters, was zu einem exponentiellen Wachstum führt. Sobald ein bestimmter Schwellwert (Threshold) erreicht ist, wechselt das Wachstum zu einem linearen Anstieg, um das Netz nicht zu überlasten. Bei einem Timeout (keine Bestätigung innerhalb einer festgelegten Zeit) wird das Überlastfenster auf die Hälfte seiner aktuellen Größe reduziert, und der Slow Start beginnt von vorne.

### TCP Reno

TCP Reno optimiert das Verhalten von TCP Tahoe durch die Einführung von Fast Retransmit und Fast Recovery. Beim Empfang von drei Quittungsduplikaten (Anzeichen für ein verlorenes Segment) wird das fehlende Segment sofort neu gesendet (Fast Retransmit). Anstatt das Überlastfenster wie bei TCP Tahoe drastisch zu reduzieren und mit Slow Start neu zu beginnen, bleibt das Fenster bei TCP Reno relativ groß und wird nur auf die Hälfte der aktuellen Größe reduziert. Dadurch wird eine schnellere Erholung ermöglicht und die Netzwerkauslastung bleibt höher.

### Vergleich der Algorithmen

TCP Reno zeigt eine bessere Netzwerkauslastung im Vergleich zu TCP Tahoe, da es nicht vollständig auf den Slow Start zurückfällt, sondern das Überlastfenster nur reduziert. Dies führt zu einer effizienteren Nutzung der verfügbaren Netzwerkressourcen und einer schnelleren Wiederherstellung nach Paketverlusten.

### Additive Increase, Multiplicative Decrease (AIMD)

Ein weiteres Prinzip zur Stauvermeidung ist das AIMD-Prinzip. Hierbei wird die Senderate linear erhöht (Additive Increase) und bei Paketverlusten multiplicativ reduziert (Multiplicative Decrease). Dies führt zu einem zyklischen Verhalten der Senderate, die sich an der maximalen Kapazität des Netzes orientiert.

### Bezug zur aktuellen Situation der Corona-Pandemie

Dieses Prinzip der Staukontrolle kann auch auf die aktuelle Situation der Corona-Pandemie übertragen werden. Hier lassen wir die Maßnahmen laufen, bis ein bestimmter Wert, der Reproduktionsfaktor 1, erreicht ist. Wenn wir sehen, dass unsere Krankenhäuser überlastet sein könnten, führen wir wieder Restriktionen ein, ähnlich wie beim Reduzieren der Senderate bei Netzwerküberlastung. Danach werden die Restriktionen schrittweise wieder gelockert, was dem linearen Anstieg bei der Staukontrolle entspricht. Wenn jedoch erneut eine Überlastung droht, werden die Maßnahmen wieder verschärft. Aktuell befinden wir uns in der Phase des linearen Anstiegs, und es bleibt abzuwarten, ob eine erneute Überlastung auftritt, die weitere Maßnahmen erfordert.

## Durchsatz bei TCP

Um den Durchsatz bei TCP zu bewerten, betrachten wir das aktuelle Congestion-Window und den Wert, den es beim Paketverlust erreicht hat. Dabei berücksichtigen wir die Round-Trip-Time (RTT), also die Rundlaufzeit. Der Durchsatz pendelt zwischen dem Wert des Congestion-Window (W) geteilt durch 2\*RTT und W/RTT. Dies führt zu einer typischen Sägezahnkurve, bei der der Durchsatz zwischen der Hälfte von W und W liegt, also etwa 75 % der maximalen Netzwerkauslastung erreicht. Dieser Wert kann je nach Anzahl der Verkehrsteilnehmer variieren.

## Schlussfolgerung

Die Fluss- und Staukontrolle sind essenzielle Mechanismen in der Transportschicht, um die Zuverlässigkeit und Effizienz der Datenübertragung im Internet zu gewährleisten. Verschiedene Techniken wie die Stop-and-Wait-Methode, Fenstertechnik und Pufferreservierung bieten unterschiedliche Vor- und Nachteile, die je nach Anwendungsszenario abzuwägen sind. Durch die Implementierung von Strategien zur Fluss- und Staukontrolle kann eine optimale Netzwerkauslastung bei minimaler Fehlerrate erreicht werden. Der Einsatz von Retransmission-Timern, TCP Tahoe und TCP Reno zeigt, wie wichtige Optimierungen zur Effizienzsteigerung beitragen können. Auch der Vergleich zur Corona-Pandemie verdeutlicht, wie Prinzipien der Staukontrolle in verschiedenen Kontexten angewendet werden können.

# Fragen und Antworten zur Netzwerktechnik

## 1. Welche Parameter beeinflussen die Größe des Sequenznummernraumes?

Die Größe des Sequenznummernraumes wird durch die Anzahl der Bits bestimmt, die für die Sequenznummern verwendet werden. Ein zu kleiner Sequenznummernraum führt dazu, dass Fehler passieren können, da Nachrichten unterwegs sind, die die gleiche Sequenznummer haben.

## 2. Wie wird die Eindeutigkeit von Sequenznummern sichergestellt?

Die Eindeutigkeit von Sequenznummern wird dadurch sichergestellt, dass Sequenznummern mit jeder neuen Übertragung inkrementiert werden und groß genug sind, um Überlappungen zu vermeiden. Dadurch werden Fehler durch wiederholte Sequenznummern verhindert.

## 3. Wozu wird die Fenstertechnik eingesetzt?

Die Fenstertechnik wird verwendet, um den Durchsatz zu erhöhen und den Datenfluss zu regulieren, inklusive Stau- und Flusskontrolle.

## 4. Wie wirken sich zu kleine Fenster aus?

Zu kleine Fenster führen dazu, dass die verfügbare Kapazität nicht vollständig genutzt wird, wodurch die Datenübertragungsrate sinkt und die Effizienz der Datenübertragung beeinträchtigt wird.

## 5. Wie wirken sich zu kleine Sequenznummernräume aus?

Zu kleine Sequenznummernräume können zu Fehlern führen, da Nachrichten unterwegs sind, die die gleiche Sequenznummer haben, was zu Verwirrung und möglichen Datenverlusten führt.

## 6. Warum ist für einen sicheren Verbindungsaufbau auf der Transportschicht ein Drei-Wege-Handschlag erforderlich?

Ein Drei-Wege-Handschlag ist erforderlich, um sicherzustellen, dass beide Seiten wissen, dass eine Verbindung aufgebaut wurde. Ohne den Drei-Wege-Handschlag besteht das Risiko, dass eine Seite nicht über den Verbindungsaufbau informiert ist. Es wird auch erwähnt, dass ein Drei-Wege-Handschlag besser ist als ein Zwei-Wege-Handschlag, weil die zusätzliche Bestätigung die Wahrscheinlichkeit verringert, dass eine Antwort verloren geht.

## 7. Unter welchen Voraussetzungen genügt ein Zwei-Wege-Handschlag für einen Verbindungsaufbau?

Ein Zwei-Wege-Handschlag kann ausreichen, wenn die Verbindung hundertprozentig sicher ist und keine Rückantworten verloren gehen können. Das heißt, wenn die Verbindung so sicher ist, dass garantiert ist, dass jede gesendete Nachricht ankommt, dann reicht ein Zwei-Wege-Handschlag aus.

## 8. Warum muss der Verbindungsabbau beidseitig geschehen?

Der Verbindungsabbau muss beidseitig geschehen, um sicherzustellen, dass beide Seiten darüber informiert sind, dass die Kommunikation beendet ist. Dies verhindert Situationen, in denen eine Seite denkt, dass die Verbindung noch aktiv ist, während die andere Seite bereits geschlossen hat. Ein Beispiel aus dem Transkript ist ein Telefonat, bei dem eine Seite möglicherweise noch spricht, während die andere Seite bereits aufgelegt hat.

## 9. Was ist der Unterschied zwischen Flusskontrolle und Staukontrolle?

- **Flusskontrolle**: Kümmert sich um die Datenübertragung zwischen Sender und Empfänger, um sicherzustellen, dass der Sender den Empfänger nicht überlastet. Ein Beispiel ist ein Supercomputer, der Daten an ein Mobiltelefon sendet und dabei darauf achten muss, dass das Mobiltelefon nicht überfordert wird.
- **Staukontrolle**: Kümmert sich darum, dass es im Netzwerk keine Überlastungen gibt. Sie stellt sicher, dass das Netz zwischen den Kommunikationspunkten nicht überlastet wird, indem es die Datenmenge reguliert, die ins Netzwerk eingespeist wird. Ein Stau kann auftreten, wenn an den Zwischenpunkten des Netzwerks andere Datenflüsse die Kapazität beanspruchen.

## 10. Welche Anforderungen einer Anwendung können den Einsatz von UDP rechtfertigen?

UDP ist unsicher, aber schnell. Anwendungen, die eine schnelle Datenübertragung benötigen und bei denen es nicht so wichtig ist, ob alle Daten sicher ankommen, setzen auf UDP. Beispiele dafür sind Video-Streaming, bei dem der Verlust einiger Datenpakete toleriert werden kann, oder regelmäßige Statusmeldungen, bei denen es nicht tragisch ist, wenn mal eine Nachricht verloren geht.

## 11. Wie kann man in einer Anwendung, die UDP verwendet, einen zuverlässigen Datentransfer garantieren?

Obwohl UDP keine eingebaute Zuverlässigkeit bietet, kann man in der Anwendungsebene zusätzliche Mechanismen einbauen, wie zum Beispiel Sequenznummern. Diese Sequenznummern werden in den Nutzdaten mitgesendet, und der Empfänger kann anhand dieser Nummern überprüfen, ob alle Datenpakete angekommen sind. Fehlen Pakete, können sie erneut gesendet werden.

## 12. Alice sendet 2 TCP-Segmente (mit Sequenznummer 90 und 110) an Bob.

### Wie viele Daten enthält das erste Segment? Wie lang ist das erste Segment insgesamt?

Das erste Segment enthält 20 Bytes Daten (Sequenznummer 110 - Sequenznummer 90 = 20 Bytes). Zusätzlich zum Dateninhalt enthält jedes TCP-Segment einen Header, der bei TCP mindestens 40 Bytes lang ist. Somit ist das erste Segment insgesamt 60 Bytes lang (20 Bytes Daten + 40 Bytes Header).

### Wie lautet die Quittungsnummer der Bestätigung von Bob, wenn nur das erste Segment verloren geht?

Wenn nur das erste Segment verloren geht, wird Bob die Quittungsnummer 90 zurücksenden. Diese Quittungsnummer zeigt an, dass er immer noch auf das erste Segment wartet und es erneut gesendet werden muss.

## 13. Welche Mechanismen verwendet TCP für eine zuverlässige Ende-zu-Ende Verbindung?

TCP verwendet mehrere Mechanismen für eine zuverlässige Ende-zu-Ende-Verbindung:

- **Drei-Wege-Handschlag**: Zur Bestätigung, dass beide Seiten bereit für die Kommunikation sind.
- **Sequenznummern**: Um die Reihenfolge der Pakete zu überwachen und sicherzustellen, dass alle Pakete korrekt und vollständig ankommen.
- **Bestätigungen (ACKs)**: Empfänger bestätigen den Erhalt von Paketen, sodass der Sender weiß, welche Pakete erfolgreich angekommen sind.
- **Wiederholungsmechanismen**: Wenn keine Bestätigung empfangen wird, sendet TCP das Paket erneut.
- **Flusskontrolle und Staukontrolle**: Um sicherzustellen, dass das Netzwerk und der Empfänger nicht überlastet werden.

## 14. Wie realisiert man „Multiplexen“ von Anwendungen auf der Transportschicht?

Das Multiplexen von Anwendungen auf der Transportschicht wird durch die Verwendung von **Ports** realisiert. Jeder Port stellt einen Kommunikationsendpunkt für eine Anwendung dar. Durch die Verwendung verschiedener Ports können mehrere Anwendungen gleichzeitig über dasselbe Netzwerk kommunizieren, ohne dass es zu Verwechslungen kommt.

## 15. Wie funktioniert TCP Tahoe zur Staukontrolle?

TCP Tahoe verwendet eine Kombination aus **Slow Start**, **Congestion Avoidance** und **Fast Retransmit** zur Staukontrolle:

- **Slow Start**: Beginnt mit einer niedrigen Übertragungsrate und erhöht die Rate exponentiell, bis ein Verlust erkannt wird.
- **Congestion Avoidance**: Nach Erreichen eines bestimmten Schwellenwerts wird die Übertragungsrate nur noch linear erhöht, um Staus zu vermeiden.
- **Fast Retransmit**: Wenn drei duplizierte ACKs empfangen werden, interpretiert TCP dies als Paketverlust und sendet das vermisste Paket sofort erneut, ohne auf den Timeout zu warten.

## 16. Können Sende- und Empfangsfenster bei der Fenstertechnik unterschiedlich groß sein?

Ja, Sende- und Empfangsfenster können unterschiedlich groß sein. Der Grund dafür liegt in den unterschiedlichen Fähigkeiten und Speicherkapazitäten der Geräte. Ein Beispiel ist ein Supercomputer, der große Datenmengen senden kann, während ein Smartphone möglicherweise nur kleine Datenmengen empfangen kann. Die Fenstertechnik ermöglicht es, diese Unterschiede zu berücksichtigen und den Datenfluss entsprechend zu regulieren.
